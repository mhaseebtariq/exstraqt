{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2024 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LightGBM model for AML using graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sklearn2pmml/resources/__init__.py:1: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "from snapml import GraphFeaturePreprocessor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "\n",
    "# For exporting to PMML\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn2pmml import sklearn2pmml\n",
    "from sklearn2pmml.decoration import CategoricalDomain, ContinuousDomain\n",
    "from sklearn2pmml.pipeline import PMMLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data_path = \"./aml-demo-data/out_dir_small_hi/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015669\n"
     ]
    }
   ],
   "source": [
    "n_test = round(pd.read_csv(f\"{formatted_data_path}formatted_transactions.csv\").shape[0] * 0.2)\n",
    "print(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the input transacton file enriched with graph-based features.\n",
    "transactions_path = formatted_data_path + \"formatted_transactions.csv\"\n",
    "\n",
    "# Set the output path for the trained PMML model.\n",
    "gf_model_out_path = formatted_data_path + \"aml-hi-small_model.pmml\"\n",
    "basic_model_out_path = formatted_data_path + \"aml-hi-small_basic_model.pmml\"\n",
    "\n",
    "# Set the column indices to be removed: Transaction ID, Source Account ID, Target Account ID, Source Bank ID, Target Bank ID\n",
    "remove_cols = [0,1,2,10,11]\n",
    "\n",
    "# Batch size used for creating graph-based features\n",
    "batch_size = int(n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data\n",
      "Data loaded succesfully.\n",
      "Data shape is  (5078345, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test data\")\n",
    "X_all = np.loadtxt(transactions_path, dtype=np.float64, delimiter=\",\", comments='#', skiprows=1)\n",
    "\n",
    "Y_all = X_all[:,-1] # Labels\n",
    "X_all = X_all[:,:-1] # Drop labels\n",
    "\n",
    "print(\"Data loaded succesfully.\")\n",
    "print(\"Data shape is \", X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a graph feature preprocessor \n",
      "Setting the parameters of the graph feature preprocessor \n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a graph feature preprocessor \")\n",
    "gp = GraphFeaturePreprocessor()\n",
    "\n",
    "print(\"Setting the parameters of the graph feature preprocessor \")\n",
    "tw_days = 1\n",
    "gf_params = {\n",
    "    # Number of software threads to be used\n",
    "    'num_threads': 12,\n",
    "\n",
    "    # Enable account statistics\n",
    "    'vertex_stats': True,\n",
    "    'vertex_stats_cols': [3,6],\n",
    "\n",
    "    # Enable graph-pattern-based features\n",
    "    'fan': True,\n",
    "    'degree': True,\n",
    "    'scatter-gather': True,\n",
    "    'temp-cycle': True,\n",
    "    'lc-cycle': True,\n",
    "    'lc-cycle_len': 10,\n",
    "\n",
    "    # Set time window parameters\n",
    "    'time_window': tw_days*24*3600,\n",
    "    'vertex_stats_tw': tw_days*24*3600,\n",
    "    'scatter-gather_tw': 6*3600,\n",
    "    'temp-cycle_tw': tw_days*24*3600,\n",
    "    'lc-cycle_tw': tw_days*24*3600,\n",
    "}\n",
    "gp.set_params(gf_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for determining the number of graph-based features produced by Graph Feature Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_gf_feats(gf):\n",
    "    params = gf.get_params()\n",
    "    feat_num = 0\n",
    "\n",
    "    # add features names for the graph patterns\n",
    "    for pattern in ['fan', 'degree', 'scatter-gather', 'temp-cycle', 'lc-cycle']:\n",
    "        if pattern in params:\n",
    "            if params[pattern]:\n",
    "                bins = len(params[pattern +'_bins'])\n",
    "                if pattern in ['fan', 'degree']:\n",
    "                    feat_num += 2*bins\n",
    "                else:\n",
    "                    feat_num += bins\n",
    "\n",
    "    # add fan, deg, and ratio features\n",
    "    for k in [0, 1, 2]:\n",
    "        if k in params[\"vertex_stats_feats\"]:\n",
    "            feat_num += 4\n",
    "\n",
    "    # add avg, sum, min, max, median, var, skew, and kurtosis features\n",
    "    for k in [3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "        if k in params[\"vertex_stats_feats\"]:\n",
    "            feat_num += 4*len(params[\"vertex_stats_cols\"])\n",
    "\n",
    "    return feat_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate graph-based features using Graph Feature Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating graph-based features\n",
      "Batch size: 1015669\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "616c7bca84c64de28d6d0028d88be543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, description='Processing:', max=5078345)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Generating graph-based features\", flush=True)\n",
    "\n",
    "print(\"Batch size:\", batch_size)\n",
    "\n",
    "num_rows = np.shape(X_all)[0]\n",
    "num_cols = np.shape(X_all)[1] + get_num_gf_feats(gp)\n",
    "\n",
    "X_all_gf = np.zeros((num_rows,num_cols))\n",
    "\n",
    "# Display the progress bar\n",
    "pbar = IntProgress(min=0, max=num_rows, description='Processing:',)\n",
    "display(pbar)\n",
    "\n",
    "for i in range(0, num_rows, batch_size):\n",
    "    pbar.value = i # update progress bar\n",
    "\n",
    "    batch_size_true = batch_size\n",
    "    if i + batch_size > num_rows:\n",
    "        batch_size_true = num_rows - i\n",
    "\n",
    "    # Generate graph-based features for a batch of transactions\n",
    "    Features_in = X_all[i:i+batch_size_true,:].astype('float64')\n",
    "    Features_out = gp.transform(Features_in)\n",
    "    X_all_gf[i:i+batch_size_true,:] = Features_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove columns that relate to transaction and account IDs\n",
    "X_all_gf_rm = np.delete(X_all_gf, remove_cols, 1)\n",
    "X_all_rm = np.delete(X_all, remove_cols, 1)\n",
    "\n",
    "## Split to train and test set\n",
    "# Graph-based features\n",
    "X_train_gf = X_all_gf_rm[:-n_test]\n",
    "X_test_gf = X_all_gf_rm[-n_test:]\n",
    "\n",
    "# Basic features only\n",
    "X_train_basic = X_all_rm[:-n_test]\n",
    "X_test_basic = X_all_rm[-n_test:]\n",
    "\n",
    "# Labels\n",
    "y_train = Y_all[:-n_test]\n",
    "y_test = Y_all[-n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Model Training\n",
    "\n",
    "### Function for training LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_train_evaluate(X_train, y_train, X_test, y_test, params, model_path, gen_pmml=False):\n",
    "        \"\"\" Evaluate an LightGBM configuration\n",
    "\n",
    "        Args:\n",
    "            X_train (np.ndarray): Training feature matrix\n",
    "            y_train (np.ndarray): Training labels\n",
    "            X_test (np.ndarray): Test feature matrix\n",
    "            y_test (np.ndarray): Test labels\n",
    "            params (dict): Model configuration\n",
    "            model_path (string): Where to save the model\n",
    "\n",
    "        Returns:\n",
    "            score (float): Configuration score\n",
    "        \"\"\"\n",
    "\n",
    "        lgb_params = params.copy()\n",
    "        num_round = lgb_params['num_round']\n",
    "        lgb_params.pop('num_round')\n",
    "\n",
    "        lgb_params['objective'] = 'binary'\n",
    "        lgb_params.pop('alpha')\n",
    "        lgb_params.pop('gamma')\n",
    "\n",
    "        early_stopping_rounds = 20\n",
    "        if gen_pmml:\n",
    "            lgbm_mdl = LGBMClassifier(**lgb_params,\n",
    "                                        num_iterations=num_round)\n",
    "\n",
    "            pmml_pipeline = PMMLPipeline([(\"classifier\", lgbm_mdl)])\n",
    "            pmml_pipeline.fit(X_train, y_train)\n",
    "\n",
    "            sklearn2pmml(pmml_pipeline, model_path, with_repr=True)\n",
    "            print(\"PMML Model saved to path\", model_path, flush=True)\n",
    "\n",
    "            z_test = pmml_pipeline.predict_proba(X_test)\n",
    "            z_test = z_test[:,1] # probabilities of class 1\n",
    "            preds = pmml_pipeline.predict(X_test)\n",
    "        else:\n",
    "            dtrain = lgb.Dataset(X_train, y_train, weight=None)\n",
    "            dtest = lgb.Dataset(X_test, y_test, weight=None)\n",
    "\n",
    "            bst = lgb.train(lgb_params,\n",
    "                            dtrain,\n",
    "                            num_boost_round=num_round,\n",
    "                            valid_sets=[dtest],\n",
    "                            callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds), lgb.log_evaluation(50)]\n",
    "                            )\n",
    "\n",
    "            # bst.save_model(model_path)\n",
    "            # print(\"Txt model saved to path\", model_path, flush=True)\n",
    "\n",
    "            z_test = bst.predict(X_test)\n",
    "            preds = np.round(z_test)  # 1: illicit, 0: licit\n",
    "\n",
    "        score = fbeta_score(y_test, preds.astype(np.float64), beta=1, zero_division=0)\n",
    "\n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model with graph-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the training parameters. These parameters can be found using a Hyperparameter Tuning method such as Successive Halving.\n",
    "params = {\n",
    "    'boosting': 'gbdt',\n",
    "    'metric': 'auc',\n",
    "    'num_round': 185,\n",
    "    'num_leaves': 21,\n",
    "    'max_bin': 256,\n",
    "    'learning_rate': 0.08995441299910924,\n",
    "    'lambda_l1': 0.4902016501409548,\n",
    "    'lambda_l2': 81.93169246795033,\n",
    "    'scale_pos_weight': 4.495921090533586,\n",
    "    'alpha': 0.8028096762102561,\n",
    "    'gamma': 2.1902844884226473,\n",
    "    'seed': 5935727,\n",
    "    'max_depth': 10\n",
    "}\n",
    "\n",
    "print(\"Training using graph-based features.\")\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "res_score = lgbm_train_evaluate(X_train_gf, y_train, X_test_gf, y_test, params, gf_model_out_path, gen_pmml=True)\n",
    "print(\"----------------------------------------------------------------------------------\")\n",
    "print(\"Test minority-class F1 score is: \", res_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(round(res_score * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
