{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"DGLBACKEND\"] = \"pytorch\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import torch\n",
    "from dgl.nn import GraphConv\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "import settings as s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9cca740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(s.STAGED_DATA_LOCATION)\n",
    "data.loc[:, \"source\"] = data[\"source\"].str.slice(0, 8)\n",
    "data.loc[:, \"target\"] = data[\"target\"].str.slice(0, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb2420f-7296-4c1c-aa96-9c57e4a05dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_rates = {\n",
    "    \"jpy\": np.float32(0.009487665410827868),\n",
    "    \"cny\": np.float32(0.14930721887033868),\n",
    "    \"cad\": np.float32(0.7579775434031815),\n",
    "    \"sar\": np.float32(0.2665884611958837),\n",
    "    \"aud\": np.float32(0.7078143121927827),\n",
    "    \"ils\": np.float32(0.29612081311363503),\n",
    "    \"chf\": np.float32(1.0928961554056371),\n",
    "    \"usd\": np.float32(1.0),\n",
    "    \"eur\": np.float32(1.171783425225877),\n",
    "    \"rub\": np.float32(0.012852809604990688),\n",
    "    \"gbp\": np.float32(1.2916554735187644),\n",
    "    \"btc\": np.float32(11879.132698717296),\n",
    "    \"inr\": np.float32(0.013615817231245796),\n",
    "    \"mxn\": np.float32(0.047296753463246695),\n",
    "    \"brl\": np.float32(0.1771008654705292),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ab2cc8c-4234-404b-a15c-2561f35da7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.9 s, sys: 218 ms, total: 19.1 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.loc[:, \"amount_usd\"] = data.apply(lambda x: currency_rates[x[\"source_currency\"]] * x[\"source_amount\"], axis=1)\n",
    "data.loc[:, \"timestamp_trend\"] = (data.loc[:, \"timestamp\"].astype(int) / 10**9) - (data.loc[:, \"timestamp\"].min().timestamp() - 1)\n",
    "del data[\"timestamp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9874e11-c681-4a5c-8ea5-69317798d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_quantiles(values, weights, quantiles=0.5, interpolate=False):\n",
    "    i = values.argsort()\n",
    "    sorted_weights = weights[i]\n",
    "    sorted_values = values[i]\n",
    "    sorted_weights_cumsum = sorted_weights.cumsum()\n",
    "\n",
    "    if interpolate:\n",
    "        xp = (sorted_weights_cumsum - sorted_weights/2 ) / sorted_weights_cumsum[-1]\n",
    "        return np.interp(quantiles, xp, sorted_values)\n",
    "    else:\n",
    "        return sorted_values[np.searchsorted(sorted_weights_cumsum, quantiles * sorted_weights_cumsum[-1])]\n",
    "\n",
    "\n",
    "def weighted_std(values, weights):\n",
    "    average = np.average(values, weights=weights)\n",
    "    variance = np.average((values-average)**2, weights=weights)\n",
    "    return np.sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f89d357-7f8c-4577-af96-a20862b40598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 3.51 s, total: 1min 44s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "timestamp_weighted_std = data.groupby([\"source\", \"target\"]).apply(\n",
    "    lambda x: weighted_std(x[\"timestamp_trend\"], x[\"amount_usd\"]),\n",
    "    include_groups=False\n",
    ").reset_index().rename(columns={0 : \"timestamp_weighted_std\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90fd110f-909c-4210-8130-a72c02d8dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 40.5 s, sys: 1.27 s, total: 41.8 s\n",
      "Wall time: 40.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "timestamp_weighted_mean = data.groupby([\"source\", \"target\"]).apply(\n",
    "    lambda x: np.average(x[\"timestamp_trend\"], weights=x[\"amount_usd\"]),\n",
    "    include_groups=False\n",
    ").reset_index().rename(columns={0 : \"timestamp_weighted_mean\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7e48b98-739a-4542-89bc-b04205a65723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.1 s, sys: 204 ms, total: 28.3 s\n",
      "Wall time: 28.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "timestamp_weighted_median = data.groupby([\"source\", \"target\"]).apply(\n",
    "    lambda x: weighted_quantiles(\n",
    "        x[\"timestamp_trend\"].values, weights=x[\"amount_usd\"].values, quantiles=0.5, interpolate=True\n",
    "    ),\n",
    "    include_groups=False\n",
    ").reset_index().rename(columns={0 : \"timestamp_weighted_median\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cb08d92-6a90-4aaf-b0ba-6d4c6994438e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.9 s, sys: 188 ms, total: 28.1 s\n",
      "Wall time: 28 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "timestamp_weighted_90th = data.groupby([\"source\", \"target\"]).apply(\n",
    "    lambda x: weighted_quantiles(\n",
    "        x[\"timestamp_trend\"].values, weights=x[\"amount_usd\"].values, quantiles=0.9, interpolate=True\n",
    "    ),\n",
    "    include_groups=False\n",
    ").reset_index().rename(columns={0 : \"timestamp_weighted_90th\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a929510a-c45c-4581-b5f0-7d00a723ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(grouped_data, key, source_or_target=\"source\"):\n",
    "    source, target = key\n",
    "    row = {\n",
    "        \"source\": source, \"target\": target, \n",
    "        \"amount_usd\": sum(grouped_data[\"amount_usd\"]), \n",
    "        \"is_laundering\": max(grouped_data[\"is_laundering\"])\n",
    "    }\n",
    "    turnover_currency = (\n",
    "        grouped_data.groupby(\n",
    "            f\"{source_or_target}_currency\"\n",
    "        ).agg({f\"{source_or_target}_amount\": \"sum\"}).to_dict()[f\"{source_or_target}_amount\"]\n",
    "    )\n",
    "    # if len(turnover_currency) > 1:\n",
    "    #     if \"btc\" not in turnover_currency:\n",
    "    #         raise Exception(turnover_currency)\n",
    "    row.update(turnover_currency)\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43a0f59c-dae9-4a06-bece-0b74ceb039c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 20s, sys: 9.28 s, total: 6min 29s\n",
      "Wall time: 6min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "features = []\n",
    "for key_, group in data.groupby([\"source\", \"target\"]):\n",
    "    features.append(generate_features(group, key_))\n",
    "features = pd.DataFrame(features).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7df55ab8-2fd6-4a48-a51a-69a86e6a85ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.68 s, sys: 221 ms, total: 4.9 s\n",
      "Wall time: 4.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "index = [\"source\", \"target\"]\n",
    "to_join = [timestamp_weighted_std, timestamp_weighted_mean, timestamp_weighted_median, timestamp_weighted_90th]\n",
    "features = features.set_index(index)\n",
    "for join in to_join:\n",
    "    features = features.join(join.set_index(index))\n",
    "features = features.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7590157-b927-41ee-8918-cf7efaa31646",
   "metadata": {},
   "outputs": [],
   "source": [
    "features.loc[:, \"id\" ] = list(features.index)\n",
    "left = features.loc[:, [\"id\", \"source\", \"target\", \"timestamp_weighted_mean\", \"amount_usd\"]].set_index(\"target\")\n",
    "right = features.loc[:, [\"id\", \"source\", \"target\", \"timestamp_weighted_mean\", \"amount_usd\"]].set_index(\"source\")\n",
    "edges = left.join(right, how=\"inner\", lsuffix=\"_left\").reset_index(drop=True)\n",
    "edges = edges[\n",
    "    [\"id_left\", \"id\", \"timestamp_weighted_mean\", \"timestamp_weighted_mean_left\", \"amount_usd\", \"amount_usd_left\"]\n",
    "    ].rename(\n",
    "    columns={\"id_left\": \"source\", \"id\": \"target\"}\n",
    ")\n",
    "edges.loc[:, \"recency\"] = 1 - abs(edges[\"timestamp_weighted_mean_left\"] - edges[\"timestamp_weighted_mean\"]) / (\n",
    "    edges[\"timestamp_weighted_mean_left\"] + edges[\"timestamp_weighted_mean\"]\n",
    ")\n",
    "edges.loc[:, \"flow\"] = 1 - abs(edges[\"amount_usd_left\"] - edges[\"amount_usd\"]) / (\n",
    "    edges[\"amount_usd_left\"] + edges[\"amount_usd\"]\n",
    ")\n",
    "features_test = features.sample(frac=0.3).copy(deep=True)\n",
    "features.loc[:, \"train_mask\"] = True\n",
    "features.loc[features_test.index, \"train_mask\"] = False\n",
    "del edges[\"timestamp_weighted_mean_left\"]\n",
    "del edges[\"timestamp_weighted_mean\"]\n",
    "del edges[\"amount_usd_left\"]\n",
    "del edges[\"amount_usd\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0e2de04-981c-4458-b376-dc4d297b296e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [\n",
    "    'amount_usd', 'usd', 'eur', 'cny',\n",
    "    'jpy', 'inr', 'rub', 'gbp', 'cad', 'aud', 'mxn', 'brl', 'chf', 'ils',\n",
    "    'sar', 'btc', 'timestamp_weighted_std', 'timestamp_weighted_mean',\n",
    "    'timestamp_weighted_median', 'timestamp_weighted_90th'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb1dd884-ad71-40ae-8e41-e59ce83aec84",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dgl.graph((edges[\"source\"], edges[\"target\"]), num_nodes=features.shape[0])\n",
    "\n",
    "# Node attributes\n",
    "graph.ndata[\"feat\"] = torch.from_numpy(np.array(features[feature_columns].values, dtype=np.float32))\n",
    "graph.ndata[\"label\"] = torch.from_numpy(np.array(features[\"is_laundering\"].values, np.int64))\n",
    "graph.ndata[\"train_mask\"] = torch.from_numpy(features[\"train_mask\"].values)\n",
    "graph.ndata[\"test_mask\"] = torch.from_numpy(~features[\"train_mask\"].values)\n",
    "\n",
    "# Edge attributes\n",
    "# These are probably not supported in the model\n",
    "edges_attributes = [\"recency\", \"flow\"]\n",
    "graph.edata[\"recency\"] = torch.from_numpy(np.array(edges[edges_attributes].values, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6b9bb76-fc4d-4240-be40-1ef2e589efc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats, allow_zero_in_degree=True)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes, allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        return h\n",
    "    \n",
    "\n",
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    # best_val_acc = 0\n",
    "    # best_test_acc = 0\n",
    "\n",
    "    features = g.ndata[\"feat\"]\n",
    "    labels = g.ndata[\"label\"]\n",
    "    train_mask = g.ndata[\"train_mask\"]\n",
    "    # val_mask = g.ndata[\"val_mask\"]\n",
    "    test_mask = g.ndata[\"test_mask\"]\n",
    "    for e in range(100):\n",
    "        # Forward\n",
    "        logits = model(g, features)\n",
    "        # Compute prediction\n",
    "        pred = logits.argmax(1)\n",
    "\n",
    "        # Compute loss\n",
    "        # Note that you should only compute the losses of the nodes in the training set.\n",
    "        loss = F.cross_entropy(logits[train_mask], labels[train_mask], weight=torch.tensor([1.0, 100.0]))\n",
    "\n",
    "        y = pred[test_mask]\n",
    "        y_true = labels[test_mask]\n",
    "        # Compute accuracy on training/validation/test\n",
    "        train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "        # val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "        test_acc = (y == y_true).float().mean()\n",
    "\n",
    "        # # Save the best validation accuracy and the corresponding test accuracy.\n",
    "        # if best_val_acc < val_acc:\n",
    "        #     best_val_acc = val_acc\n",
    "        #     best_test_acc = test_acc\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if e % 5 == 0:\n",
    "            # print(\n",
    "            #     f\"In epoch {e}, loss: {loss:.3f}, val acc: {val_acc:.3f} (best {best_val_acc:.3f}), test acc: {test_acc:.3f} (best {best_test_acc:.3f})\"\n",
    "            # )\n",
    "            print(\n",
    "                f\"In epoch {e}, loss: {loss:.3f}, test acc: {test_acc:.3f}\"\n",
    "            )\n",
    "    return y, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0313446a-4c65-47a0-b7b2-004b475a5fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In epoch 0, loss: 1198976.875, test acc: 0.757\n",
      "In epoch 5, loss: 177803.250, test acc: 0.955\n",
      "In epoch 10, loss: 319607.156, test acc: 0.639\n",
      "In epoch 15, loss: 119910.000, test acc: 0.688\n",
      "In epoch 20, loss: 101918.680, test acc: 0.575\n",
      "In epoch 25, loss: 87060.523, test acc: 0.899\n",
      "In epoch 30, loss: 63340.883, test acc: 0.914\n",
      "In epoch 35, loss: 46380.887, test acc: 0.277\n",
      "In epoch 40, loss: 70854.039, test acc: 0.604\n",
      "In epoch 45, loss: 55014.809, test acc: 0.967\n",
      "In epoch 50, loss: 81124.547, test acc: 0.313\n",
      "In epoch 55, loss: 101953.422, test acc: 0.869\n",
      "In epoch 60, loss: 65272.984, test acc: 0.314\n",
      "In epoch 65, loss: 59597.215, test acc: 0.974\n",
      "In epoch 70, loss: 41365.840, test acc: 0.749\n",
      "In epoch 75, loss: 65573.484, test acc: 0.651\n",
      "In epoch 80, loss: 53056.926, test acc: 0.622\n",
      "In epoch 85, loss: 40356.359, test acc: 0.903\n",
      "In epoch 90, loss: 81222.039, test acc: 0.312\n",
      "In epoch 95, loss: 58085.973, test acc: 0.810\n"
     ]
    }
   ],
   "source": [
    "hidden_features = 64\n",
    "model = GCN(graph.ndata[\"feat\"].shape[1], hidden_features, 2)\n",
    "y, y_true = train(graph, model)\n",
    "y_true = np.array(y_true.tolist())\n",
    "y = np.array(y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ae5f8d-3540-4688-9612-ca10c1eaf37c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.493 0.011\n"
     ]
    }
   ],
   "source": [
    "print(round(recall_score(y_true, y), 3), round(f1_score(y_true, y), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fff3f6bc-79f9-4541-9fc8-415b32a19377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4266"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(y.sum() / y.shape[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c020a2ff-da9c-44b0-8c29-3b24ebf3e273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(y_true.sum() / y_true.shape[0], 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423405c2-d689-461d-9689-c48c29672253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
