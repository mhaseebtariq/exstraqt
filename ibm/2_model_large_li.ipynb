{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import settings_large_li as s\n",
    "\n",
    "os.environ[\"EXT_DATA_TYPE_FOLDER\"] = s.OUTPUT_POSTFIX.lstrip(\"-\")\n",
    "\n",
    "from common import get_weights, delete_large_vars, MULTI_PROC_STAGING_LOCATION\n",
    "from communities import get_communities_spark\n",
    "from features import (\n",
    "    generate_features_spark, generate_features_udf_wrapper, get_edge_features_udf, \n",
    "    SCHEMA_FEAT_UDF, FEATURE_TYPES\n",
    ")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a6e817-a3c3-4241-a04f-f8ce646c1f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    sys.version_info.major,\n",
    "    sys.version_info.minor,\n",
    "    sys.version_info.micro,\n",
    ") != (3, 11, 8):\n",
    "    raise EnvironmentError(\n",
    "        \"Only runs efficiently on Python 3.11.8 (Tested on: Conda 24.1.2 | Apple M3 Pro)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27447d11-c65b-420e-a660-29b498c58569",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/12 10:02:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "SPARK_CONF = [\n",
    "    (\"spark.driver.memory\", \"32g\"),\n",
    "    (\"spark.worker.memory\", \"32g\"),\n",
    "    (\"spark.driver.maxResultSize\", \"32g\"),\n",
    "    (\"spark.driver.bindAddress\", \"127.0.0.1\"),\n",
    "    (\"spark.sql.execution.arrow.pyspark.enabled\", \"true\"),\n",
    "    (\"spark.network.timeout\", \"600s\"),\n",
    "]\n",
    "\n",
    "shutil.rmtree(\"artifacts\", ignore_errors=True)\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"testing\")\n",
    "    .config(conf=SparkConf().setAll(SPARK_CONF))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e69899e-e6a0-4f84-a288-737de0dd3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fdc571c-b31c-4970-8f32-a9955cceb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERC = 0.6\n",
    "VALIDATION_PERC = 0.2\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "KEEP_TOP_N = 100\n",
    "\n",
    "assert(sum([TRAIN_PERC, VALIDATION_PERC, TEST_PERC]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b07872dd-5cd5-4a39-9c39-76a9ab296961",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_main = os.path.join(\"features\", os.environ[\"EXT_DATA_TYPE_FOLDER\"])\n",
    "# shutil.rmtree(location_main, ignore_errors=True)\n",
    "\n",
    "location_flows = f\"{location_main}{os.sep}flows_input{os.sep}\"\n",
    "location_flow_dispense = f\"{location_main}{os.sep}flow_dispense.parquet\"\n",
    "location_flow_passthrough = f\"{location_main}{os.sep}flow_passthrough.parquet\"\n",
    "location_flow_sink = f\"{location_main}{os.sep}flow_sink.parquet\"\n",
    "\n",
    "location_comm_as_source_features = f\"{location_main}{os.sep}comm_as_source_features.parquet\"\n",
    "location_comm_as_target_features = f\"{location_main}{os.sep}comm_as_target_features.parquet\"\n",
    "location_comm_as_passthrough_features = f\"{location_main}{os.sep}comm_as_passthrough_features.parquet\"\n",
    "location_comm_as_passthrough_features_reverse = f\"{location_main}{os.sep}comm_as_passthrough_features_reverse.parquet\"\n",
    "\n",
    "location_features_node_level = f\"{location_main}{os.sep}features_node_level.parquet\"\n",
    "location_features_edges = f\"{location_main}{os.sep}features_edges.parquet\"\n",
    "\n",
    "location_features_edges_train = f\"{location_main}{os.sep}features_edges_train.parquet\"\n",
    "location_features_edges_valid = f\"{location_main}{os.sep}features_edges_valid.parquet\"\n",
    "location_features_edges_test = f\"{location_main}{os.sep}features_edges_test.parquet\"\n",
    "\n",
    "location_train_trx_features = f\"{location_main}{os.sep}train_trx_features.parquet\"\n",
    "location_valid_trx_features = f\"{location_main}{os.sep}valid_trx_features.parquet\"\n",
    "location_test_trx_features = f\"{location_main}{os.sep}test_trx_features.parquet\"\n",
    "\n",
    "location_train_features = f\"{location_main}{os.sep}train_features.parquet\"\n",
    "location_valid_features = f\"{location_main}{os.sep}valid_features.parquet\"\n",
    "location_test_features = f\"{location_main}{os.sep}test_features.parquet\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_main)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c35a497-3f7f-498a-8a5a-da1a78d1f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(s.STAGED_DATA_LOCATION)\n",
    "data = data.withColumn(\"is_laundering\", sf.col(\"is_laundering\").cast(\"boolean\"))\n",
    "data_count_original = data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70a13395-4873-4612-b464-1e8103b5ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:===================================================>  (192 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175887982 105532789 35177596 35177597\n",
      "\n",
      "CPU times: user 3.07 s, sys: 1.46 s, total: 4.53 s\n",
      "Wall time: 25min 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trx_ids_sorted = data.sort(\"timestamp\").select(\"transaction_id\").toPandas()[\"transaction_id\"].values\n",
    "trx_count = len(trx_ids_sorted)\n",
    "\n",
    "last_train_index = int(np.floor(trx_count * TRAIN_PERC))\n",
    "last_validation_index = last_train_index + int(np.floor(trx_count * VALIDATION_PERC))\n",
    "train_indexes = trx_ids_sorted[:last_train_index]\n",
    "validation_indexes = trx_ids_sorted[last_train_index:last_validation_index]\n",
    "test_indexes = trx_ids_sorted[last_validation_index:]\n",
    "\n",
    "train_indexes = spark.createDataFrame(\n",
    "    pd.DataFrame(train_indexes, columns=[\"transaction_id\"])\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "validation_indexes = spark.createDataFrame(\n",
    "    pd.DataFrame(validation_indexes, columns=[\"transaction_id\"])\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "test_indexes = spark.createDataFrame(\n",
    "    pd.DataFrame(test_indexes, columns=[\"transaction_id\"])\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "train = train_indexes.join(\n",
    "    data, on=\"transaction_id\", how=\"left\"\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "validation = validation_indexes.join(\n",
    "    data, on=\"transaction_id\", how=\"left\"\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "test = test_indexes.join(\n",
    "    data, on=\"transaction_id\", how=\"left\"\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "print()\n",
    "print(trx_count, train.count(), validation.count(), test.count())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "762aff1b-6019-4f35-9659-e63d751c2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later on, we will reset the variables (to free up memory), while still keeping these intact\n",
    "to_keep = %who_ls\n",
    "to_keep = list(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e3a4cb-49c2-4b39-8d18-7ee9ec22daca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 66:===================================================>  (192 + 8) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175820031 159671706\n",
      "CPU times: user 11.4 s, sys: 739 ms, total: 12.1 s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "edges_totals = data.select(\"source\", \"target\", \"amount\").groupby(\n",
    "    [\"source\", \"target\"]\n",
    ").agg(sf.count(\"amount\").alias(\"amount\")).toPandas()\n",
    "edges_totals = edges_totals.sort_values(\"amount\", ascending=False).reset_index(drop=True)\n",
    "left_edges = spark.createDataFrame(edges_totals.groupby(\"target\").head(KEEP_TOP_N).loc[:, [\"source\", \"target\"]])\n",
    "right_edges = spark.createDataFrame(edges_totals.groupby(\"source\").head(KEEP_TOP_N).loc[:, [\"source\", \"target\"]])\n",
    "\n",
    "columns = [\"source\", \"target\", \"timestamp\", \"amount\"]\n",
    "\n",
    "left = left_edges.select(sf.col(\"source\").alias(\"src\"), sf.col(\"target\").alias(\"tgt\")).join(\n",
    "    data.select(*columns),\n",
    "    on=(sf.col(\"src\") == sf.col(\"source\")) & (sf.col(\"tgt\") == sf.col(\"target\")),\n",
    "    how=\"left\"\n",
    ").drop(\"src\", \"tgt\").persist(StorageLevel.DISK_ONLY)\n",
    "select = []\n",
    "for column in left.columns:\n",
    "    select.append(sf.col(column).alias(f\"left_{column}\"))\n",
    "left = left.select(*select)\n",
    "right = right_edges.select(sf.col(\"source\").alias(\"src\"), sf.col(\"target\").alias(\"tgt\")).join(\n",
    "    data.select(*columns),\n",
    "    on=(sf.col(\"src\") == sf.col(\"source\")) & (sf.col(\"tgt\") == sf.col(\"target\")),\n",
    "    how=\"left\"\n",
    ").drop(\"src\", \"tgt\").persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "print(left.count(), right.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b29341fe-4e6c-4dff-a960-9844437fd96b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispense\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "passthrough\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sink\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.8 s, sys: 1.45 s, total: 7.26 s\n",
      "Wall time: 19min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "flows_temporal = left.join(\n",
    "    right,\n",
    "    (left[\"left_target\"] == right[\"source\"]) &\n",
    "    (left[\"left_timestamp\"] <= right[\"timestamp\"]),\n",
    "    how=\"inner\"\n",
    ").groupby([\"left_source\", \"left_target\", \"source\", \"target\"]).agg(\n",
    "    sf.sum(\"left_amount\").alias(\"left_amount\"),\n",
    "    sf.sum(\"amount\").alias(\"amount\"),\n",
    ").drop(\"left_target\").select(\n",
    "    sf.col(\"left_source\").alias(\"dispense\"),\n",
    "    sf.col(\"source\").alias(\"passthrough\"),\n",
    "    sf.col(\"target\").alias(\"sink\"),\n",
    "    sf.least(\"left_amount\", \"amount\").alias(\"amount\"),\n",
    ")\n",
    "\n",
    "aggregate = [\n",
    "    sf.sum(\"amount\").alias(\"amount_sum\"),\n",
    "    sf.mean(\"amount\").alias(\"amount_mean\"),\n",
    "    sf.median(\"amount\").alias(\"amount_median\"),\n",
    "    sf.max(\"amount\").alias(\"amount_max\"),\n",
    "    sf.stddev(\"amount\").alias(\"amount_std\"),\n",
    "    sf.countDistinct(\"dispense\").alias(\"dispense_count\"),\n",
    "    sf.countDistinct(\"passthrough\").alias(\"passthrough_count\"),\n",
    "    sf.countDistinct(\"sink\").alias(\"sink_count\"),\n",
    "]\n",
    "for flow_location, flow_type in [\n",
    "    (location_flow_dispense, \"dispense\"), (location_flow_passthrough, \"passthrough\"), (location_flow_sink, \"sink\")\n",
    "]:\n",
    "    print(flow_type)\n",
    "    flows_temporal_stats = flows_temporal.groupby(flow_type).agg(*aggregate).toPandas()\n",
    "    flows_temporal_cyclic_stats = flows_temporal.where(\n",
    "        (sf.col(\"dispense\") == sf.col(\"sink\"))\n",
    "    ).groupby(flow_type).agg(*aggregate).toPandas()\n",
    "    flows_temporal_stats = flows_temporal_stats.set_index(flow_type).join(\n",
    "        flows_temporal_cyclic_stats.set_index(flow_type),\n",
    "        how=\"left\", rsuffix=\"_cycle\"\n",
    "    )\n",
    "    flows_temporal_stats.index.name = \"key\"\n",
    "    flows_temporal_stats.to_parquet(flow_location)\n",
    "    del flows_temporal_stats\n",
    "    del flows_temporal_cyclic_stats\n",
    "\n",
    "left.unpersist()\n",
    "right.unpersist()\n",
    "\n",
    "del edges_totals\n",
    "del left_edges\n",
    "del right_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88213f0e-2497-4f01-b735-f941102e4f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing comm_as_source\n",
      "\n",
      "Processed hop #1 | 6,546,146 | 1,667,461\n",
      "Processed hop #2 | 11,743,314 | 1,469,375\n",
      "Processed hop #3 | 21,126,347 | 1,409,144\n",
      "Processed hop #4 | 28,378,197 | 1,391,266\n",
      "\n",
      "Processing comm_as_target\n",
      "\n",
      "Processed hop #1 | 6,558,360 | 1,314,480\n",
      "Processed hop #2 | 18,557,822 | 1,194,763\n",
      "Processed hop #3 | 31,991,627 | 1,162,194\n",
      "Processed hop #4 | 40,376,550 | 1,141,529\n",
      "\n",
      "Processing comm_as_passthrough\n",
      "\n",
      "Processed hop #1 | 6,037,558 | 1,296,091\n",
      "Processed hop #2 | 10,075,947 | 1,116,547\n",
      "Processed hop #3 | 17,959,727 | 1,070,066\n",
      "Processed hop #4 | 22,473,290 | 1,055,391\n",
      "\n",
      "Processing comm_as_passthrough_reverse\n",
      "\n",
      "Processed hop #1 | 6,430,169 | 1,286,192\n",
      "Processed hop #2 | 18,024,540 | 1,166,579\n",
      "Processed hop #3 | 31,226,605 | 1,135,556\n",
      "Processed hop #4 | 39,696,655 | 1,116,244\n",
      "\n",
      "\n",
      "comm_as_source_features\n",
      "\n",
      "CPU times: user 2min 35s, sys: 9.71 s, total: 2min 45s\n",
      "Wall time: 2min 38s\n",
      "\n",
      "comm_as_target_features\n",
      "\n",
      "CPU times: user 2min 16s, sys: 8.5 s, total: 2min 24s\n",
      "Wall time: 2min 18s\n",
      "\n",
      "comm_as_passthrough_features\n",
      "\n",
      "CPU times: user 2min 3s, sys: 8.04 s, total: 2min 11s\n",
      "Wall time: 2min 5s\n",
      "\n",
      "comm_as_passthrough_features_reverse\n",
      "\n",
      "CPU times: user 2min 14s, sys: 8.33 s, total: 2min 23s\n",
      "Wall time: 2min 16s\n",
      "\n",
      "\n",
      "CPU times: user 27min 27s, sys: 1min 21s, total: 28min 49s\n",
      "Wall time: 29min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_input = data.select(\"*\")\n",
    "nodes_source = set(data.select(\"source\").distinct().toPandas()[\"source\"])\n",
    "nodes_target = set(data.select(\"target\").distinct().toPandas()[\"target\"])\n",
    "nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "%run generate_flow_features.ipynb\n",
    "\n",
    "comm_as_source_features.to_parquet(location_comm_as_source_features)\n",
    "comm_as_target_features.to_parquet(location_comm_as_target_features)\n",
    "comm_as_passthrough_features.to_parquet(location_comm_as_passthrough_features)\n",
    "comm_as_passthrough_features_reverse.to_parquet(location_comm_as_passthrough_features_reverse)\n",
    "\n",
    "del comm_as_source_features\n",
    "del comm_as_target_features\n",
    "del comm_as_passthrough_features\n",
    "del comm_as_passthrough_features_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2c2057d-c9e4-4df3-8fc2-8e9dca5d1dc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2047791\n",
      "250000 2047791\n",
      "500000 2047791\n",
      "750000 2047791\n",
      "1000000 2047791\n",
      "1250000 2047791\n",
      "1500000 2047791\n",
      "1750000 2047791\n",
      "2000000 2047791\n",
      "CPU times: user 2min 50s, sys: 2.41 s, total: 2min 53s\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_agg_weights = get_weights(\n",
    "    data.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        sf.sum(\"amount\").alias(\"amount\")\n",
    "    ).toPandas()\n",
    ")\n",
    "\n",
    "data_agg_weights_rev = data_agg_weights.rename(\n",
    "    columns={\"target\": \"source\", \"source\": \"target\"}\n",
    ").loc[:, [\"source\", \"target\", \"weight\"]]\n",
    "data_agg_weights_ud = pd.concat([data_agg_weights, data_agg_weights_rev], ignore_index=True)\n",
    "data_agg_weights_ud = data_agg_weights_ud.groupby([\"source\", \"target\"]).agg(weight=(\"weight\", \"sum\")).reset_index()\n",
    "\n",
    "data_agg_weights_ud.sort_values(\"weight\", ascending=False, inplace=True)\n",
    "grouped_ud = data_agg_weights_ud.groupby(\"source\").head(KEEP_TOP_N).reset_index(drop=True)\n",
    "grouped_ud = grouped_ud.groupby(\"source\").agg(targets=(\"target\", set))\n",
    "\n",
    "total = grouped_ud.index.nunique()\n",
    "nodes_neighborhoods = {}\n",
    "for index, (source, targets) in enumerate(grouped_ud.iterrows()):\n",
    "    community_candidates = {source}\n",
    "    for target in targets[\"targets\"]:\n",
    "        community_candidates |= (grouped_ud.loc[target, \"targets\"] | {target})\n",
    "    nodes_neighborhoods[source] = set(community_candidates)\n",
    "    if not (index % 250_000):\n",
    "        print(index, total)\n",
    "\n",
    "del data_agg_weights_rev\n",
    "del data_agg_weights_ud\n",
    "del grouped_ud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac9bfb33-be4f-4dbe-a1aa-2f48dc75a2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing communities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 4.07 s, total: 55.3 s\n",
      "Wall time: 7min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Constructing communities\")\n",
    "\n",
    "graph = ig.Graph.DataFrame(data_agg_weights, use_vids=False, directed=True)\n",
    "communities = get_communities_spark(nodes_neighborhoods, graph, os.cpu_count(), spark)\n",
    "\n",
    "del graph\n",
    "del data_agg_weights\n",
    "del nodes_neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48961885-70d5-4fd6-bf88-55694f326092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8177437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.8 s, sys: 5.4 s, total: 22.2 s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ts_min = data.select(sf.min(\"timestamp\").alias(\"x\")).collect()[0][\"x\"] - timedelta(minutes=1)\n",
    "data_graph_agg = data.groupby([\"source\", \"target\", \"source_bank\", \"target_bank\", \"source_currency\"]).agg(\n",
    "    sf.count(\"source\").alias(\"num_transactions\"),\n",
    "    sf.sum(\"amount\").alias(\"amount\"),\n",
    "    sf.sum(\"source_amount\").alias(\"source_amount\"),\n",
    "    sf.collect_list(sf.array((sf.col(\"timestamp\") - ts_min).cast(\"long\"), sf.col(\"amount\"))).alias(\"timestamps_amounts\"),\n",
    ")\n",
    "data_graph_agg_sdf = data_graph_agg.persist(StorageLevel.DISK_ONLY)\n",
    "print(data_graph_agg_sdf.count())\n",
    "data_graph_agg = data_graph_agg_sdf.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0941a40-42cd-4a48-ac50-e0c70fada876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Communities features creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30min 26s, sys: 14min 47s, total: 45min 13s\n",
      "Wall time: 1h 18min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"Communities features creation\")\n",
    "\n",
    "graph = ig.Graph.DataFrame(data_graph_agg, use_vids=False, directed=True)\n",
    "features = generate_features_spark(communities, graph, spark)\n",
    "features.columns = [f\"{s.G_COMM_PREFIX}{x}\" if x != \"key\" else x for x in features.columns]\n",
    "\n",
    "del graph\n",
    "del communities\n",
    "del data_graph_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7093cb9c-2ddb-4172-8a04-d4c2c0924487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-hop-source features creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.3 s, sys: 1.99 s, total: 12.3 s\n",
      "Wall time: 23min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"1-hop-source features creation\")\n",
    "\n",
    "features_source = data_graph_agg_sdf.withColumn(\"key\", sf.col(\"source\")).groupby(\"key\").applyInPandas(\n",
    "    generate_features_udf_wrapper(False), schema=SCHEMA_FEAT_UDF\n",
    ").toPandas()\n",
    "features_source = pd.DataFrame(features_source[\"features\"].apply(json.loads).tolist())\n",
    "types = {k: v for k, v in FEATURE_TYPES.items() if k in features_source.columns}\n",
    "features_source = features_source.astype(types)\n",
    "features_source.columns = [f\"{s.G_1HOP_PREFIX}{x}\" if x != \"key\" else x for x in features_source.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15e81ebb-1e56-41ba-8a04-9166ad34751c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-hop-target features creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.43 s, sys: 992 ms, total: 9.43 s\n",
      "Wall time: 18min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(\"1-hop-target features creation\")\n",
    "\n",
    "features_target = data_graph_agg_sdf.withColumn(\"key\", sf.col(\"target\")).groupby(\"key\").applyInPandas(\n",
    "    generate_features_udf_wrapper(False), schema=SCHEMA_FEAT_UDF\n",
    ").toPandas()\n",
    "features_target = pd.DataFrame(features_target[\"features\"].apply(json.loads).tolist())\n",
    "types = {k: v for k, v in FEATURE_TYPES.items() if k in features_target.columns}\n",
    "features_target = features_target.astype(types)\n",
    "features_target.columns = [f\"{s.G_1HOP_PREFIX}{x}\" if x != \"key\" else x for x in features_target.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f45f4cf-663d-4fb9-8b90-4064bd2cf3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 3.57 s, total: 24.4 s\n",
      "Wall time: 21.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_features = features.set_index(\"key\").join(\n",
    "    features_source.set_index(\"key\"), how=\"left\", rsuffix=f\"_1_hop_as_source\"\n",
    ")\n",
    "all_features.index.name = \"key\"\n",
    "all_features = all_features.reset_index()\n",
    "\n",
    "all_features = all_features.set_index(\"key\").join(\n",
    "    features_target.set_index(\"key\"), how=\"left\", rsuffix=f\"_1_hop_as_target\"\n",
    ")\n",
    "\n",
    "all_features = all_features.join(\n",
    "    pd.read_parquet(location_comm_as_source_features), how=\"left\", rsuffix=\"_dispense\"\n",
    ").join(\n",
    "    pd.read_parquet(location_comm_as_target_features), how=\"left\", rsuffix=\"_sink\"\n",
    ").join(\n",
    "    pd.read_parquet(location_comm_as_passthrough_features), how=\"left\", rsuffix=\"_passthrough\"\n",
    ").join(\n",
    "    pd.read_parquet(location_comm_as_passthrough_features_reverse), how=\"left\", rsuffix=\"_passthrough_rev\"\n",
    ").join(\n",
    "    pd.read_parquet(location_flow_dispense), how=\"left\", rsuffix=\"_dispense\"\n",
    ").join(\n",
    "    pd.read_parquet(location_flow_passthrough), how=\"left\", rsuffix=\"_passthrough\"\n",
    ").join(\n",
    "    pd.read_parquet(location_flow_sink), how=\"left\", rsuffix=\"_sink\"\n",
    ")\n",
    "\n",
    "all_features.to_parquet(location_features_node_level)\n",
    "del all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a41180a-7206-47ee-b292-9b2d7fbc8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.read_parquet(location_features_node_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b7526b8-de67-4aa9-93b5-352a5bb67d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "anomalies = all_features.loc[:, []]\n",
    "anomalies.loc[:, \"anomaly_score\"] = IsolationForest().fit(\n",
    "    all_features.fillna(0)\n",
    ").decision_function(all_features.fillna(0))\n",
    "anomalies.loc[:, \"anomaly_score\"] += abs(anomalies.loc[:, \"anomaly_score\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c04f2ba-88f3-49d0-b6d8-d6266d19dfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 93.55\n"
     ]
    }
   ],
   "source": [
    "if s.FILE_SIZE == \"Small\":\n",
    "    n_components = 50\n",
    "elif s.FILE_SIZE == \"Medium\":\n",
    "    n_components = 20\n",
    "else:\n",
    "    n_components = 5\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "all_features_dim_reduced = pd.DataFrame(\n",
    "    pca.fit_transform(normalize(all_features.fillna(0), norm=\"l1\", axis=1)),\n",
    "    index=all_features.index\n",
    ")\n",
    "print(n_components, round(sum(pca.explained_variance_ratio_) * 100, 2))\n",
    "all_features_dim_reduced.columns = [\n",
    "    f\"pca_{x + 1}\" for x in all_features_dim_reduced.columns\n",
    "]\n",
    "del all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "240a6967-a4a8-4990-927a-9da791df0c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating edge features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.6 s, sys: 4.68 s, total: 30.3 s\n",
      "Wall time: 28min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "print(f\"Generating edge features\")\n",
    "\n",
    "to_select = [\"source\", \"target\", \"format\", \"source_currency\", \"source_amount\", \"amount\", \"timestamp\"]\n",
    "\n",
    "edges_features_input = data.select(to_select).groupby(\n",
    "    [\"source\", \"target\", \"format\", \"source_currency\"]\n",
    ").agg(\n",
    "    sf.sum(\"source_amount\").alias(\"source_amount\"), \n",
    "    sf.sum(\"amount\").alias(\"amount\"),\n",
    "    sf.unix_timestamp(sf.min(\"timestamp\")).alias(\"min_ts\"),\n",
    "    sf.unix_timestamp(sf.max(\"timestamp\")).alias(\"max_ts\"),\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "_ = edges_features_input.count()\n",
    "\n",
    "edge_features = edges_features_input.groupby([\"source\", \"target\"]).applyInPandas(\n",
    "    get_edge_features_udf, schema=SCHEMA_FEAT_UDF\n",
    ").toPandas()\n",
    "edge_features = pd.DataFrame(edge_features[\"features\"].apply(json.loads).tolist())\n",
    "\n",
    "edge_features.to_parquet(location_features_edges)\n",
    "del edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6456cecb-97a0-45c6-bffc-a9db2d004ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = pd.read_parquet(location_features_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2884d7dd-1069-4275-b582-66e3604f45db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.7 s, sys: 3.31 s, total: 41.1 s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_edges = train.select(\"source\", \"target\").drop_duplicates().toPandas().set_index(\n",
    "    [\"source\", \"target\"]\n",
    ")\n",
    "valid_edges = validation.select(\"source\", \"target\").drop_duplicates().toPandas().set_index(\n",
    "    [\"source\", \"target\"]\n",
    ")\n",
    "test_edges = test.select(\"source\", \"target\").drop_duplicates().toPandas().set_index(\n",
    "    [\"source\", \"target\"]\n",
    ")\n",
    "\n",
    "train_features = train_edges.join(\n",
    "    edge_features.set_index([\"source\", \"target\"]), how=\"left\"\n",
    ").reset_index()\n",
    "validation_features = valid_edges.join(\n",
    "    edge_features.set_index([\"source\", \"target\"]), how=\"left\"\n",
    ").reset_index()\n",
    "test_features = test_edges.join(\n",
    "    edge_features.set_index([\"source\", \"target\"]), how=\"left\"\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb4a603e-a2af-41bc-8c10-f71c4bae2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_edge_features(features_in, location):\n",
    "    features_in = features_in.set_index(\"target\").join(\n",
    "        anomalies, how=\"left\"\n",
    "    ).reset_index().set_index(\"source\").join(\n",
    "        anomalies, how=\"left\", rsuffix=\"_source\"\n",
    "    ).reset_index().set_index(\"target\").join(\n",
    "        all_features_dim_reduced, how=\"left\"\n",
    "    ).reset_index().set_index(\"source\").join(\n",
    "        all_features_dim_reduced, how=\"left\", rsuffix=\"_source\"\n",
    "    ).reset_index()\n",
    "    features_in.loc[:, \"anom_scores_diff\"] = features_in.loc[:, \"anomaly_score\"] - features_in.loc[:, \"anomaly_score_source\"]\n",
    "    features_in.loc[:, \"anom_scores_min\"] = np.array(\n",
    "        [\n",
    "            features_in.loc[:, \"anomaly_score\"].values, \n",
    "            features_in.loc[:, \"anomaly_score_source\"].values\n",
    "        ],\n",
    "    ).min(axis=0)\n",
    "    features_in.loc[:, \"anom_scores_max\"] = np.array(\n",
    "        [\n",
    "            features_in.loc[:, \"anomaly_score\"].values, \n",
    "            features_in.loc[:, \"anomaly_score_source\"].values\n",
    "        ],\n",
    "    ).max(axis=0)\n",
    "    features_in.loc[:, \"anom_scores_mean\"] = np.array(\n",
    "        [\n",
    "            features_in.loc[:, \"anomaly_score\"].values, \n",
    "            features_in.loc[:, \"anomaly_score_source\"].values\n",
    "        ],\n",
    "    ).mean(axis=0)\n",
    "    features_in.to_parquet(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7edf80de-4720-4c0a-8d5b-3bfafd0a26c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.7 s, sys: 3.72 s, total: 24.4 s\n",
      "Wall time: 24.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_edge_features(train_features, location_features_edges_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7adbd114-df75-4bca-b697-7fcd08ae36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 2.45 s, total: 16.8 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_edge_features(validation_features, location_features_edges_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40d4fed8-cc76-44e0-809a-5d6ae82539c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 2.33 s, total: 16.8 s\n",
      "Wall time: 16.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_edge_features(test_features, location_features_edges_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f4364bc-eb49-4d03-b85b-8ff293a88fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trx_features(data_in, location):\n",
    "    columns = [\"source\", \"target\", \"source_currency\", \"target_currency\", \"format\", \"amount\", \"is_laundering\"]\n",
    "    \n",
    "    trx_features = data_in.select(*columns).toPandas()\n",
    "    trx_features.loc[:, \"inter_currency\"] = trx_features[\"source_currency\"] != trx_features[\"target_currency\"]\n",
    "\n",
    "    trx_features.to_parquet(location)\n",
    "    del trx_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c783f612-4c76-4ea5-aed2-68eeaec1191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 12.9 s, total: 1min 38s\n",
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "save_trx_features(train, location_train_trx_features)\n",
    "save_trx_features(validation, location_valid_trx_features)\n",
    "save_trx_features(test, location_test_trx_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8e6eaaec-8af4-43d7-8127-a306b855f430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To free up memory for training\n",
    "\n",
    "to_reset = %who_ls\n",
    "to_reset = list(to_reset)\n",
    "to_reset.remove(\"to_keep\")\n",
    "to_reset = set(to_reset) - set(to_keep)\n",
    "for var_to_reset in list(to_reset):\n",
    "    var_to_reset = f\"^{var_to_reset}$\"\n",
    "    %reset_selective -f {var_to_reset}\n",
    "\n",
    "delete_large_vars(globals(), locals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "13c3a17d-14f9-4d34-9103-0c7e2e8c064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(location_features_trx, location_features_edges, location_features):\n",
    "    columns_category = [\"source_currency\", \"target_currency\", \"format\"]\n",
    "    new_types = {column: \"category\" for column in columns_category}\n",
    "    features_input = spark.read.parquet(location_features_edges)\n",
    "    trx_features_input = spark.read.parquet(location_features_trx).withColumn(\n",
    "        \"source_left\", sf.col(\"source\")\n",
    "    ).withColumn(\n",
    "        \"target_left\", sf.col(\"target\")\n",
    "    ).drop(\"source\", \"target\")\n",
    "    features_input = trx_features_input.join(\n",
    "        features_input,\n",
    "        (trx_features_input[\"source_left\"] == features_input[\"source\"]) &\n",
    "        (trx_features_input[\"target_left\"] == features_input[\"target\"]),\n",
    "        how=\"left\"\n",
    "    ).drop(\"source_left\", \"target_left\", \"source\", \"target\")\n",
    "    features_input = features_input.coalesce(1).write.parquet(\"temp-spark.parquet\", mode=\"overwrite\")\n",
    "    features_input = pd.read_parquet(\"temp-spark.parquet\").fillna(0)\n",
    "    for column in features_input.columns:\n",
    "        if features_input[column].dtype == np.float64:\n",
    "            new_types[column] = np.float32\n",
    "    features_input = features_input.astype(new_types)\n",
    "    features_input.to_parquet(location_features)\n",
    "    del features_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96867e2d-ceed-4176-b2f2-cb407c592ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/12 14:09:48 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 45s, sys: 1min 19s, total: 4min 5s\n",
      "Wall time: 9min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "combine_features(location_train_trx_features, location_features_edges_train, location_train_features)\n",
    "combine_features(location_valid_trx_features, location_features_edges_valid, location_valid_features)\n",
    "combine_features(location_test_trx_features, location_features_edges_test, location_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8924af3-4f88-48dc-9e82-ab345e77f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(MULTI_PROC_STAGING_LOCATION, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b6fa53f-6ecf-4210-93c6-9cde1605237c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257.0\n"
     ]
    }
   ],
   "source": [
    "print((time.time() - start) // 60)\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4994538f-cc63-4a41-b494-43d016f0f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_parquet(location_train_features)\n",
    "validation_features = pd.read_parquet(location_valid_features)\n",
    "test_features = pd.read_parquet(location_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2ea56f4-4dba-4cb4-a95e-b8989ca7b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.4 s, sys: 2.82 s, total: 4.22 s\n",
      "Wall time: 6.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "missing_columns = (\n",
    "    (set(train_features.columns).symmetric_difference(validation_features.columns)) |\n",
    "    (set(train_features.columns).symmetric_difference(test_features.columns)) |\n",
    "    (set(test_features.columns).symmetric_difference(validation_features.columns))\n",
    ")\n",
    "for column in missing_columns:\n",
    "    if missing in train_features.columns:\n",
    "        print(f\"Deleting missing column from train: {column}\")\n",
    "        del train_features[column]\n",
    "    if missing in validation_features.columns:\n",
    "        print(f\"Deleting missing column from validation: {column}\")\n",
    "        del validation_features[column]\n",
    "    if missing in test_features.columns:\n",
    "        print(f\"Deleting missing column from test: {column}\")\n",
    "        del test_features[column]\n",
    "\n",
    "train_features_labels = train_features.loc[:, [\"is_laundering\"]].copy(deep=True)\n",
    "del train_features[\"is_laundering\"]\n",
    "\n",
    "validation_features_labels = validation_features.loc[:, [\"is_laundering\"]].copy(deep=True)\n",
    "validation_features = validation_features.loc[:, train_features.columns]\n",
    "\n",
    "test_features_labels = test_features.loc[:, [\"is_laundering\"]].copy(deep=True)\n",
    "test_features = test_features.loc[:, train_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db2dbe51-59bf-4e8e-a132-c4c3121ae717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y, y_):\n",
    "    return 1 - f1_score(y, np.round(y_))\n",
    "\n",
    "\n",
    "def train_model(x, y, x_, y_, cv=False):\n",
    "    if cv:\n",
    "        model = xgb.XGBClassifier(\n",
    "            early_stopping_rounds=20, scale_pos_weight=5,\n",
    "            eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=1, max_depth=6,\n",
    "            colsample_bytree=1, subsample=1, n_estimators=100,\n",
    "            enable_categorical=True,\n",
    "        )\n",
    "    else:\n",
    "        model = xgb.XGBClassifier(\n",
    "            early_stopping_rounds=20, scale_pos_weight=5,\n",
    "            eval_metric=f1_eval, disable_default_eval_metric=True, \n",
    "            num_parallel_tree=1, max_depth=6,\n",
    "            colsample_bytree=1, subsample=1, \n",
    "            n_estimators=500, enable_categorical=True,\n",
    "        )\n",
    "    model.fit(x, y, verbose=not cv, eval_set=[(x_, y_)])\n",
    "    print(f\"Best iteration: {model.best_iteration}\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de1642f1-ce3f-4a20-8b99-f0362047c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-f1_eval:1.00000\n",
      "[1]\tvalidation_0-f1_eval:0.99704\n",
      "[2]\tvalidation_0-f1_eval:0.99704\n",
      "[3]\tvalidation_0-f1_eval:0.99506\n",
      "[4]\tvalidation_0-f1_eval:0.88028\n",
      "[5]\tvalidation_0-f1_eval:0.86268\n",
      "[6]\tvalidation_0-f1_eval:0.86089\n",
      "[7]\tvalidation_0-f1_eval:0.85624\n",
      "[8]\tvalidation_0-f1_eval:0.85533\n",
      "[9]\tvalidation_0-f1_eval:0.85548\n",
      "[10]\tvalidation_0-f1_eval:0.85296\n",
      "[11]\tvalidation_0-f1_eval:0.85227\n",
      "[12]\tvalidation_0-f1_eval:0.84973\n",
      "[13]\tvalidation_0-f1_eval:0.84943\n",
      "[14]\tvalidation_0-f1_eval:0.84867\n",
      "[15]\tvalidation_0-f1_eval:0.84860\n",
      "[16]\tvalidation_0-f1_eval:0.84225\n",
      "[17]\tvalidation_0-f1_eval:0.84151\n",
      "[18]\tvalidation_0-f1_eval:0.84223\n",
      "[19]\tvalidation_0-f1_eval:0.83910\n",
      "[20]\tvalidation_0-f1_eval:0.83820\n",
      "[21]\tvalidation_0-f1_eval:0.83831\n",
      "[22]\tvalidation_0-f1_eval:0.83781\n",
      "[23]\tvalidation_0-f1_eval:0.83766\n",
      "[24]\tvalidation_0-f1_eval:0.83773\n",
      "[25]\tvalidation_0-f1_eval:0.84362\n",
      "[26]\tvalidation_0-f1_eval:0.83802\n",
      "[27]\tvalidation_0-f1_eval:0.83775\n",
      "[28]\tvalidation_0-f1_eval:0.83761\n",
      "[29]\tvalidation_0-f1_eval:0.83753\n",
      "[30]\tvalidation_0-f1_eval:0.83705\n",
      "[31]\tvalidation_0-f1_eval:0.83699\n",
      "[32]\tvalidation_0-f1_eval:0.83688\n",
      "[33]\tvalidation_0-f1_eval:0.83459\n",
      "[34]\tvalidation_0-f1_eval:0.83296\n",
      "[35]\tvalidation_0-f1_eval:0.83309\n",
      "[36]\tvalidation_0-f1_eval:0.83301\n",
      "[37]\tvalidation_0-f1_eval:0.83275\n",
      "[38]\tvalidation_0-f1_eval:0.83264\n",
      "[39]\tvalidation_0-f1_eval:0.83182\n",
      "[40]\tvalidation_0-f1_eval:0.83001\n",
      "[41]\tvalidation_0-f1_eval:0.82884\n",
      "[42]\tvalidation_0-f1_eval:0.82845\n",
      "[43]\tvalidation_0-f1_eval:0.82820\n",
      "[44]\tvalidation_0-f1_eval:0.82695\n",
      "[45]\tvalidation_0-f1_eval:0.82619\n",
      "[46]\tvalidation_0-f1_eval:0.82588\n",
      "[47]\tvalidation_0-f1_eval:0.82612\n",
      "[48]\tvalidation_0-f1_eval:0.82612\n",
      "[49]\tvalidation_0-f1_eval:0.82567\n",
      "[50]\tvalidation_0-f1_eval:0.82605\n",
      "[51]\tvalidation_0-f1_eval:0.82600\n",
      "[52]\tvalidation_0-f1_eval:0.82593\n",
      "[53]\tvalidation_0-f1_eval:0.82407\n",
      "[54]\tvalidation_0-f1_eval:0.82371\n",
      "[55]\tvalidation_0-f1_eval:0.82307\n",
      "[56]\tvalidation_0-f1_eval:0.82270\n",
      "[57]\tvalidation_0-f1_eval:0.82262\n",
      "[58]\tvalidation_0-f1_eval:0.82279\n",
      "[59]\tvalidation_0-f1_eval:0.82234\n",
      "[60]\tvalidation_0-f1_eval:0.82246\n",
      "[61]\tvalidation_0-f1_eval:0.82244\n",
      "[62]\tvalidation_0-f1_eval:0.82218\n",
      "[63]\tvalidation_0-f1_eval:0.82201\n",
      "[64]\tvalidation_0-f1_eval:0.82217\n",
      "[65]\tvalidation_0-f1_eval:0.82205\n",
      "[66]\tvalidation_0-f1_eval:0.82219\n",
      "[67]\tvalidation_0-f1_eval:0.82149\n",
      "[68]\tvalidation_0-f1_eval:0.82126\n",
      "[69]\tvalidation_0-f1_eval:0.82131\n",
      "[70]\tvalidation_0-f1_eval:0.82109\n",
      "[71]\tvalidation_0-f1_eval:0.82104\n",
      "[72]\tvalidation_0-f1_eval:0.82120\n",
      "[73]\tvalidation_0-f1_eval:0.82072\n",
      "[74]\tvalidation_0-f1_eval:0.82035\n",
      "[75]\tvalidation_0-f1_eval:0.81865\n",
      "[76]\tvalidation_0-f1_eval:0.81858\n",
      "[77]\tvalidation_0-f1_eval:0.81886\n",
      "[78]\tvalidation_0-f1_eval:0.81856\n",
      "[79]\tvalidation_0-f1_eval:0.81836\n",
      "[80]\tvalidation_0-f1_eval:0.81828\n",
      "[81]\tvalidation_0-f1_eval:0.81787\n",
      "[82]\tvalidation_0-f1_eval:0.81755\n",
      "[83]\tvalidation_0-f1_eval:0.81766\n",
      "[84]\tvalidation_0-f1_eval:0.81746\n",
      "[85]\tvalidation_0-f1_eval:0.81665\n",
      "[86]\tvalidation_0-f1_eval:0.81642\n",
      "[87]\tvalidation_0-f1_eval:0.81500\n",
      "[88]\tvalidation_0-f1_eval:0.81399\n",
      "[89]\tvalidation_0-f1_eval:0.81367\n",
      "[90]\tvalidation_0-f1_eval:0.81371\n",
      "[91]\tvalidation_0-f1_eval:0.81377\n",
      "[92]\tvalidation_0-f1_eval:0.81369\n",
      "[93]\tvalidation_0-f1_eval:0.81337\n",
      "[94]\tvalidation_0-f1_eval:0.81339\n",
      "[95]\tvalidation_0-f1_eval:0.81385\n",
      "[96]\tvalidation_0-f1_eval:0.81405\n",
      "[97]\tvalidation_0-f1_eval:0.81354\n",
      "[98]\tvalidation_0-f1_eval:0.81348\n",
      "[99]\tvalidation_0-f1_eval:0.81351\n",
      "[100]\tvalidation_0-f1_eval:0.81345\n",
      "[101]\tvalidation_0-f1_eval:0.81319\n",
      "[102]\tvalidation_0-f1_eval:0.81320\n",
      "[103]\tvalidation_0-f1_eval:0.81312\n",
      "[104]\tvalidation_0-f1_eval:0.81328\n",
      "[105]\tvalidation_0-f1_eval:0.81276\n",
      "[106]\tvalidation_0-f1_eval:0.81276\n",
      "[107]\tvalidation_0-f1_eval:0.81239\n",
      "[108]\tvalidation_0-f1_eval:0.81280\n",
      "[109]\tvalidation_0-f1_eval:0.81280\n",
      "[110]\tvalidation_0-f1_eval:0.81271\n",
      "[111]\tvalidation_0-f1_eval:0.81263\n",
      "[112]\tvalidation_0-f1_eval:0.81178\n",
      "[113]\tvalidation_0-f1_eval:0.81185\n",
      "[114]\tvalidation_0-f1_eval:0.81224\n",
      "[115]\tvalidation_0-f1_eval:0.81259\n",
      "[116]\tvalidation_0-f1_eval:0.81260\n",
      "[117]\tvalidation_0-f1_eval:0.81252\n",
      "[118]\tvalidation_0-f1_eval:0.81252\n",
      "[119]\tvalidation_0-f1_eval:0.81256\n",
      "[120]\tvalidation_0-f1_eval:0.81203\n",
      "[121]\tvalidation_0-f1_eval:0.81193\n",
      "[122]\tvalidation_0-f1_eval:0.81204\n",
      "[123]\tvalidation_0-f1_eval:0.81127\n",
      "[124]\tvalidation_0-f1_eval:0.81110\n",
      "[125]\tvalidation_0-f1_eval:0.81098\n",
      "[126]\tvalidation_0-f1_eval:0.81095\n",
      "[127]\tvalidation_0-f1_eval:0.81093\n",
      "[128]\tvalidation_0-f1_eval:0.81085\n",
      "[129]\tvalidation_0-f1_eval:0.81096\n",
      "[130]\tvalidation_0-f1_eval:0.81017\n",
      "[131]\tvalidation_0-f1_eval:0.80985\n",
      "[132]\tvalidation_0-f1_eval:0.80918\n",
      "[133]\tvalidation_0-f1_eval:0.80928\n",
      "[134]\tvalidation_0-f1_eval:0.80939\n",
      "[135]\tvalidation_0-f1_eval:0.80915\n",
      "[136]\tvalidation_0-f1_eval:0.80894\n",
      "[137]\tvalidation_0-f1_eval:0.80890\n",
      "[138]\tvalidation_0-f1_eval:0.80902\n",
      "[139]\tvalidation_0-f1_eval:0.80884\n",
      "[140]\tvalidation_0-f1_eval:0.80903\n",
      "[141]\tvalidation_0-f1_eval:0.80853\n",
      "[142]\tvalidation_0-f1_eval:0.80782\n",
      "[143]\tvalidation_0-f1_eval:0.80792\n",
      "[144]\tvalidation_0-f1_eval:0.80767\n",
      "[145]\tvalidation_0-f1_eval:0.80727\n",
      "[146]\tvalidation_0-f1_eval:0.80718\n",
      "[147]\tvalidation_0-f1_eval:0.80679\n",
      "[148]\tvalidation_0-f1_eval:0.80681\n",
      "[149]\tvalidation_0-f1_eval:0.80673\n",
      "[150]\tvalidation_0-f1_eval:0.80439\n",
      "[151]\tvalidation_0-f1_eval:0.80406\n",
      "[152]\tvalidation_0-f1_eval:0.80414\n",
      "[153]\tvalidation_0-f1_eval:0.80340\n",
      "[154]\tvalidation_0-f1_eval:0.80337\n",
      "[155]\tvalidation_0-f1_eval:0.80334\n",
      "[156]\tvalidation_0-f1_eval:0.80346\n",
      "[157]\tvalidation_0-f1_eval:0.80332\n",
      "[158]\tvalidation_0-f1_eval:0.80331\n",
      "[159]\tvalidation_0-f1_eval:0.80313\n",
      "[160]\tvalidation_0-f1_eval:0.80319\n",
      "[161]\tvalidation_0-f1_eval:0.80344\n",
      "[162]\tvalidation_0-f1_eval:0.80327\n",
      "[163]\tvalidation_0-f1_eval:0.80332\n",
      "[164]\tvalidation_0-f1_eval:0.80308\n",
      "[165]\tvalidation_0-f1_eval:0.80317\n",
      "[166]\tvalidation_0-f1_eval:0.80309\n",
      "[167]\tvalidation_0-f1_eval:0.80297\n",
      "[168]\tvalidation_0-f1_eval:0.80290\n",
      "[169]\tvalidation_0-f1_eval:0.80298\n",
      "[170]\tvalidation_0-f1_eval:0.80297\n",
      "[171]\tvalidation_0-f1_eval:0.80300\n",
      "[172]\tvalidation_0-f1_eval:0.80303\n",
      "[173]\tvalidation_0-f1_eval:0.80320\n",
      "[174]\tvalidation_0-f1_eval:0.80281\n",
      "[175]\tvalidation_0-f1_eval:0.80279\n",
      "[176]\tvalidation_0-f1_eval:0.80267\n",
      "[177]\tvalidation_0-f1_eval:0.80192\n",
      "[178]\tvalidation_0-f1_eval:0.80187\n",
      "[179]\tvalidation_0-f1_eval:0.80106\n",
      "[180]\tvalidation_0-f1_eval:0.80103\n",
      "[181]\tvalidation_0-f1_eval:0.80102\n",
      "[182]\tvalidation_0-f1_eval:0.80101\n",
      "[183]\tvalidation_0-f1_eval:0.80102\n",
      "[184]\tvalidation_0-f1_eval:0.80095\n",
      "[185]\tvalidation_0-f1_eval:0.80082\n",
      "[186]\tvalidation_0-f1_eval:0.80080\n",
      "[187]\tvalidation_0-f1_eval:0.80074\n",
      "[188]\tvalidation_0-f1_eval:0.80073\n",
      "[189]\tvalidation_0-f1_eval:0.80088\n",
      "[190]\tvalidation_0-f1_eval:0.80075\n",
      "[191]\tvalidation_0-f1_eval:0.80076\n",
      "[192]\tvalidation_0-f1_eval:0.80076\n",
      "[193]\tvalidation_0-f1_eval:0.80087\n",
      "[194]\tvalidation_0-f1_eval:0.80101\n",
      "[195]\tvalidation_0-f1_eval:0.80108\n",
      "[196]\tvalidation_0-f1_eval:0.80088\n",
      "[197]\tvalidation_0-f1_eval:0.80099\n",
      "[198]\tvalidation_0-f1_eval:0.80104\n",
      "[199]\tvalidation_0-f1_eval:0.80086\n",
      "[200]\tvalidation_0-f1_eval:0.80083\n",
      "[201]\tvalidation_0-f1_eval:0.80089\n",
      "[202]\tvalidation_0-f1_eval:0.80099\n",
      "[203]\tvalidation_0-f1_eval:0.80086\n",
      "[204]\tvalidation_0-f1_eval:0.80073\n",
      "[205]\tvalidation_0-f1_eval:0.80061\n",
      "[206]\tvalidation_0-f1_eval:0.80062\n",
      "[207]\tvalidation_0-f1_eval:0.80048\n",
      "[208]\tvalidation_0-f1_eval:0.80051\n",
      "[209]\tvalidation_0-f1_eval:0.80051\n",
      "[210]\tvalidation_0-f1_eval:0.80049\n",
      "[211]\tvalidation_0-f1_eval:0.80041\n",
      "[212]\tvalidation_0-f1_eval:0.80048\n",
      "[213]\tvalidation_0-f1_eval:0.80033\n",
      "[214]\tvalidation_0-f1_eval:0.80037\n",
      "[215]\tvalidation_0-f1_eval:0.80037\n",
      "[216]\tvalidation_0-f1_eval:0.80043\n",
      "[217]\tvalidation_0-f1_eval:0.80018\n",
      "[218]\tvalidation_0-f1_eval:0.80019\n",
      "[219]\tvalidation_0-f1_eval:0.80018\n",
      "[220]\tvalidation_0-f1_eval:0.79967\n",
      "[221]\tvalidation_0-f1_eval:0.79958\n",
      "[222]\tvalidation_0-f1_eval:0.79967\n",
      "[223]\tvalidation_0-f1_eval:0.79962\n",
      "[224]\tvalidation_0-f1_eval:0.79969\n",
      "[225]\tvalidation_0-f1_eval:0.79967\n",
      "[226]\tvalidation_0-f1_eval:0.79938\n",
      "[227]\tvalidation_0-f1_eval:0.79929\n",
      "[228]\tvalidation_0-f1_eval:0.79924\n",
      "[229]\tvalidation_0-f1_eval:0.79916\n",
      "[230]\tvalidation_0-f1_eval:0.79878\n",
      "[231]\tvalidation_0-f1_eval:0.79911\n",
      "[232]\tvalidation_0-f1_eval:0.79884\n",
      "[233]\tvalidation_0-f1_eval:0.79902\n",
      "[234]\tvalidation_0-f1_eval:0.79882\n",
      "[235]\tvalidation_0-f1_eval:0.79918\n",
      "[236]\tvalidation_0-f1_eval:0.79921\n",
      "[237]\tvalidation_0-f1_eval:0.79939\n",
      "[238]\tvalidation_0-f1_eval:0.79943\n",
      "[239]\tvalidation_0-f1_eval:0.79954\n",
      "[240]\tvalidation_0-f1_eval:0.79945\n",
      "[241]\tvalidation_0-f1_eval:0.79940\n",
      "[242]\tvalidation_0-f1_eval:0.79940\n",
      "[243]\tvalidation_0-f1_eval:0.79933\n",
      "[244]\tvalidation_0-f1_eval:0.79939\n",
      "[245]\tvalidation_0-f1_eval:0.79936\n",
      "[246]\tvalidation_0-f1_eval:0.79939\n",
      "[247]\tvalidation_0-f1_eval:0.79932\n",
      "[248]\tvalidation_0-f1_eval:0.79908\n",
      "[249]\tvalidation_0-f1_eval:0.79906\n",
      "Best iteration: 230\n",
      "\n",
      "30.35 20.07\n",
      "\n",
      "CPU times: user 1h 8min, sys: 1min 51s, total: 1h 9min 52s\n",
      "Wall time: 16min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = train_model(\n",
    "    train_features, train_features_labels[\"is_laundering\"].values, \n",
    "    validation_features, validation_features_labels[\"is_laundering\"].values,\n",
    ")\n",
    "y_test_predicted = model.predict(test_features)\n",
    "f1_final = f1_score(test_features_labels[\"is_laundering\"], y_test_predicted) * 100\n",
    "print(\n",
    "    round(f1_final, 2),\n",
    "    round(recall_score(test_features_labels[\"is_laundering\"], y_test_predicted) * 100, 2)\n",
    ")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58e178c2-8cf6-4edb-ae31-320420efc8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best iteration: 99\n",
      "\n",
      "29.2 18.98\n",
      "Fold 2\n",
      "Best iteration: 87\n",
      "\n",
      "27.96 18.24\n",
      "Fold 3\n",
      "Best iteration: 93\n",
      "\n",
      "28.54 18.69\n",
      "Fold 4\n",
      "Best iteration: 98\n",
      "\n",
      "28.86 18.87\n",
      "Fold 5\n",
      "Best iteration: 99\n",
      "\n",
      "28.94 18.99\n",
      "CPU times: user 2h 25min 40s, sys: 7min 3s, total: 2h 32min 44s\n",
      "Wall time: 35min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CV_FOLD_PERC = 0.8\n",
    "N_FOLDS = 5\n",
    "\n",
    "f1_scores = []\n",
    "for fold in range(N_FOLDS):\n",
    "    print(\"Fold\", fold + 1)\n",
    "    x_train = train_features.sample(frac=CV_FOLD_PERC)\n",
    "    x_train_labels = x_train.loc[:, []].join(train_features_labels, how=\"left\")\n",
    "    x_validation = validation_features.sample(frac=CV_FOLD_PERC)\n",
    "    x_validation_labels = x_validation.loc[:, []].join(validation_features_labels, how=\"left\")\n",
    "    model = train_model(\n",
    "        x_train, x_train_labels[\"is_laundering\"].values, \n",
    "        x_validation, x_validation_labels[\"is_laundering\"].values,\n",
    "        cv=True\n",
    "    )\n",
    "    y_test_predicted = model.predict(test_features)\n",
    "    f1_cv = f1_score(test_features_labels[\"is_laundering\"], y_test_predicted) * 100\n",
    "    print(\n",
    "        round(f1_cv, 2),\n",
    "        round(recall_score(test_features_labels[\"is_laundering\"], y_test_predicted) * 100, 2)\n",
    "    )\n",
    "    f1_scores.append(f1_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c18819c8-a15e-40da-b154-01c7c52cd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp_best = 24.23\n",
    "gfp_std = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "998bda30-ec09-4839-84b3-bebdbb79bea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP best: 24.23  0.12\n"
     ]
    }
   ],
   "source": [
    "print(f\"GFP best: {gfp_best}  {gfp_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb6bbb2c-8383-43e7-91f2-447c9b013683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30.35 0.43\n"
     ]
    }
   ],
   "source": [
    "print(f\"{round(f1_final, 2)} {round(np.std(f1_scores), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0f8243a3-75d5-46e5-81c7-a5418ec30623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplift of 25.25%\n"
     ]
    }
   ],
   "source": [
    "uplift = round(((f1_final - gfp_best) / gfp_best) * 100, 2)\n",
    "print(f\"Uplift of {uplift}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7c5a8dc-1b84-4e39-bf01-27b6f39959a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.0\n"
     ]
    }
   ],
   "source": [
    "print((time.time() - start) // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777a9ba-c6ba-466b-9f36-1270c2527121",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
