{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.storagelevel import StorageLevel\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import settings as s\n",
    "from common import create_workload_for_multi_proc, get_weights, MULTI_PROC_INPUT, MULTI_PROC_OUTPUT\n",
    "from communities import get_communities_multi_proc\n",
    "from features import get_features_multi_proc, get_edge_features, get_edge_features_multi_proc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90c7f1e2-c0f3-4464-b223-ddd8c6fef69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/07/04 00:02:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "shutil.rmtree(\"artifacts\", ignore_errors=True)\n",
    "\n",
    "config = [\n",
    "    (\"spark.driver.memory\", \"16g\"),\n",
    "    (\"spark.worker.memory\", \"16g\"),\n",
    "    (\"spark.driver.maxResultSize\", \"16g\"),\n",
    "    (\"spark.driver.bindAddress\", \"127.0.0.1\"),\n",
    "    (\"spark.sql.execution.arrow.pyspark.enabled\", \"true\"),\n",
    "]\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"testing\")\n",
    "    .config(conf=SparkConf().setAll(config))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e69899e-e6a0-4f84-a288-737de0dd3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fdc571c-b31c-4970-8f32-a9955cceb8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 7\n",
    "TRAIN_PERC = 0.6\n",
    "VALIDATION_PERC = 0.2\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "NUM_PROCS = 10\n",
    "\n",
    "assert(sum([TRAIN_PERC, VALIDATION_PERC, TEST_PERC]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b07872dd-5cd5-4a39-9c39-76a9ab296961",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_main_features = os.path.join(\"features\", s.OUTPUT_POSTFIX.lstrip(\"-\"))\n",
    "# shutil.rmtree(location_main_features, ignore_errors=True)\n",
    "\n",
    "location_flow_dispense = f\"{location_main_features}{os.sep}flow_dispense.parquet\"\n",
    "location_flow_passthrough = f\"{location_main_features}{os.sep}flow_passthrough.parquet\"\n",
    "location_flow_sink = f\"{location_main_features}{os.sep}flow_sink.parquet\"\n",
    "\n",
    "location_comm_as_source_features = f\"{location_main_features}/comm_as_source_features.parquet\"\n",
    "location_comm_as_target_features = f\"{location_main_features}/comm_as_target_features.parquet\"\n",
    "location_comm_as_passthrough_features = f\"{location_main_features}/comm_as_passthrough_features.parquet\"\n",
    "location_comm_as_passthrough_features_reverse = f\"{location_main_features}/comm_as_passthrough_features_reverse.parquet\"\n",
    "\n",
    "location_features_node_level = f\"{location_main_features}/features_node_level.parquet\"\n",
    "location_features_edges = f\"{location_main_features}/features_edges.parquet\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_main_features)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c35a497-3f7f-498a-8a5a-da1a78d1f3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.parquet(s.STAGED_DATA_LOCATION)\n",
    "data_count_original = data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a26466-f5b0-4fad-ac12-560d5c671b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=========================================>           (155 + 12) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reduced to 90.53%\n",
      "\n",
      "CPU times: user 59.8 s, sys: 1.07 s, total: 1min\n",
      "Wall time: 3min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "KEEP_TOP_N = 100\n",
    "\n",
    "data_agg_weights = get_weights(\n",
    "    data.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        sf.sum(\"amount\").alias(\"amount\")\n",
    "    ).toPandas()\n",
    ")\n",
    "data_agg_weights.sort_values(\"weight\", ascending=False, inplace=True)\n",
    "\n",
    "edges_to_keep = data_agg_weights.groupby(\"source\").head(KEEP_TOP_N).reset_index(drop=True)\n",
    "edges_to_keep.sort_values(\"weight\", ascending=False, inplace=True)\n",
    "edges_to_keep = edges_to_keep.groupby(\"target\").head(KEEP_TOP_N).reset_index(drop=True)\n",
    "edges_to_keep = edges_to_keep.loc[:, [\"source\", \"target\"]].drop_duplicates()\n",
    "edges_to_keep = spark.createDataFrame(edges_to_keep)\n",
    "\n",
    "data_graph = data.join(\n",
    "    edges_to_keep.select(sf.col(\"source\").alias(\"src\"), sf.col(\"target\").alias(\"dst\")),\n",
    "    (sf.col(\"source\") == sf.col(\"src\")) &\n",
    "    (sf.col(\"target\") == sf.col(\"dst\"))\n",
    ").drop(\"src\", \"dst\").persist(StorageLevel.DISK_ONLY)\n",
    "data_count_graph = data_graph.count()\n",
    "reduction = round((data_count_graph / data_count_original) * 100, 2)\n",
    "print(f\"\\nReduced to {reduction}%\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e156f9b4-e083-498d-b2d1-b1c89e44686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dispense\n",
      "passthrough\n",
      "sink\n",
      "CPU times: user 23min 52s, sys: 21.4 s, total: 24min 14s\n",
      "Wall time: 28min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "left = data_graph.select(\"source\", \"target\", \"timestamp\", \"amount\")\n",
    "select = []\n",
    "for column in left.columns:\n",
    "    select.append(sf.col(column).alias(f\"left_{column}\"))\n",
    "left = left.select(*select)\n",
    "right = data_graph.select(\"source\", \"target\", \"timestamp\", \"amount\")\n",
    "\n",
    "flows_temporal = left.join(\n",
    "    right,\n",
    "    (left[\"left_target\"] == right[\"source\"]) &\n",
    "    (left[\"left_timestamp\"] <= right[\"timestamp\"]),\n",
    "    how=\"inner\"\n",
    ").groupby([\"left_source\", \"left_target\", \"source\", \"target\"]).agg(\n",
    "    sf.sum(\"left_amount\").alias(\"left_amount\"),\n",
    "    sf.sum(\"amount\").alias(\"amount\"),\n",
    ").drop(\"left_target\").select(\n",
    "    sf.col(\"left_source\").alias(\"dispense\"),\n",
    "    sf.col(\"source\").alias(\"passthrough\"),\n",
    "    sf.col(\"target\").alias(\"sink\"),\n",
    "    sf.least(\"left_amount\", \"amount\").alias(\"amount\"),\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "flows_temporal.count()\n",
    "flows_temporal = flows_temporal.toPandas()\n",
    "\n",
    "\n",
    "# TODO: This can be made much faster!\n",
    "flow_dispense, flow_passthrough, flow_sink = [], [], []\n",
    "for flow_data, flow_type in [\n",
    "    (flow_dispense, \"dispense\"), (flow_passthrough, \"passthrough\"), (flow_sink, \"sink\")\n",
    "]:\n",
    "    print(flow_type)\n",
    "    prefix = f\"{s.G_FLOW_PREFIX}{flow_type}_\"\n",
    "    for key, group in flows_temporal.groupby(flow_type):\n",
    "        cycle = group[(group[\"dispense\"] == group[\"sink\"]) & (group[\"dispense\"] != group[\"passthrough\"])]\n",
    "        row = {\n",
    "            \"key\": key,\n",
    "            f\"{prefix}amount_sum\": group[\"amount\"].sum(),\n",
    "            f\"{prefix}amount_mean\": group[\"amount\"].mean(),\n",
    "            f\"{prefix}amount_max\": group[\"amount\"].max(),\n",
    "            f\"{prefix}dispense_count\": group[\"dispense\"].nunique(),\n",
    "            f\"{prefix}passthrough_count\": group[\"passthrough\"].nunique(),\n",
    "            f\"{prefix}sink_count\": group[\"sink\"].nunique(),\n",
    "            f\"{prefix}cycle_sum\": cycle[\"amount\"].sum(),\n",
    "            f\"{prefix}cycle_mean\": cycle[\"amount\"].mean(),\n",
    "            f\"{prefix}cycle_max\": cycle[\"amount\"].max(),\n",
    "            f\"{prefix}cycle_passthrough_count\": cycle[\"passthrough\"].nunique(),\n",
    "        }\n",
    "        flow_data.append(row)\n",
    "\n",
    "pd.DataFrame(flow_dispense).set_index(\"key\").to_parquet(location_flow_dispense)\n",
    "pd.DataFrame(flow_passthrough).set_index(\"key\").to_parquet(location_flow_passthrough)\n",
    "pd.DataFrame(flow_sink).set_index(\"key\").to_parquet(location_flow_sink)\n",
    "\n",
    "del flows_temporal\n",
    "del flow_dispense\n",
    "del flow_passthrough\n",
    "del flow_sink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a13395-4873-4612-b464-1e8103b5ff75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179504480\n",
      "CPU times: user 1.78 s, sys: 947 ms, total: 2.73 s\n",
      "Wall time: 16.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "trx_ids_sorted = data.sort(\"timestamp\").select(\"transaction_id\").toPandas()[\"transaction_id\"].values\n",
    "trx_count = len(trx_ids_sorted)\n",
    "print(trx_count)\n",
    "\n",
    "last_train_index = int(np.floor(trx_count * TRAIN_PERC))\n",
    "last_validation_index = last_train_index + int(np.floor(trx_count * VALIDATION_PERC))\n",
    "train_indexes = trx_ids_sorted[:last_train_index]\n",
    "validation_indexes = trx_ids_sorted[last_train_index:last_validation_index]\n",
    "test_indexes = trx_ids_sorted[last_validation_index:]\n",
    "\n",
    "train_indexes = spark.createDataFrame(\n",
    "    pd.DataFrame(train_indexes, columns=[\"transaction_id\"])\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "validation_indexes = spark.createDataFrame(\n",
    "    pd.DataFrame(validation_indexes, columns=[\"transaction_id\"])\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "test_indexes = spark.createDataFrame(\n",
    "    pd.DataFrame(test_indexes, columns=[\"transaction_id\"])\n",
    ").persist(StorageLevel.DISK_ONLY)\n",
    "\n",
    "train = train_indexes.join(\n",
    "    data, on=\"transaction_id\", how=\"left\"\n",
    ")\n",
    "validation = validation_indexes.join(\n",
    "    data, on=\"transaction_id\", how=\"left\"\n",
    ")\n",
    "test = test_indexes.join(\n",
    "    data, on=\"transaction_id\", how=\"left\"\n",
    ")\n",
    "train_validation = train.union(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88213f0e-2497-4f01-b735-f941102e4f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing comm_as_source\n",
      "\n",
      "Processed hop #1 | 6,792,234 | 1,707,738\n",
      "Processed hop #2 | 12,751,288 | 1,513,895\n",
      "Processed hop #3 | 23,531,566 | 1,456,691\n",
      "Processed hop #4 | 32,069,701 | 1,440,156\n",
      "\n",
      "Processing comm_as_target\n",
      "\n",
      "Processed hop #1 | 6,802,442 | 1,352,114\n",
      "Processed hop #2 | 19,753,739 | 1,234,156\n",
      "Processed hop #3 | 35,125,799 | 1,216,266\n",
      "Processed hop #4 | 46,743,035 | 1,207,335\n",
      "\n",
      "Processing comm_as_passthrough\n",
      "\n",
      "Processed hop #1 | 6,279,937 | 1,329,490\n",
      "Processed hop #2 | 11,029,056 | 1,154,274\n",
      "Processed hop #3 | 20,118,081 | 1,109,985\n",
      "Processed hop #4 | 25,603,374 | 1,096,681\n",
      "\n",
      "Processing comm_as_passthrough_reverse\n",
      "\n",
      "Processed hop #1 | 6,669,849 | 1,323,277\n",
      "Processed hop #2 | 19,196,985 | 1,205,401\n",
      "Processed hop #3 | 34,298,330 | 1,187,666\n",
      "Processed hop #4 | 45,818,132 | 1,178,795\n",
      "CPU times: user 2min 39s, sys: 5.06 s, total: 2min 44s\n",
      "Wall time: 2min 45s\n",
      "CPU times: user 2min 19s, sys: 3.49 s, total: 2min 22s\n",
      "Wall time: 2min 22s\n",
      "CPU times: user 2min 3s, sys: 2.24 s, total: 2min 6s\n",
      "Wall time: 2min 5s\n",
      "CPU times: user 2min 16s, sys: 3.07 s, total: 2min 19s\n",
      "Wall time: 2min 19s\n",
      "CPU times: user 30min 6s, sys: 1min 13s, total: 31min 19s\n",
      "Wall time: 32min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_input = data.select(\"*\")\n",
    "nodes_source = set(data.select(\"source\").distinct().toPandas()[\"source\"])\n",
    "nodes_target = set(data.select(\"target\").distinct().toPandas()[\"target\"])\n",
    "nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "%run nested_communities_global.ipynb\n",
    "\n",
    "comm_as_source_features.to_parquet(location_comm_as_source_features)\n",
    "comm_as_target_features.to_parquet(location_comm_as_target_features)\n",
    "comm_as_passthrough_features.to_parquet(location_comm_as_passthrough_features)\n",
    "comm_as_passthrough_features_reverse.to_parquet(location_comm_as_passthrough_features_reverse)\n",
    "\n",
    "del comm_as_source_features\n",
    "del comm_as_target_features\n",
    "del comm_as_passthrough_features\n",
    "del comm_as_passthrough_features_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48961885-70d5-4fd6-bf88-55694f326092",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 s, sys: 4.88 s, total: 20.7 s\n",
      "Wall time: 38.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ts_min = data_graph.select(sf.min(\"timestamp\").alias(\"x\")).collect()[0][\"x\"] - timedelta(minutes=1)\n",
    "data_graph_agg = data_graph.groupby([\"source\", \"target\", \"source_bank\", \"target_bank\", \"source_currency\"]).agg(\n",
    "    sf.count(\"source\").alias(\"num_transactions\"),\n",
    "    sf.sum(\"amount\").alias(\"amount\"),\n",
    "    sf.sum(\"source_amount\").alias(\"source_amount\"),\n",
    "    sf.collect_list(sf.array((sf.col(\"timestamp\") - ts_min).cast(\"long\"), sf.col(\"amount\"))).alias(\"timestamps_amounts\"),\n",
    ")\n",
    "data_graph_agg = data_graph_agg.toPandas()\n",
    "data_graph_agg = data_graph_agg.convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f45f4cf-663d-4fb9-8b90-4064bd2cf3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "%run nested_features_generation.ipynb\n",
    "\n",
    "all_features = all_features.join(\n",
    "    pd.read_parquet(location_comm_as_source_features), how=\"left\", rsuffix=\"_dispense\"\n",
    ").join(\n",
    "    pd.read_parquet(location_comm_as_target_features), how=\"left\", rsuffix=\"_sink\"\n",
    ").join(\n",
    "    pd.read_parquet(location_comm_as_passthrough_features), how=\"left\", rsuffix=\"_passthrough\"\n",
    ").join(\n",
    "    pd.read_parquet(location_comm_as_passthrough_features_reverse), how=\"left\", rsuffix=\"_passthrough_rev\"\n",
    ").join(\n",
    "    pd.read_parquet(location_flow_dispense), how=\"left\"\n",
    ").join(\n",
    "    pd.read_parquet(location_flow_passthrough), how=\"left\"\n",
    ").join(\n",
    "    pd.read_parquet(location_flow_sink), how=\"left\"\n",
    ")\n",
    "\n",
    "all_features.to_parquet(location_features_node_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a41180a-7206-47ee-b292-9b2d7fbc8e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = pd.read_parquet(location_features_node_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b7526b8-de67-4aa9-93b5-352a5bb67d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "anomalies = all_features.loc[:, []]\n",
    "anomalies.loc[:, \"anomaly_score\"] = IsolationForest().fit(\n",
    "    all_features.fillna(0)\n",
    ").decision_function(all_features.fillna(0))\n",
    "anomalies.loc[:, \"anomaly_score\"] += abs(anomalies.loc[:, \"anomaly_score\"].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c04f2ba-88f3-49d0-b6d8-d6266d19dfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.96\n",
      "CPU times: user 26.2 s, sys: 2.6 s, total: 28.8 s\n",
      "Wall time: 6.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "all_features_dim_reduced = pd.DataFrame(\n",
    "    pca.fit_transform(normalize(all_features.fillna(0), norm=\"l1\", axis=1)),\n",
    "    index=all_features.index\n",
    ")\n",
    "print(round(sum(pca.explained_variance_ratio_) * 100, 2))\n",
    "all_features_dim_reduced.columns = [\n",
    "    f\"pca_{x + 1}\" for x in all_features_dim_reduced.columns\n",
    "]\n",
    "del all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747aae1c-6460-4455-b46a-4fe2dec98044",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "to_select = [\"source\", \"target\", \"format\", \"source_currency\", \"source_amount\", \"amount\"]\n",
    "\n",
    "edges_features_input = data.select(to_select).groupby(\n",
    "    [\"source\", \"target\", \"format\", \"source_currency\"]\n",
    ").agg(\n",
    "    sf.sum(\"source_amount\").alias(\"source_amount\"), sf.sum(\"amount\").alias(\"amount\")\n",
    ").toPandas()\n",
    "iterator_chunk_as_pickles, _ = create_workload_for_multi_proc(\n",
    "    edges_features_input[[\"source\", \"target\"]].drop_duplicates().shape[0],\n",
    "    edges_features_input.groupby([\"source\", \"target\"]), \n",
    "    NUM_PROCS, \n",
    "    shuffle=False\n",
    ")\n",
    "edge_features = get_edge_features_multi_proc(iterator_chunk_as_pickles)\n",
    "edge_features.to_parquet(location_features_edges)\n",
    "del edge_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6456cecb-97a0-45c6-bffc-a9db2d004ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_features = pd.read_parquet(location_features_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2884d7dd-1069-4275-b582-66e3604f45db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_edges = train.select(\"source\", \"target\").drop_duplicates().toPandas().set_index(\n",
    "    [\"source\", \"target\"]\n",
    ")\n",
    "valid_edges = validation.select(\"source\", \"target\").drop_duplicates().toPandas().set_index(\n",
    "    [\"source\", \"target\"]\n",
    ")\n",
    "test_edges = test.select(\"source\", \"target\").drop_duplicates().toPandas().set_index(\n",
    "    [\"source\", \"target\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cb4a603e-a2af-41bc-8c10-f71c4bae2e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train_edges.join(\n",
    "    edge_features.set_index([\"source\", \"target\"]), how=\"left\"\n",
    ").reset_index()\n",
    "validation_features = valid_edges.join(\n",
    "    edge_features.set_index([\"source\", \"target\"]), how=\"left\"\n",
    ").reset_index()\n",
    "test_features = test_edges.join(\n",
    "    edge_features.set_index([\"source\", \"target\"]), how=\"left\"\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7edf80de-4720-4c0a-8d5b-3bfafd0a26c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21 s, sys: 3.63 s, total: 24.6 s\n",
      "Wall time: 25.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_features = train_features.set_index(\"target\").join(\n",
    "    anomalies, how=\"left\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    anomalies, how=\"left\", rsuffix=\"_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    all_features_dim_reduced, how=\"left\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    all_features_dim_reduced, how=\"left\", rsuffix=\"_source\"\n",
    ").reset_index()\n",
    "train_features.loc[:, \"anom_scores_diff\"] = train_features.loc[:, \"anomaly_score\"] - train_features.loc[:, \"anomaly_score_source\"]\n",
    "train_features.loc[:, \"anom_scores_min\"] = np.array(\n",
    "    [\n",
    "        train_features.loc[:, \"anomaly_score\"].values, \n",
    "        train_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").min(axis=0)\n",
    "train_features.loc[:, \"anom_scores_max\"] = np.array(\n",
    "    [\n",
    "        train_features.loc[:, \"anomaly_score\"].values, \n",
    "        train_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").max(axis=0)\n",
    "train_features.loc[:, \"anom_scores_mean\"] = np.array(\n",
    "    [\n",
    "        train_features.loc[:, \"anomaly_score\"].values, \n",
    "        train_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").mean(axis=0)\n",
    "train_features.to_parquet(f\"{location_train}/train.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7adbd114-df75-4bca-b697-7fcd08ae36c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 2.29 s, total: 16.3 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "validation_features = validation_features.set_index(\"target\").join(\n",
    "    anomalies, how=\"left\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    anomalies, how=\"left\", rsuffix=\"_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    all_features_dim_reduced, how=\"left\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    all_features_dim_reduced, how=\"left\", rsuffix=\"_source\"\n",
    ").reset_index()\n",
    "validation_features.loc[:, \"anom_scores_diff\"] = validation_features.loc[:, \"anomaly_score\"] - validation_features.loc[:, \"anomaly_score_source\"]\n",
    "validation_features.loc[:, \"anom_scores_min\"] = np.array(\n",
    "    [\n",
    "        validation_features.loc[:, \"anomaly_score\"].values, \n",
    "        validation_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").min(axis=0)\n",
    "validation_features.loc[:, \"anom_scores_max\"] = np.array(\n",
    "    [\n",
    "        validation_features.loc[:, \"anomaly_score\"].values, \n",
    "        validation_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").max(axis=0)\n",
    "validation_features.loc[:, \"anom_scores_mean\"] = np.array(\n",
    "    [\n",
    "        validation_features.loc[:, \"anomaly_score\"].values, \n",
    "        validation_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").mean(axis=0)\n",
    "validation_features.to_parquet(f\"{location_train}/validation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40d4fed8-cc76-44e0-809a-5d6ae82539c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15 s, sys: 2.29 s, total: 17.3 s\n",
      "Wall time: 17.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "test_features = test_features.set_index(\"target\").join(\n",
    "    anomalies, how=\"left\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    anomalies, how=\"left\", rsuffix=\"_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    all_features_dim_reduced, how=\"left\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    all_features_dim_reduced, how=\"left\", rsuffix=\"_source\"\n",
    ").reset_index()\n",
    "test_features.loc[:, \"anom_scores_diff\"] = test_features.loc[:, \"anomaly_score\"] - test_features.loc[:, \"anomaly_score_source\"]\n",
    "test_features.loc[:, \"anom_scores_min\"] = np.array(\n",
    "    [\n",
    "        test_features.loc[:, \"anomaly_score\"].values, \n",
    "        test_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").min(axis=0)\n",
    "test_features.loc[:, \"anom_scores_max\"] = np.array(\n",
    "    [\n",
    "        test_features.loc[:, \"anomaly_score\"].values, \n",
    "        test_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").max(axis=0)\n",
    "test_features.loc[:, \"anom_scores_mean\"] = np.array(\n",
    "    [\n",
    "        test_features.loc[:, \"anomaly_score\"].values, \n",
    "        test_features.loc[:, \"anomaly_score_source\"].values\n",
    "    ],\n",
    ").mean(axis=0)\n",
    "test_features.to_parquet(f\"{location_train}/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c783f612-4c76-4ea5-aed2-68eeaec1191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.8 s, sys: 26.8 s, total: 1min 23s\n",
      "Wall time: 2min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "columns = [\"source\", \"target\", \"source_currency\", \"target_currency\", \"format\", \"amount\", \"is_laundering\"]\n",
    "columns_category = [\"source_currency\", \"target_currency\", \"format\"]\n",
    "train_trx_features = train.select(*columns).toPandas()\n",
    "train_trx_features.loc[:, \"inter_currency\"] = train_trx_features[\"source_currency\"] != train_trx_features[\"target_currency\"]\n",
    "valid_trx_features = validation.select(*columns).toPandas()\n",
    "valid_trx_features.loc[:, \"inter_currency\"] = valid_trx_features[\"source_currency\"] != valid_trx_features[\"target_currency\"]\n",
    "test_trx_features = test.select(*columns).toPandas()\n",
    "test_trx_features.loc[:, \"inter_currency\"] = test_trx_features[\"source_currency\"] != test_trx_features[\"target_currency\"]\n",
    "\n",
    "train_trx_features.to_parquet(f\"{location_train}/train_trx_features\")\n",
    "valid_trx_features.to_parquet(f\"{location_train}/valid_trx_features\")\n",
    "test_trx_features.to_parquet(f\"{location_train}/test_trx_features\")\n",
    "\n",
    "del train_trx_features\n",
    "del valid_trx_features\n",
    "del test_trx_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2c09aa3-08e1-44a9-a8f8-c917e8a52fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trx_features = spark.read.parquet(f\"{location_train}/train_trx_features\")\n",
    "valid_trx_features = spark.read.parquet(f\"{location_train}/valid_trx_features\")\n",
    "test_trx_features = spark.read.parquet(f\"{location_train}/test_trx_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "96867e2d-ceed-4176-b2f2-cb407c592ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21.6 s, sys: 11.9 s, total: 33.6 s\n",
      "Wall time: 1min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "label_columns = [\"source\", \"target\", \"is_laundering\"]\n",
    "new_types = {column: \"category\" for column in columns_category}\n",
    "new_types.update({\"is_laundering\": bool})\n",
    "\n",
    "# train_features = spark.read.parquet(f\"{location_train}/train.parquet\")\n",
    "# train_trx_features = train_trx_features.withColumn(\n",
    "#     \"source_left\", sf.col(\"source\")\n",
    "# ).withColumn(\n",
    "#     \"target_left\", sf.col(\"target\")\n",
    "# ).drop(\"source\", \"target\")\n",
    "# train_features = train_trx_features.join(\n",
    "#     train_features,\n",
    "#     (train_trx_features[\"source_left\"] == train_features[\"source\"]) &\n",
    "#     (train_trx_features[\"target_left\"] == train_features[\"target\"]),\n",
    "#     how=\"left\"\n",
    "# ).drop(\"source_left\", \"target_left\")\n",
    "# train_features = train_features.toPandas()\n",
    "# train_features = train_features.astype(new_types)\n",
    "\n",
    "validation_features = spark.read.parquet(f\"{location_train}/validation.parquet\")\n",
    "valid_trx_features = valid_trx_features.withColumn(\n",
    "    \"source_left\", sf.col(\"source\")\n",
    ").withColumn(\n",
    "    \"target_left\", sf.col(\"target\")\n",
    ").drop(\"source\", \"target\")\n",
    "validation_features = valid_trx_features.join(\n",
    "    validation_features,\n",
    "    (valid_trx_features[\"source_left\"] == validation_features[\"source\"]) &\n",
    "    (valid_trx_features[\"target_left\"] == validation_features[\"target\"]),\n",
    "    how=\"left\"\n",
    ").drop(\"source_left\", \"target_left\")\n",
    "validation_features = validation_features.toPandas()\n",
    "validation_features = validation_features.astype(new_types)\n",
    "\n",
    "test_features = spark.read.parquet(f\"{location_train}/test.parquet\")\n",
    "test_trx_features = test_trx_features.withColumn(\n",
    "    \"source_left\", sf.col(\"source\")\n",
    ").withColumn(\n",
    "    \"target_left\", sf.col(\"target\")\n",
    ").drop(\"source\", \"target\")\n",
    "test_features = test_trx_features.join(\n",
    "    test_features,\n",
    "    (test_trx_features[\"source_left\"] == test_features[\"source\"]) &\n",
    "    (test_trx_features[\"target_left\"] == test_features[\"target\"]),\n",
    "    how=\"left\"\n",
    ").drop(\"source_left\", \"target_left\")\n",
    "test_features = test_features.toPandas()\n",
    "test_features = test_features.astype(new_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2ea56f4-4dba-4cb4-a95e-b8989ca7b917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 8.29 s, total: 18.6 s\n",
      "Wall time: 23.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "label_columns = [\"source\", \"target\", \"is_laundering\"]\n",
    "\n",
    "# TODO: Why is `format_Reinvestment` not in validation/test data\n",
    "# del train_features[\"format_Reinvestment\"]\n",
    "\n",
    "train_features_labels = train_features.loc[:, label_columns].copy(deep=True)\n",
    "del train_features[\"is_laundering\"]\n",
    "del train_features[\"source\"]\n",
    "del train_features[\"target\"]\n",
    "\n",
    "validation_features_labels = validation_features.loc[:, label_columns].copy(deep=True)\n",
    "validation_features = validation_features.loc[:, train_features.columns]\n",
    "\n",
    "test_features_labels = test_features.loc[:, label_columns].copy(deep=True)\n",
    "test_features = test_features.loc[:, train_features.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aafdcaf7-7031-4259-b972-f946ba09cb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y, y_):\n",
    "    return 1 - f1_score(y, np.round(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db2dbe51-59bf-4e8e-a132-c4c3121ae717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For HI\n",
    "# def train_model(x, y, x_, y_):\n",
    "#     model = xgb.XGBClassifier(\n",
    "#         early_stopping_rounds=20, scale_pos_weight=10,\n",
    "#         eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=20, max_depth=6,\n",
    "#         colsample_bytree=0.5, subsample=0.5, enable_categorical=True,\n",
    "#     )\n",
    "#     model.fit(x, y, verbose=False, eval_set=[(x_, y_)])\n",
    "#     print(f\"Best iteration: {model.best_iteration}\\n\")\n",
    "#     return model\n",
    "\n",
    "\n",
    "# For LI\n",
    "def train_model(x, y, x_, y_):\n",
    "    # model = xgb.XGBClassifier(\n",
    "    #     scale_pos_weight=10,\n",
    "    #     eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=20, max_depth=6,\n",
    "    #     colsample_bytree=0.5, subsample=0.5, n_estimators=1000,\n",
    "    #     enable_categorical=True,\n",
    "    # )\n",
    "    model = xgb.XGBClassifier(\n",
    "        early_stopping_rounds=20, scale_pos_weight=5,\n",
    "        eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=1, max_depth=6,\n",
    "        colsample_bytree=1, subsample=1, n_estimators=500,\n",
    "        enable_categorical=True,\n",
    "    )\n",
    "    model.fit(x, y, verbose=True, eval_set=[(x_, y_)])\n",
    "    print(f\"Best iteration: {model.best_iteration}\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de1642f1-ce3f-4a20-8b99-f0362047c8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-f1_eval:0.53664\n",
      "[1]\tvalidation_0-f1_eval:0.51116\n",
      "[2]\tvalidation_0-f1_eval:0.50245\n",
      "[3]\tvalidation_0-f1_eval:0.49714\n",
      "[4]\tvalidation_0-f1_eval:0.49438\n",
      "[5]\tvalidation_0-f1_eval:0.49283\n",
      "[6]\tvalidation_0-f1_eval:0.49157\n",
      "[7]\tvalidation_0-f1_eval:0.49153\n",
      "[8]\tvalidation_0-f1_eval:0.48984\n",
      "[9]\tvalidation_0-f1_eval:0.49019\n",
      "[10]\tvalidation_0-f1_eval:0.48905\n",
      "[11]\tvalidation_0-f1_eval:0.48755\n",
      "[12]\tvalidation_0-f1_eval:0.48613\n",
      "[13]\tvalidation_0-f1_eval:0.48505\n",
      "[14]\tvalidation_0-f1_eval:0.48358\n",
      "[15]\tvalidation_0-f1_eval:0.48341\n",
      "[16]\tvalidation_0-f1_eval:0.48268\n",
      "[17]\tvalidation_0-f1_eval:0.48437\n",
      "[18]\tvalidation_0-f1_eval:0.48031\n",
      "[19]\tvalidation_0-f1_eval:0.47996\n",
      "[20]\tvalidation_0-f1_eval:0.47923\n",
      "[21]\tvalidation_0-f1_eval:0.47921\n",
      "[22]\tvalidation_0-f1_eval:0.47892\n",
      "[23]\tvalidation_0-f1_eval:0.47857\n",
      "[24]\tvalidation_0-f1_eval:0.47760\n",
      "[25]\tvalidation_0-f1_eval:0.47734\n",
      "[26]\tvalidation_0-f1_eval:0.47728\n",
      "[27]\tvalidation_0-f1_eval:0.47691\n",
      "[28]\tvalidation_0-f1_eval:0.47637\n",
      "[29]\tvalidation_0-f1_eval:0.47567\n",
      "[30]\tvalidation_0-f1_eval:0.47464\n",
      "[31]\tvalidation_0-f1_eval:0.47280\n",
      "[32]\tvalidation_0-f1_eval:0.47290\n",
      "[33]\tvalidation_0-f1_eval:0.47277\n",
      "[34]\tvalidation_0-f1_eval:0.47165\n",
      "[35]\tvalidation_0-f1_eval:0.47147\n",
      "[36]\tvalidation_0-f1_eval:0.47134\n",
      "[37]\tvalidation_0-f1_eval:0.47118\n",
      "[38]\tvalidation_0-f1_eval:0.47036\n",
      "[39]\tvalidation_0-f1_eval:0.47020\n",
      "[40]\tvalidation_0-f1_eval:0.46999\n",
      "[41]\tvalidation_0-f1_eval:0.46979\n",
      "[42]\tvalidation_0-f1_eval:0.46847\n",
      "[43]\tvalidation_0-f1_eval:0.46831\n",
      "[44]\tvalidation_0-f1_eval:0.47000\n",
      "[45]\tvalidation_0-f1_eval:0.46759\n",
      "[46]\tvalidation_0-f1_eval:0.46604\n",
      "[47]\tvalidation_0-f1_eval:0.46591\n",
      "[48]\tvalidation_0-f1_eval:0.46537\n",
      "[49]\tvalidation_0-f1_eval:0.46021\n",
      "[50]\tvalidation_0-f1_eval:0.45984\n",
      "[51]\tvalidation_0-f1_eval:0.45954\n",
      "[52]\tvalidation_0-f1_eval:0.45906\n",
      "[53]\tvalidation_0-f1_eval:0.45810\n",
      "[54]\tvalidation_0-f1_eval:0.45786\n",
      "[55]\tvalidation_0-f1_eval:0.45680\n",
      "[56]\tvalidation_0-f1_eval:0.45655\n",
      "[57]\tvalidation_0-f1_eval:0.45593\n",
      "[58]\tvalidation_0-f1_eval:0.45505\n",
      "[59]\tvalidation_0-f1_eval:0.45349\n",
      "[60]\tvalidation_0-f1_eval:0.45265\n",
      "[61]\tvalidation_0-f1_eval:0.45260\n",
      "[62]\tvalidation_0-f1_eval:0.45237\n",
      "[63]\tvalidation_0-f1_eval:0.45228\n",
      "[64]\tvalidation_0-f1_eval:0.45241\n",
      "[65]\tvalidation_0-f1_eval:0.45159\n",
      "[66]\tvalidation_0-f1_eval:0.45013\n",
      "[67]\tvalidation_0-f1_eval:0.44927\n",
      "[68]\tvalidation_0-f1_eval:0.44851\n",
      "[69]\tvalidation_0-f1_eval:0.44859\n",
      "[70]\tvalidation_0-f1_eval:0.44843\n",
      "[71]\tvalidation_0-f1_eval:0.44849\n",
      "[72]\tvalidation_0-f1_eval:0.44852\n",
      "[73]\tvalidation_0-f1_eval:0.44847\n",
      "[74]\tvalidation_0-f1_eval:0.44831\n",
      "[75]\tvalidation_0-f1_eval:0.44827\n",
      "[76]\tvalidation_0-f1_eval:0.44780\n",
      "[77]\tvalidation_0-f1_eval:0.44750\n",
      "[78]\tvalidation_0-f1_eval:0.44723\n",
      "[79]\tvalidation_0-f1_eval:0.44276\n",
      "[80]\tvalidation_0-f1_eval:0.44281\n",
      "[81]\tvalidation_0-f1_eval:0.44261\n",
      "[82]\tvalidation_0-f1_eval:0.44229\n",
      "[83]\tvalidation_0-f1_eval:0.44204\n",
      "[84]\tvalidation_0-f1_eval:0.44159\n",
      "[85]\tvalidation_0-f1_eval:0.44126\n",
      "[86]\tvalidation_0-f1_eval:0.44113\n",
      "[87]\tvalidation_0-f1_eval:0.44070\n",
      "[88]\tvalidation_0-f1_eval:0.44053\n",
      "[89]\tvalidation_0-f1_eval:0.44034\n",
      "[90]\tvalidation_0-f1_eval:0.44021\n",
      "[91]\tvalidation_0-f1_eval:0.44000\n",
      "[92]\tvalidation_0-f1_eval:0.43938\n",
      "[93]\tvalidation_0-f1_eval:0.43946\n",
      "[94]\tvalidation_0-f1_eval:0.43910\n",
      "[95]\tvalidation_0-f1_eval:0.43896\n",
      "[96]\tvalidation_0-f1_eval:0.43891\n",
      "[97]\tvalidation_0-f1_eval:0.43877\n",
      "[98]\tvalidation_0-f1_eval:0.43884\n",
      "[99]\tvalidation_0-f1_eval:0.43896\n",
      "[100]\tvalidation_0-f1_eval:0.43835\n",
      "[101]\tvalidation_0-f1_eval:0.43846\n",
      "[102]\tvalidation_0-f1_eval:0.43796\n",
      "[103]\tvalidation_0-f1_eval:0.43770\n",
      "[104]\tvalidation_0-f1_eval:0.43780\n",
      "[105]\tvalidation_0-f1_eval:0.43779\n",
      "[106]\tvalidation_0-f1_eval:0.43752\n",
      "[107]\tvalidation_0-f1_eval:0.43764\n",
      "[108]\tvalidation_0-f1_eval:0.43767\n",
      "[109]\tvalidation_0-f1_eval:0.43698\n",
      "[110]\tvalidation_0-f1_eval:0.43716\n",
      "[111]\tvalidation_0-f1_eval:0.43722\n",
      "[112]\tvalidation_0-f1_eval:0.43728\n",
      "[113]\tvalidation_0-f1_eval:0.43695\n",
      "[114]\tvalidation_0-f1_eval:0.43692\n",
      "[115]\tvalidation_0-f1_eval:0.43651\n",
      "[116]\tvalidation_0-f1_eval:0.43662\n",
      "[117]\tvalidation_0-f1_eval:0.43684\n",
      "[118]\tvalidation_0-f1_eval:0.43672\n",
      "[119]\tvalidation_0-f1_eval:0.43668\n",
      "[120]\tvalidation_0-f1_eval:0.43657\n",
      "[121]\tvalidation_0-f1_eval:0.43645\n",
      "[122]\tvalidation_0-f1_eval:0.43624\n",
      "[123]\tvalidation_0-f1_eval:0.43599\n",
      "[124]\tvalidation_0-f1_eval:0.43572\n",
      "[125]\tvalidation_0-f1_eval:0.43536\n",
      "[126]\tvalidation_0-f1_eval:0.43523\n",
      "[127]\tvalidation_0-f1_eval:0.43522\n",
      "[128]\tvalidation_0-f1_eval:0.43514\n",
      "[129]\tvalidation_0-f1_eval:0.43517\n",
      "[130]\tvalidation_0-f1_eval:0.43542\n",
      "[131]\tvalidation_0-f1_eval:0.43496\n",
      "[132]\tvalidation_0-f1_eval:0.43481\n",
      "[133]\tvalidation_0-f1_eval:0.43485\n",
      "[134]\tvalidation_0-f1_eval:0.43488\n",
      "[135]\tvalidation_0-f1_eval:0.43490\n",
      "[136]\tvalidation_0-f1_eval:0.43475\n",
      "[137]\tvalidation_0-f1_eval:0.43480\n",
      "[138]\tvalidation_0-f1_eval:0.43482\n",
      "[139]\tvalidation_0-f1_eval:0.43486\n",
      "[140]\tvalidation_0-f1_eval:0.43499\n",
      "[141]\tvalidation_0-f1_eval:0.43434\n",
      "[142]\tvalidation_0-f1_eval:0.43424\n",
      "[143]\tvalidation_0-f1_eval:0.43339\n",
      "[144]\tvalidation_0-f1_eval:0.43331\n",
      "[145]\tvalidation_0-f1_eval:0.43336\n",
      "[146]\tvalidation_0-f1_eval:0.43339\n",
      "[147]\tvalidation_0-f1_eval:0.43339\n",
      "[148]\tvalidation_0-f1_eval:0.43339\n",
      "[149]\tvalidation_0-f1_eval:0.43339\n",
      "[150]\tvalidation_0-f1_eval:0.43327\n",
      "[151]\tvalidation_0-f1_eval:0.43331\n",
      "[152]\tvalidation_0-f1_eval:0.43321\n",
      "[153]\tvalidation_0-f1_eval:0.43294\n",
      "[154]\tvalidation_0-f1_eval:0.43305\n",
      "[155]\tvalidation_0-f1_eval:0.43301\n",
      "[156]\tvalidation_0-f1_eval:0.43300\n",
      "[157]\tvalidation_0-f1_eval:0.43297\n",
      "[158]\tvalidation_0-f1_eval:0.43278\n",
      "[159]\tvalidation_0-f1_eval:0.43278\n",
      "[160]\tvalidation_0-f1_eval:0.43282\n",
      "[161]\tvalidation_0-f1_eval:0.43286\n",
      "[162]\tvalidation_0-f1_eval:0.43292\n",
      "[163]\tvalidation_0-f1_eval:0.43295\n",
      "[164]\tvalidation_0-f1_eval:0.43285\n",
      "[165]\tvalidation_0-f1_eval:0.43277\n",
      "[166]\tvalidation_0-f1_eval:0.43275\n",
      "[167]\tvalidation_0-f1_eval:0.43272\n",
      "[168]\tvalidation_0-f1_eval:0.43264\n",
      "[169]\tvalidation_0-f1_eval:0.43261\n",
      "[170]\tvalidation_0-f1_eval:0.43246\n",
      "[171]\tvalidation_0-f1_eval:0.43248\n",
      "[172]\tvalidation_0-f1_eval:0.43243\n",
      "[173]\tvalidation_0-f1_eval:0.43252\n",
      "[174]\tvalidation_0-f1_eval:0.43253\n",
      "[175]\tvalidation_0-f1_eval:0.43235\n",
      "[176]\tvalidation_0-f1_eval:0.43237\n",
      "[177]\tvalidation_0-f1_eval:0.43238\n",
      "[178]\tvalidation_0-f1_eval:0.43245\n",
      "[179]\tvalidation_0-f1_eval:0.43245\n",
      "[180]\tvalidation_0-f1_eval:0.43234\n",
      "[181]\tvalidation_0-f1_eval:0.43220\n",
      "[182]\tvalidation_0-f1_eval:0.43217\n",
      "[183]\tvalidation_0-f1_eval:0.43218\n",
      "[184]\tvalidation_0-f1_eval:0.43213\n",
      "[185]\tvalidation_0-f1_eval:0.43256\n",
      "[186]\tvalidation_0-f1_eval:0.43225\n",
      "[187]\tvalidation_0-f1_eval:0.43270\n",
      "[188]\tvalidation_0-f1_eval:0.43269\n",
      "[189]\tvalidation_0-f1_eval:0.43254\n",
      "[190]\tvalidation_0-f1_eval:0.43261\n",
      "[191]\tvalidation_0-f1_eval:0.43250\n",
      "[192]\tvalidation_0-f1_eval:0.43240\n",
      "[193]\tvalidation_0-f1_eval:0.43196\n",
      "[194]\tvalidation_0-f1_eval:0.43203\n",
      "[195]\tvalidation_0-f1_eval:0.43201\n",
      "[196]\tvalidation_0-f1_eval:0.43207\n",
      "[197]\tvalidation_0-f1_eval:0.43200\n",
      "[198]\tvalidation_0-f1_eval:0.43085\n",
      "[199]\tvalidation_0-f1_eval:0.43082\n",
      "[200]\tvalidation_0-f1_eval:0.43103\n",
      "[201]\tvalidation_0-f1_eval:0.43093\n",
      "[202]\tvalidation_0-f1_eval:0.43081\n",
      "[203]\tvalidation_0-f1_eval:0.43074\n",
      "[204]\tvalidation_0-f1_eval:0.43070\n",
      "[205]\tvalidation_0-f1_eval:0.43070\n",
      "[206]\tvalidation_0-f1_eval:0.43057\n",
      "[207]\tvalidation_0-f1_eval:0.43052\n",
      "[208]\tvalidation_0-f1_eval:0.43051\n",
      "[209]\tvalidation_0-f1_eval:0.43051\n",
      "[210]\tvalidation_0-f1_eval:0.43041\n",
      "[211]\tvalidation_0-f1_eval:0.43045\n",
      "[212]\tvalidation_0-f1_eval:0.43049\n",
      "[213]\tvalidation_0-f1_eval:0.43047\n",
      "[214]\tvalidation_0-f1_eval:0.43049\n",
      "[215]\tvalidation_0-f1_eval:0.43033\n",
      "[216]\tvalidation_0-f1_eval:0.43048\n",
      "[217]\tvalidation_0-f1_eval:0.43035\n",
      "[218]\tvalidation_0-f1_eval:0.43050\n",
      "[219]\tvalidation_0-f1_eval:0.43049\n",
      "[220]\tvalidation_0-f1_eval:0.43064\n",
      "[221]\tvalidation_0-f1_eval:0.43063\n",
      "[222]\tvalidation_0-f1_eval:0.43068\n",
      "[223]\tvalidation_0-f1_eval:0.43069\n",
      "[224]\tvalidation_0-f1_eval:0.43082\n",
      "[225]\tvalidation_0-f1_eval:0.43066\n",
      "[226]\tvalidation_0-f1_eval:0.43052\n",
      "[227]\tvalidation_0-f1_eval:0.43058\n",
      "[228]\tvalidation_0-f1_eval:0.43063\n",
      "[229]\tvalidation_0-f1_eval:0.43060\n",
      "[230]\tvalidation_0-f1_eval:0.43051\n",
      "[231]\tvalidation_0-f1_eval:0.43056\n",
      "[232]\tvalidation_0-f1_eval:0.43055\n",
      "[233]\tvalidation_0-f1_eval:0.43065\n",
      "[234]\tvalidation_0-f1_eval:0.43073\n",
      "Best iteration: 215\n",
      "\n",
      "aggregated 66.68 57.84\n",
      "\n",
      "CPU times: user 1h 51min 37s, sys: 52min 37s, total: 2h 44min 14s\n",
      "Wall time: 34min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model = train_model(\n",
    "    train_features, train_features_labels[\"is_laundering\"].values, \n",
    "    validation_features, validation_features_labels[\"is_laundering\"].values\n",
    ")\n",
    "y_test_predicted = model.predict(test_features)\n",
    "print(\n",
    "    \"aggregated\",\n",
    "    round(f1_score(test_features_labels[\"is_laundering\"], y_test_predicted) * 100, 2),\n",
    "    round(recall_score(test_features_labels[\"is_laundering\"], y_test_predicted) * 100, 2)\n",
    ")\n",
    "# predictions_data = get_orig_prediction_data(\n",
    "#     test_features_labels, test_labels_orig, y_test_predicted\n",
    "# )\n",
    "# f1_final = round(f1_score(predictions_data[\"is_laundering\"], predictions_data[\"predicted\"]) * 100, 2)\n",
    "# print(\n",
    "#     \"final\",\n",
    "#     f1_final,\n",
    "#     round(recall_score(predictions_data[\"is_laundering\"], predictions_data[\"predicted\"]) * 100, 2)\n",
    "# )\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e178c2-8cf6-4edb-ae31-320420efc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "CV_FOLD_PERC = 0.8\n",
    "N_FOLDS = 5\n",
    "\n",
    "f1_scores = []\n",
    "for fold in range(N_FOLDS):\n",
    "    print(\"Fold\", fold + 1)\n",
    "    x_train = train_features.sample(frac=CV_FOLD_PERC)\n",
    "    x_train_labels = x_train.loc[:, []].join(train_features_labels, how=\"left\")\n",
    "    x_validation = validation_features.sample(frac=CV_FOLD_PERC)\n",
    "    x_validation_labels = x_validation.loc[:, []].join(validation_features_labels, how=\"left\")\n",
    "    model = train_model(\n",
    "        x_train, x_train_labels[\"is_laundering\"].values, \n",
    "        x_validation, x_validation_labels[\"is_laundering\"].values\n",
    "    )\n",
    "    y_test_predicted = model.predict(test_features)\n",
    "    predictions_data = get_orig_prediction_data(\n",
    "        test_features_labels, test_labels_orig, y_test_predicted\n",
    "    )\n",
    "    f1_cv = f1_score(predictions_data[\"is_laundering\"], predictions_data[\"predicted\"]) * 100\n",
    "    print(\n",
    "        round(f1_cv, 2),\n",
    "        round(recall_score(predictions_data[\"is_laundering\"], predictions_data[\"predicted\"]) * 100, 2)\n",
    "    )\n",
    "    f1_scores.append(f1_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6bbb2c-8383-43e7-91f2-447c9b013683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{f1_final} Â±{round(np.std(f1_scores), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c5a8dc-1b84-4e39-bf01-27b6f39959a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((time.time() - start) // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e2b7dc-3e04-4d18-b234-e928bb6b0f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
