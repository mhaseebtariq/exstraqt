{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df0d2cd91ed9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "import settings as s\n",
    "\n",
    "os.environ[\"EXSTRAQT_DATA_TYPE_FOLDER\"] = s.OUTPUT_POSTFIX.lstrip(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a51150-f7c3-4c13-ac56-6c7a1b01b2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert s.FILE_SIZE in (\"Small\", \"Medium\"), \"Script suitable for `small` or `medium` datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf365b0b01f624",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = int(os.environ.get(\"EXSTRAQT_SEED\", 42))\n",
    "print(f\"{SEED=}\")\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "EXSTRAQT_NUM_PROCS = int(os.environ.get(\"EXSTRAQT_NUM_PROCS\", os.cpu_count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5657d454a7a1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_main = os.path.join(\"features\", os.environ[\"EXSTRAQT_DATA_TYPE_FOLDER\"])\n",
    "\n",
    "location_train_features_dm = f\"{location_main}{os.sep}train_dm.bin\"\n",
    "location_valid_features_dm = f\"{location_main}{os.sep}valid_dm.bin\"\n",
    "location_test_features_dm = f\"{location_main}{os.sep}test_dm.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7853fef793861a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda_available = False\n",
    "try:\n",
    "    import torch\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "xgb_args = dict(\n",
    "    seed=SEED,\n",
    "    max_depth=6,\n",
    "    scale_pos_weight=3,\n",
    "    eta=0.3,\n",
    "    subsample=1,\n",
    "    colsample_bytree=0.5,\n",
    "    num_parallel_tree=10,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"aucpr\",\n",
    "    disable_default_eval_metric=True,\n",
    "    nthread=EXSTRAQT_NUM_PROCS,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "if not s.HIGH_ILLICIT:\n",
    "    if s.FILE_SIZE == \"Small\":\n",
    "        xgb_args[\"eta\"] = 0.1\n",
    "    elif s.FILE_SIZE == \"Medium\":\n",
    "        xgb_args[\"eta\"] = 0.2\n",
    "        xgb_args[\"scale_pos_weight\"] = 4\n",
    "    else:\n",
    "        raise Exception(\"Use `training_large` for Large datasets!\")\n",
    "    xgb_args[\"max_depth\"] = 5\n",
    "\n",
    "if cuda_available:\n",
    "    xgb_args[\"device\"] = \"cuda\"\n",
    "    xgb_args[\"nthread\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d979a08-07a6-41b9-8c5d-90e973e8d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "validation_dm = xgb.DMatrix(location_valid_features_dm)\n",
    "\n",
    "models = []\n",
    "all_training_files = glob(f\"{location_train_features_dm}{os.sep}*.bin\") or [location_train_features_dm]\n",
    "for index, fl in enumerate(sorted(all_training_files)):\n",
    "    train_dm = xgb.DMatrix(fl)\n",
    "    model = xgb.train(\n",
    "        xgb_args,\n",
    "        train_dm,\n",
    "        num_boost_round=100,\n",
    "        evals=[(validation_dm, \"validation\")],\n",
    "        verbose_eval=True,\n",
    "        early_stopping_rounds=10,\n",
    "    )\n",
    "    models.append(model)\n",
    "    print(f\"Trained {index + 1} of {len(all_training_files)} | {model.best_iteration=}\")\n",
    "    del train_dm\n",
    "del validation_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e905d-c157-4807-b73b-6fbcb71c650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm = xgb.DMatrix(location_test_features_dm)\n",
    "y_test_predicted = []\n",
    "for model in models:\n",
    "    y_test_predicted.append(model.predict(test_dm, iteration_range=(0, model.best_iteration)))\n",
    "y_test_predicted = np.max(y_test_predicted, axis=0) > 0.5\n",
    "f1_test = f1_score(test_dm.get_label(), y_test_predicted) * 100\n",
    "print(\n",
    "    f\"{SEED=}\",\n",
    "    f\"f1={round(f1_test, 2)}\",\n",
    "    f\"recall={round(recall_score(test_dm.get_label(), y_test_predicted) * 100, 2)}\",\n",
    ")\n",
    "del test_dm\n",
    "print(f1_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
