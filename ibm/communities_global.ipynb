{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from datetime import timedelta, datetime\n",
    "from itertools import combinations\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from pyspark.sql import functions as sf\n",
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from scipy import stats\n",
    "\n",
    "import settings as s\n",
    "from common import create_workload_for_multi_proc\n",
    "from communities import get_communities_multi_proc\n",
    "from features import get_features_multi_proc, pov_features\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7f1e2-c0f3-4464-b223-ddd8c6fef69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = [\n",
    "    (\"spark.driver.memory\", \"16g\"),\n",
    "    (\"spark.worker.memory\", \"16g\"),\n",
    "    (\"spark.driver.maxResultSize\", \"16g\"),\n",
    "]\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"testing\")\n",
    "    .config(conf=SparkConf().setAll(config))\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69899e-e6a0-4f84-a288-737de0dd3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d95e6-ad47-4c78-9da3-4387ea8610cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = (\n",
    "    data_input.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        sf.sum(\"amount\").alias(\"amount\")\n",
    "    )\n",
    ").toPandas()\n",
    "data_agg.loc[:, \"amount\"] = np.ceil(data_agg.loc[:, \"amount\"])\n",
    "data_agg = data_agg.astype({\"amount\": np.uint64})\n",
    "data_agg = data_agg.sort_values(\"amount\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0b0ed-bb7c-46ea-aff8-542335fe9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_sent = data_agg.groupby(\"source\").agg({\"amount\": \"sum\"})[\"amount\"].to_dict()\n",
    "totals_received = data_agg.groupby(\"target\").agg({\"amount\": \"sum\"})[\"amount\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7c627-1d78-4c2b-be10-934c35c05710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_communities(top_n, n_hops, data_input, pov, cp, totals, to_check_in):\n",
    "    if not(0 < n_hops < 11):\n",
    "        raise NotImplementedError\n",
    "    if top_n < 1:\n",
    "        raise ValueError\n",
    "    communities_data = []\n",
    "    n_1 = {}\n",
    "    print(\"Processing hop # 1\")\n",
    "    for node, group in data_input.groupby(pov):\n",
    "        if not set([node]).intersection(to_check_in):\n",
    "            continue\n",
    "        group = group.head(top_n)\n",
    "        n_1[node] = Counter(dict(group.loc[:, [cp, \"amount\"]].values))\n",
    "    communities_data.append(n_1)\n",
    "    for n_hop in range(1, n_hops):\n",
    "        n_minus_1th = communities_data[-1]\n",
    "        print(f\"Processing hop # {n_hop + 1}\")\n",
    "        n_th = {}\n",
    "        for node in n_1.keys():\n",
    "            nth_level = Counter()\n",
    "            reference_amount = totals[node]\n",
    "            for node_n, node_n_amount in n_minus_1th[node].items():\n",
    "                n_1_th = pd.DataFrame(n_1.get(node_n, Counter()).items(), columns=[\"key\", \"amount\"])\n",
    "                n_1_th.loc[:, \"amount\"] = n_1_th.loc[:, \"amount\"].apply(lambda x: min([x, node_n_amount, reference_amount]))\n",
    "                nth_level += Counter(dict(n_1_th.values))\n",
    "            n_th[node] = Counter(dict(nth_level.most_common(top_n)))\n",
    "        communities_data.append(dict(n_th))\n",
    "    return communities_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153c715-8699-4abf-9e1b-99949d37bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing communities_as_source\\n\")\n",
    "communities_as_source = get_communities(50, 4, data_agg, \"source\", \"target\", totals_sent, nodes_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd484ee-cf34-466c-980c-f1d4978a57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing communities_as_target\\n\")\n",
    "communities_as_target = get_communities(50, 4, data_agg, \"target\", \"source\", totals_received, nodes_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aeb50-c10d-47d9-86c1-8d33ace73688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing communities_as_passthrough\\n\")\n",
    "communities_as_passthrough = get_communities(\n",
    "    50, 4, data_agg.loc[data_agg[\"source\"].isin(nodes_passthrough), :], \"source\", \"target\", \n",
    "    totals_received, nodes_passthrough\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed78fd-8a2a-41bd-8908-b73835a59247",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = []\n",
    "for node in nodes_source:\n",
    "    all_nodes = set()\n",
    "    node_comm_stats = {\"key\": node}\n",
    "    for index, communities in enumerate(communities_as_source):\n",
    "        n_hop = index + 1\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = 0\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = 0\n",
    "        if not communities[node]:\n",
    "            continue\n",
    "        nodes_community, amounts_community = zip(*communities[node].items())\n",
    "        if not index:\n",
    "            sum_prev = totals_sent[node]\n",
    "        else:\n",
    "            sum_prev = sum(communities_as_source[index - 1][node].values())\n",
    "        sum_prev = min([totals_sent[node], sum_prev])\n",
    "        amounts_community_adjusted = np.array(amounts_community, dtype=np.float64)\n",
    "        amounts_community_adjusted /= sum_prev\n",
    "        amounts_community_adjusted[amounts_community_adjusted > 1] = 1\n",
    "        sum_this = sum(communities[node].values())\n",
    "        perc_transferred = (sum_this / sum_prev) if sum_prev > sum_this else 1\n",
    "        amounts_community_adjusted *= perc_transferred\n",
    "        number_of_new_accounts = len(set(nodes_community) - all_nodes)\n",
    "        all_nodes = all_nodes.union(nodes_community)\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = len(nodes_community)\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = len(all_nodes)\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = number_of_new_accounts\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = np.max(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = np.mean(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = np.median(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = np.std(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_skew_transferred\"] = stats.skew(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_kurtosis_transferred\"] = stats.kurtosis(amounts_community_adjusted)\n",
    "    communities_as_source_features.append(node_comm_stats)\n",
    "\n",
    "communities_as_source_features = pd.DataFrame(communities_as_source_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec56cd2-0b7f-42b5-a2da-a1a29178cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_target_features = []\n",
    "for node in nodes_target:\n",
    "    all_nodes = set()\n",
    "    node_comm_stats = {\"key\": node}\n",
    "    for index, communities in enumerate(communities_as_target):\n",
    "        n_hop = index + 1\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = 0\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = 0\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = 0\n",
    "        if not communities[node]:\n",
    "            continue\n",
    "        nodes_community, amounts_community = zip(*communities[node].items())\n",
    "        if not index:\n",
    "            sum_prev = totals_received[node]\n",
    "        else:\n",
    "            sum_prev = sum(communities_as_target[index - 1][node].values())\n",
    "        sum_prev = min([totals_received[node], sum_prev])\n",
    "        amounts_community_adjusted = np.array(amounts_community, dtype=np.float64)\n",
    "        amounts_community_adjusted /= sum_prev\n",
    "        amounts_community_adjusted[amounts_community_adjusted > 1] = 1\n",
    "        sum_this = sum(communities[node].values())\n",
    "        perc_transferred = (sum_this / sum_prev) if sum_prev > sum_this else 1\n",
    "        amounts_community_adjusted *= perc_transferred\n",
    "        number_of_new_accounts = len(set(nodes_community) - all_nodes)\n",
    "        all_nodes = all_nodes.union(nodes_community)\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = len(nodes_community)\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = len(all_nodes)\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = number_of_new_accounts\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = np.max(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = np.mean(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = np.median(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = np.std(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_skew_transferred\"] = stats.skew(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_kurtosis_transferred\"] = stats.kurtosis(amounts_community_adjusted)\n",
    "    communities_as_target_features.append(node_comm_stats)\n",
    "\n",
    "communities_as_target_features = pd.DataFrame(communities_as_target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb95904-1c97-4442-9400-82f4980a4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_passthrough_features = []\n",
    "for node in nodes_passthrough:\n",
    "    all_nodes = set()\n",
    "    node_comm_stats = {\"key\": node}\n",
    "    for index, communities in enumerate(communities_as_passthrough):\n",
    "        n_hop = index + 1\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = 0\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = 0\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = 0\n",
    "        if not communities[node]:\n",
    "            continue\n",
    "        nodes_community, amounts_community = zip(*communities[node].items())\n",
    "        if not index:\n",
    "            sum_prev = totals_received[node]\n",
    "        else:\n",
    "            sum_prev = sum(communities_as_passthrough[index - 1][node].values())\n",
    "        sum_prev = min([totals_received[node], sum_prev])\n",
    "        amounts_community_adjusted = np.array(amounts_community, dtype=np.float64)\n",
    "        amounts_community_adjusted /= sum_prev\n",
    "        amounts_community_adjusted[amounts_community_adjusted > 1] = 1\n",
    "        sum_this = sum(communities[node].values())\n",
    "        perc_transferred = (sum_this / sum_prev) if sum_prev > sum_this else 1\n",
    "        amounts_community_adjusted *= perc_transferred\n",
    "        number_of_new_accounts = len(set(nodes_community) - all_nodes)\n",
    "        all_nodes = all_nodes.union(nodes_community)\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = len(nodes_community)\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = len(all_nodes)\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = number_of_new_accounts\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = np.max(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = np.mean(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = np.median(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = np.std(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_skew_transferred\"] = stats.skew(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_kurtosis_transferred\"] = stats.kurtosis(amounts_community_adjusted)\n",
    "    communities_as_passthrough_features.append(node_comm_stats)\n",
    "\n",
    "communities_as_passthrough_features = pd.DataFrame(communities_as_passthrough_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836cd53-b001-481c-ae52-103e5b798531",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features.set_index(\"key\", inplace=True)\n",
    "communities_as_target_features.set_index(\"key\", inplace=True)\n",
    "communities_as_passthrough_features.set_index(\"key\", inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
