{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from glob import glob\n",
    "from datetime import timedelta, datetime\n",
    "from itertools import combinations\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import networkx as nx\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "import settings as s\n",
    "from communities import get_communities_multi_proc\n",
    "from features import get_features_multi_proc\n",
    "from common import create_workload_for_multi_proc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8829f-9248-4077-85a0-954d75dc8f59",
   "metadata": {},
   "source": [
    "Ethereum dataset [15, 82] with 1, 165 accounts labelled as phishing.\n",
    "To enable transaction classification using the ETH Phishing dataset,\n",
    "we label a transaction of this dataset as phishing if its destination\n",
    "account is labelled as phishing. As a result, 0.278% of Ethereum\n",
    "transactions are labelled as phishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b09f78-9b05-478b-ae80-1008c904dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13551303\n",
      "\n",
      "1164\n",
      "\n",
      "CPU times: user 34 s, sys: 1.47 s, total: 35.4 s\n",
      "Wall time: 35.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"./data/MulDiGraph.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "nodes_mapping = {}\n",
    "phishing_nodes = {}\n",
    "for idx, nd in enumerate(nx.nodes(G)):\n",
    "    nodes_mapping[nd] = f\"id-{idx}\"\n",
    "    phishing_nodes[nodes_mapping[nd]] = G.nodes[nd][\"isp\"]\n",
    "\n",
    "rows = []\n",
    "for edge in nx.edges(G):\n",
    "    source, target = edge\n",
    "    attrs = G[source][target][0]\n",
    "    amount, timestamp = attrs[\"amount\"], attrs[\"timestamp\"]\n",
    "    source, target = nodes_mapping[source], nodes_mapping[target]\n",
    "    rows.append(\n",
    "        {\n",
    "            \"source\": source, \n",
    "            \"target\": target,\n",
    "            \"timestamp\": datetime.fromtimestamp(timestamp),\n",
    "            \"amount\": amount, \n",
    "        }\n",
    "    )\n",
    "data = pd.DataFrame(rows)\n",
    "data = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "data.index.name = \"transaction_id\"\n",
    "size_orig = data.shape[0]\n",
    "print(size_orig)\n",
    "print()\n",
    "\n",
    "# Only interested when \"target\" is phishing\n",
    "data.loc[:, \"is_phishing\"] = data.loc[:, \"target\"].apply(lambda x: phishing_nodes[x] == 1)\n",
    "phishing_nodes_filtered = set(data.loc[data[\"is_phishing\"], \"target\"].unique())\n",
    "phishing_nodes_filtered = set(data.loc[data[\"is_phishing\"], \"target\"].unique())\n",
    "phishing_nodes = {k: 1 if {k}.intersection(phishing_nodes_filtered) else 0 for k in phishing_nodes.keys()}\n",
    "print(sum(phishing_nodes.values()))\n",
    "print()\n",
    "\n",
    "data_orig_copy = data.loc[:, [\"source\", \"target\"]].copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b65173d-00cc-4888-b5f1-f63c2a75dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERC = 0.65\n",
    "VALIDATION_PERC = 0.15\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "NUM_PROCS = 10\n",
    "\n",
    "assert(sum([TRAIN_PERC, VALIDATION_PERC, TEST_PERC]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4061ec-a801-4d04-b031-d0b78bc7f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 217 ms, total: 25.6 s\n",
      "Wall time: 25.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "source_firsts = data.groupby(\"source\").agg(first_trx=(\"timestamp\", \"min\"))\n",
    "target_firsts = data.groupby(\"target\").agg(first_trx=(\"timestamp\", \"min\"))\n",
    "active_since = source_firsts.join(target_firsts, lsuffix=\"_left\", how=\"outer\").fillna(datetime.now())\n",
    "active_since.loc[:, \"active_since\"] = active_since.apply(lambda x: min([x[\"first_trx_left\"], x[\"first_trx\"]]), axis=1)\n",
    "active_since = active_since.loc[:, [\"active_since\"]]\n",
    "active_since.sort_values(\"active_since\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d6cfa5-97ac-49fa-be9d-a384b76b84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,932,767 | 446,023 | 594,699\n"
     ]
    }
   ],
   "source": [
    "number_of_train_accounts = int(np.floor(active_since.shape[0] * TRAIN_PERC))\n",
    "number_of_validation_accounts = int(np.floor(active_since.shape[0] * VALIDATION_PERC))\n",
    "train_accounts = set(active_since.head(number_of_train_accounts).index.tolist())\n",
    "assert len(train_accounts) == number_of_train_accounts\n",
    "remaining = active_since.loc[~active_since.index.isin(train_accounts), :].sort_values(\"active_since\")\n",
    "validation_accounts = set(remaining.head(number_of_validation_accounts).index.tolist())\n",
    "assert len(validation_accounts) == number_of_validation_accounts\n",
    "test_accounts = set(active_since.index) - train_accounts - validation_accounts\n",
    "print(f\"{len(train_accounts):,} | {len(validation_accounts):,} | {len(test_accounts):,}\")\n",
    "assert sorted(train_accounts | validation_accounts | test_accounts) == sorted(active_since.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f851d6-4900-473e-96ec-d2f4c052b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5355155 0.4\n"
     ]
    }
   ],
   "source": [
    "data = data.groupby([\"source\", \"target\", \"timestamp\"]).agg(\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    num_transactions=(\"amount\", \"count\"),\n",
    ").reset_index()\n",
    "data = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "data.index.name = \"transaction_id\"\n",
    "size_aggd = data.shape[0]\n",
    "print(size_aggd, round(size_aggd / size_orig, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7240d7ca-c966-4250-8e7d-c39a55230a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 226 ms, total: 19.9 s\n",
      "Wall time: 19.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rates = pd.read_csv(\"data/rates.csv\", sep=\";\")\n",
    "rates.loc[:, \"rate\"] = (rates[\"low\"] + rates[\"high\"]) / 2\n",
    "rates.index = pd.to_datetime(rates[\"timeOpen\"]).dt.date\n",
    "rates = rates[\"rate\"].to_dict()\n",
    "data.loc[:, \"amount_usd\"] = data.apply(lambda x: rates[x[\"timestamp\"].date()] * x[\"amount\"], axis=1)\n",
    "data.loc[:, \"is_zero_transaction\"] = data.loc[:, \"amount\"] == 0\n",
    "\n",
    "data.loc[data[\"amount\"] < 1e-6, \"amount\"] = 1e-6\n",
    "data.loc[data[\"amount_usd\"] < 1e-6, \"amount_usd\"] = 1e-6\n",
    "data = data.astype({\"amount\": np.float32, \"amount_usd\": np.float32})\n",
    "columns = [\n",
    "    \"source\", \"target\", \"timestamp\", \"num_transactions\", \n",
    "    \"amount\", \"amount_usd\", \"is_zero_transaction\",\n",
    "]\n",
    "data = data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72c1d0c-4d69-435e-9979-730536720a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# num_unique = data[\"source\"].nunique()\n",
    "# source_dispensation = []\n",
    "# for index, (_, group) in enumerate(data[[\"source\", \"amount_usd\"]].groupby(\"source\")):\n",
    "#     group.loc[:, \"source_dispensation\"] = group[\"amount_usd\"].cumsum()\n",
    "#     source_dispensation.append(group)\n",
    "#     if not (index % 200_000):\n",
    "#         print(index, num_unique)\n",
    "# source_dispensation = pd.concat(source_dispensation, ignore_index=False)\n",
    "# source_dispensation.to_parquet(\"source_dispensation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705349b5-cee6-4e68-825c-aeec19b4fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dispensation = pd.read_parquet(\"source_dispensation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e3696a-450f-4e84-acf2-590b56b6b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# num_unique = data[\"target\"].nunique()\n",
    "# target_accumulation = []\n",
    "# for index, (_, group) in enumerate(data[[\"target\", \"amount_usd\"]].groupby(\"target\")):\n",
    "#     group.loc[:, \"target_accumulation\"] = group[\"amount_usd\"].cumsum()\n",
    "#     target_accumulation.append(group)\n",
    "#     if not (index % 200_000):\n",
    "#         print(index, num_unique)\n",
    "# target_accumulation = pd.concat(target_accumulation, ignore_index=False)\n",
    "# target_accumulation.to_parquet(\"target_accumulation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5906781c-425b-4e0d-9f58-648cc690afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accumulation = pd.read_parquet(\"target_accumulation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5853016b-d48b-4db7-9f87-a2fa9bea0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = source_dispensation[[\"source_dispensation\"]].join(\n",
    "    target_accumulation[[\"target_accumulation\"]]\n",
    ").join(data)\n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3d99e2-3a2f-4eaf-9564-87d674e78759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.4 s, sys: 5.68 s, total: 59.1 s\n",
      "Wall time: 53.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dispensation_mapping = {}\n",
    "for source, group in data[[\"source\", \"source_dispensation\"]].groupby(\"source\"):\n",
    "    dispensation_mapping[source] = (group.index.tolist(), group[\"source_dispensation\"].tolist())\n",
    "\n",
    "accumulation_mapping = {}\n",
    "for target, group in data[[\"target\", \"target_accumulation\"]].groupby(\"target\"):\n",
    "    accumulation_mapping[target] = (group.index.tolist(), group[\"target_accumulation\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9afe0f-0664-4cd1-b992-39fd30e36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dis_acc_data(node, mapping_dis, mapping_acc, trx_id):\n",
    "    data_dis = mapping_dis.get(node)\n",
    "    if data_dis is None:\n",
    "        data_acc = mapping_acc[node]\n",
    "        index_acc = bisect.bisect_right(data_acc[0], trx_id)\n",
    "        if index_acc:\n",
    "            index_acc -= 1\n",
    "        else:\n",
    "            return 0, 0\n",
    "        return 0, data_acc[1][index_acc]\n",
    "    data_acc = mapping_acc.get(node)\n",
    "    if data_acc is None:\n",
    "        data_dis = mapping_dis[node]\n",
    "        index_dis = bisect.bisect_right(data_dis[0], trx_id)\n",
    "        if index_dis:\n",
    "            index_dis -= 1\n",
    "        else:\n",
    "            return 0, 0\n",
    "        return data_dis[1][index_dis], 0\n",
    "    index_dis = bisect.bisect_right(data_dis[0], trx_id)\n",
    "    index_acc = bisect.bisect_right(data_acc[0], trx_id)\n",
    "    so_far_dispensed = 0\n",
    "    if index_dis:\n",
    "        index_dis -= 1\n",
    "        so_far_dispensed = data_dis[1][index_dis]\n",
    "    so_far_accumulated = 0\n",
    "    if index_acc:\n",
    "        index_acc -= 1\n",
    "        so_far_accumulated = data_acc[1][index_acc]\n",
    "    return so_far_dispensed, so_far_accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff4bc67-9f53-4cbe-aa5e-c581f38dc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_dis_acc_data(row):\n",
    "    return get_dis_acc_data(row[\"source\"], dispensation_mapping, accumulation_mapping, row.name)\n",
    "\n",
    "\n",
    "def target_dis_acc_data(row):\n",
    "    return get_dis_acc_data(row[\"target\"], dispensation_mapping, accumulation_mapping, row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bebde69-b7a9-4caa-990a-7745fb3c5e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.7 s, sys: 562 ms, total: 36.3 s\n",
      "Wall time: 36.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.loc[:, \"dis_acc_source\"] = data.apply(source_dis_acc_data, axis=1)\n",
    "data.loc[:, \"dis_acc_target\"] = data.apply(target_dis_acc_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeba59f1-5aae-4da9-9ea3-be67c834b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, \"source_more_dispensed\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] > x[1]\n",
    ")\n",
    "data.loc[:, \"source_dis_acc_ratio\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] / (x[1] or 1) if x[0] < x[1] else 1\n",
    ")\n",
    "data.loc[:, \"source_acc_dis_ratio\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[1] / (x[0] or 1) if x[1] < x[0] else 1\n",
    ")\n",
    "data.loc[:, \"source_positive_balance\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[1] - x[0] if x[1] > x[0] else 0\n",
    ")\n",
    "data.loc[:, \"source_negative_balance\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] - x[1] if x[0] > x[1] else 0\n",
    ")\n",
    "\n",
    "data.loc[:, \"target_more_dispensed\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] > x[1]\n",
    ")\n",
    "data.loc[:, \"target_dis_acc_ratio\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] / (x[1] or 1) if x[0] < x[1] else 1\n",
    ")\n",
    "data.loc[:, \"target_acc_dis_ratio\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[1] / (x[0] or 1) if x[1] < x[0] else 1\n",
    ")\n",
    "data.loc[:, \"target_positive_balance\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[1] - x[0] if x[1] > x[0] else 0\n",
    ")\n",
    "data.loc[:, \"target_negative_balance\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] - x[1] if x[0] > x[1] else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c394d521-c289-4efa-8840-6688e4068da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"dis_acc_source\"]\n",
    "del data[\"dis_acc_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fbf5a73-c036-4096-9b17-a44a18008824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.5 s, sys: 1.03 s, total: 50.6 s\n",
      "Wall time: 50.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "active_since = active_since[\"active_since\"].to_dict()\n",
    "last_trx_ts = data[\"timestamp\"].max() + timedelta(hours=1)\n",
    "first_trx_ts = data[\"timestamp\"].min() - timedelta(hours=1)\n",
    "active_for = {k : (last_trx_ts - v).total_seconds() for k, v in active_since.items()}\n",
    "\n",
    "data.loc[:, \"source_active_for\"] = data.apply(\n",
    "    lambda x: (x[\"timestamp\"] - active_since[x[\"source\"]]).total_seconds(), axis=1\n",
    ")\n",
    "data.loc[:, \"target_active_for\"] = data.apply(\n",
    "    lambda x: (x[\"timestamp\"] - active_since[x[\"target\"]]).total_seconds(), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "700f3861-70cb-4c01-bb8b-244b53a310b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_types(df):\n",
    "    round_columns = [\n",
    "        \"source_dispensation\",\n",
    "        \"target_accumulation\",\n",
    "        \"amount\",\n",
    "        \"amount_usd\",\n",
    "        \"source_active_for\",\n",
    "        \"target_active_for\",\n",
    "    ]\n",
    "    for col in round_columns:\n",
    "        df.loc[:, col] = np.ceil(df.loc[:, col])\n",
    "    new_types = {\n",
    "        \"source_dispensation\": np.uint64,\n",
    "        \"target_accumulation\": np.uint64,\n",
    "        \"num_transactions\": np.uint16,\n",
    "        \"amount\": np.uint64,\n",
    "        \"amount_usd\": np.uint64,\n",
    "        \"source_dis_acc_ratio\": np.float16,\n",
    "        \"source_acc_dis_ratio\": np.float16,\n",
    "        \"source_positive_balance\": np.uint64,\n",
    "        \"source_negative_balance\": np.uint64,\n",
    "        \"target_dis_acc_ratio\": np.float16,\n",
    "        \"target_acc_dis_ratio\": np.float16,\n",
    "        \"target_positive_balance\": np.uint64,\n",
    "        \"target_negative_balance\": np.uint64,\n",
    "        \"source_active_for\": np.uint32,\n",
    "        \"target_active_for\": np.uint32,\n",
    "    }\n",
    "    return df.astype(new_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7812ddd-d3e7-4cb5-8cd6-de70c57be44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = update_types(data)\n",
    "data.loc[:, \"is_phishing\"] = data.loc[:, \"target\"].apply(lambda x: bool(phishing_nodes[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f309620f-0d51-4c3e-8352-bc432d22f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67 0.06 0.04\n"
     ]
    }
   ],
   "source": [
    "assert data.index.tolist() == list(range(data.shape[0]))\n",
    "\n",
    "train = data.loc[data[\"source\"].isin(train_accounts) & data[\"target\"].isin(train_accounts), :]\n",
    "validation = data.loc[data[\"source\"].isin(validation_accounts) & data[\"target\"].isin(validation_accounts), :]\n",
    "train_validation = data.loc[\n",
    "    data[\"source\"].isin(train_accounts | validation_accounts) & \n",
    "    data[\"target\"].isin(train_accounts | validation_accounts), :\n",
    "]\n",
    "test = data.loc[data[\"source\"].isin(test_accounts) & data[\"target\"].isin(test_accounts), :]\n",
    "print(\n",
    "    round(train.shape[0] / data.shape[0], 2), \n",
    "    round(validation.shape[0] / data.shape[0], 2), \n",
    "    round(test.shape[0] / data.shape[0], 2)\n",
    ")\n",
    "\n",
    "assert set(train.index).intersection(validation.index) == set()\n",
    "assert set(validation.index).intersection(test.index) == set()\n",
    "assert set(train.index).intersection(test.index) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a735041b-db89-4692-9fa2-e5f65aa377cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 354 308 1164\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(train_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len(validation_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len(test_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len([x for x, y in phishing_nodes.items() if y == 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f2e353-a0a1-462f-8979-63d6e9a23936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trx_features(df, source_target):\n",
    "    trx_feats = df.groupby(source_target).agg({\n",
    "        \"source_dispensation\": [\"max\"],\n",
    "        \"target_accumulation\": [\"max\"],\n",
    "        \"amount_usd\": [\"mean\", \"median\", \"max\", \"std\"],  # skew, kurtosis ?\n",
    "        \"num_transactions\": [\"sum\", \"count\"],\n",
    "        \"is_zero_transaction\": [\"sum\"],\n",
    "        \"source_dis_acc_ratio\": [\"mean\", \"std\"],\n",
    "        \"source_acc_dis_ratio\": [\"mean\", \"std\"],    \n",
    "        \"target_dis_acc_ratio\": [\"mean\", \"std\"],\n",
    "        \"target_acc_dis_ratio\": [\"mean\", \"std\"],\n",
    "        \"source_positive_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"source_negative_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"target_positive_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"target_negative_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"source_active_for\": [\"max\", \"std\"],\n",
    "        \"target_active_for\": [\"max\", \"std\"],\n",
    "    })\n",
    "    trx_feats.columns = [f\"trx_feats_{source_target}_{col}_{stat}\" for col, stat in trx_feats.columns]\n",
    "    trx_feats.index.name = \"key\"\n",
    "    return trx_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7cd2c4d-15eb-4513-b1fd-69a4d19c63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.2 s, sys: 1.79 s, total: 17 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_trx_features = get_trx_features(train, \"source\").join(\n",
    "    get_trx_features(train, \"target\"), how=\"outer\"\n",
    ")\n",
    "validation_trx_features = get_trx_features(train_validation, \"source\").join(\n",
    "    get_trx_features(train_validation, \"target\"), how=\"outer\"\n",
    ")\n",
    "test_trx_features = get_trx_features(data, \"source\").join(\n",
    "    get_trx_features(data, \"target\"), how=\"outer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e69899e-e6a0-4f84-a288-737de0dd3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca4b9b1-73fa-446d-81ea-223a18127df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(location_main_features, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebc24179-d5c2-4cf0-afdf-e8b5a105c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_main_features = \"features\"\n",
    "location_train = f\"{location_main_features}{os.sep}train{os.sep}\"\n",
    "location_validation = f\"{location_main_features}{os.sep}validation{os.sep}\"\n",
    "location_test = f\"{location_main_features}{os.sep}test{os.sep}\"\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_main_features)\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04a2d293-9d6c-4310-9d4f-8a77513393cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing communities_as_source\n",
      "\n",
      "Processed hop #1 | 2,731,722 | 1,317,135\n",
      "Processed hop #2 | 19,331,689 | 717,007\n",
      "Processed hop #3 | 19,170,949 | 593,559\n",
      "Processed hop #4 | 22,535,755 | 590,463\n",
      "Processing communities_as_target\n",
      "\n",
      "Processed hop #1 | 1,133,184 | 803,740\n",
      "Processed hop #2 | 25,956,156 | 796,967\n",
      "Processed hop #3 | 24,870,974 | 778,478\n",
      "Processed hop #4 | 35,492,511 | 774,624\n",
      "Processing communities_as_passthrough\n",
      "\n",
      "Processed hop #1 | 910,130 | 188,108\n",
      "Processed hop #2 | 3,653,972 | 132,093\n",
      "Processed hop #3 | 3,791,310 | 112,810\n",
      "Processed hop #4 | 4,441,974 | 111,536\n",
      "CPU times: user 13min 22s, sys: 1min 23s, total: 14min 46s\n",
      "Wall time: 15min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_agg = (\n",
    "    train.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        amount=(\"amount_usd\", \"sum\")\n",
    "    )\n",
    ").reset_index()\n",
    "nodes_source = set(train[\"source\"].unique())\n",
    "nodes_target = set(train[\"target\"].unique())\n",
    "nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "%run communities_global.ipynb\n",
    "\n",
    "communities_as_source_features.to_parquet(f\"{location_main_features}/train_communities_as_source_features.parquet\")\n",
    "communities_as_target_features.to_parquet(f\"{location_main_features}/train_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features.to_parquet(f\"{location_main_features}/train_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "136b2723-26e6-4967-91c5-2e892861c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = pd.read_parquet(f\"{location_main_features}/train_communities_as_source_features.parquet\")\n",
    "communities_as_target_features = pd.read_parquet(f\"{location_main_features}/train_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features = pd.read_parquet(f\"{location_main_features}/train_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f45f4cf-663d-4fb9-8b90-4064bd2cf3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 91 9033324\n",
      "CPU times: user 4min 16s, sys: 1min 10s, total: 5min 26s\n",
      "Wall time: 2h 10min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_train)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = train.copy(deep=True)\n",
    "in_scope_nodes = list(set(train[\"source\"].unique()).union(train[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "train.set_index(\"target\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    train_trx_features, how=\"left\", rsuffix=\"_trx_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    train_trx_features, how=\"left\", rsuffix=\"_trx_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_source\"\n",
    ").reset_index().to_parquet(f\"{location_train}data.parquet\")\n",
    "\n",
    "del train_trx_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3bd18b44-0534-471a-a230-81bfb36c0f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing communities_as_source\n",
      "\n",
      "Processed hop #1 | 357,609 | 178,569\n",
      "Processed hop #2 | 1,081,137 | 87,342\n",
      "Processed hop #3 | 740,762 | 77,555\n",
      "Processed hop #4 | 646,741 | 76,702\n",
      "Processing communities_as_target\n",
      "\n",
      "Processed hop #1 | 67,761 | 29,249\n",
      "Processed hop #2 | 766,632 | 25,546\n",
      "Processed hop #3 | 269,533 | 18,632\n",
      "Processed hop #4 | 756,821 | 18,336\n",
      "Processing communities_as_passthrough\n",
      "\n",
      "Processed hop #1 | 31,536 | 5,519\n",
      "Processed hop #2 | 66,064 | 3,346\n",
      "Processed hop #3 | 54,074 | 2,543\n",
      "Processed hop #4 | 67,521 | 2,285\n",
      "CPU times: user 32.7 s, sys: 4.35 s, total: 37.1 s\n",
      "Wall time: 45.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_agg = (\n",
    "    train_validation.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        amount=(\"amount_usd\", \"sum\")\n",
    "    )\n",
    ").reset_index()\n",
    "nodes_source = set(validation[\"source\"].unique())\n",
    "nodes_target = set(validation[\"target\"].unique())\n",
    "nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "%run communities_global.ipynb\n",
    "\n",
    "communities_as_source_features.to_parquet(f\"{location_main_features}/valid_communities_as_source_features.parquet\")\n",
    "communities_as_target_features.to_parquet(f\"{location_main_features}/valid_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features.to_parquet(f\"{location_main_features}/valid_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4621686-9dc1-46bb-8592-fd80d201a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = pd.read_parquet(f\"{location_main_features}/valid_communities_as_source_features.parquet\")\n",
    "communities_as_target_features = pd.read_parquet(f\"{location_main_features}/valid_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features = pd.read_parquet(f\"{location_main_features}/valid_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bd3defa4-a869-41ee-ac8b-107b5a5bb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 92 912230\n",
      "CPU times: user 3min 24s, sys: 13.4 s, total: 3min 37s\n",
      "Wall time: 31min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_validation)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = train_validation.copy(deep=True)\n",
    "in_scope_nodes = list(set(validation[\"source\"].unique()).union(validation[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "validation.set_index(\"target\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    validation_trx_features, how=\"left\", rsuffix=\"_trx_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    validation_trx_features, how=\"left\", rsuffix=\"_trx_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_source\"\n",
    ").reset_index().to_parquet(f\"{location_validation}data.parquet\")\n",
    "\n",
    "del validation_trx_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a529df6-b86d-4aed-92dd-c3e6bca09a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing communities_as_source\n",
      "\n",
      "Processed hop #1 | 229,905 | 146,344\n",
      "Processed hop #2 | 2,156,008 | 86,402\n",
      "Processed hop #3 | 816,499 | 77,163\n",
      "Processed hop #4 | 1,834,126 | 74,966\n",
      "Processing communities_as_target\n",
      "\n",
      "Processed hop #1 | 92,315 | 44,292\n",
      "Processed hop #2 | 1,611,384 | 42,234\n",
      "Processed hop #3 | 490,965 | 40,678\n",
      "Processed hop #4 | 1,655,175 | 40,446\n",
      "Processing communities_as_passthrough\n",
      "\n",
      "Processed hop #1 | 31,946 | 7,629\n",
      "Processed hop #2 | 237,115 | 6,589\n",
      "Processed hop #3 | 95,876 | 5,946\n",
      "Processed hop #4 | 230,346 | 5,333\n",
      "CPU times: user 42.6 s, sys: 1.44 s, total: 44.1 s\n",
      "Wall time: 44.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data_agg = (\n",
    "    data.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        amount=(\"amount_usd\", \"sum\")\n",
    "    )\n",
    ").reset_index()\n",
    "nodes_source = set(test[\"source\"].unique())\n",
    "nodes_target = set(test[\"target\"].unique())\n",
    "nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "%run communities_global.ipynb\n",
    "\n",
    "communities_as_source_features.to_parquet(f\"{location_main_features}/test_communities_as_source_features.parquet\")\n",
    "communities_as_target_features.to_parquet(f\"{location_main_features}/test_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features.to_parquet(f\"{location_main_features}/test_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "442e5869-4516-4f12-9088-2c2d8ad95f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = pd.read_parquet(f\"{location_main_features}/test_communities_as_source_features.parquet\")\n",
    "communities_as_target_features = pd.read_parquet(f\"{location_main_features}/test_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features = pd.read_parquet(f\"{location_main_features}/test_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f1b67ba-00e0-48f3-bc9a-e917a789a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 84 789229\n",
      "CPU times: user 4min 7s, sys: 15 s, total: 4min 22s\n",
      "Wall time: 34min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_test)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = data.copy(deep=True)\n",
    "in_scope_nodes = list(set(test[\"source\"].unique()).union(test[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "test.set_index(\"target\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    test_trx_features, how=\"left\", rsuffix=\"_trx_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    test_trx_features, how=\"left\", rsuffix=\"_trx_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_source\"\n",
    ").reset_index().to_parquet(f\"{location_test}data.parquet\")\n",
    "\n",
    "del test_trx_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c1d6ed1b-8c5d-45b6-8ec7-17557a4ebb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213.0\n"
     ]
    }
   ],
   "source": [
    "print((time.time() - start) // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dbf8d36-22b4-4974-9bc9-90b29063b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y, y_):\n",
    "    return 1 - f1_score(y, np.round(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1acea125-9e50-4802-955c-658c506e5a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x, y, x_, y_):\n",
    "    model = xgb.XGBClassifier(\n",
    "        early_stopping_rounds=20, scale_pos_weight=10,\n",
    "        eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=15,\n",
    "        colsample_bytree=0.5, subsample=0.5, max_depth=6,\n",
    "    )\n",
    "    model.fit(x, y, verbose=False, eval_set=[(x_, y_)])\n",
    "    print(f\"Best iteration: {model.best_iteration}\\n\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c9c6375-7b12-4daf-a48d-aeb96caed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 15\n",
      "\n",
      "F1 68.62\n",
      "Recall 59.2\n",
      "\n",
      "F1 64.11\n",
      "Recall 54.54\n",
      "\n",
      "CPU times: user 34min 19s, sys: 11.9 s, total: 34min 31s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "label_columns = [\"source\", \"target\", \"timestamp\", \"is_phishing\"]\n",
    "\n",
    "train_features = pd.read_parquet(f\"{location_train}data.parquet\")\n",
    "train_features_labels = train_features.loc[:, label_columns]\n",
    "for col in label_columns:\n",
    "    del train_features[col]\n",
    "\n",
    "validation_features = pd.read_parquet(f\"{location_validation}data.parquet\")\n",
    "validation_features_labels = validation_features.loc[:, label_columns]\n",
    "for col in label_columns:\n",
    "    del validation_features[col]\n",
    "\n",
    "test_features = pd.read_parquet(f\"{location_test}data.parquet\")\n",
    "test_features_labels = test_features.loc[:, label_columns]\n",
    "for col in label_columns:\n",
    "    del test_features[col]\n",
    "\n",
    "model = train_model(\n",
    "    train_features, train_features_labels[\"is_phishing\"].values,\n",
    "    validation_features, validation_features_labels[\"is_phishing\"].values\n",
    ")\n",
    "\n",
    "y_test_predicted = model.predict(test_features)\n",
    "print(\"F1\", round(f1_score(test_features_labels[\"is_phishing\"], y_test_predicted) * 100, 2))\n",
    "print(\"Recall\", round(recall_score(test_features_labels[\"is_phishing\"], y_test_predicted) * 100, 2))\n",
    "\n",
    "test_features_labels.loc[:, \"predicted\"] = y_test_predicted\n",
    "test_labels_orig = test_features_labels.set_index([\"source\", \"target\"]).join(\n",
    "    data_orig_copy.set_index([\"source\", \"target\"]), how=\"inner\"\n",
    ").reset_index()\n",
    "\n",
    "print()\n",
    "f1_final = round(f1_score(test_labels_orig[\"is_phishing\"], test_labels_orig[\"predicted\"]) * 100, 2)\n",
    "print(\"F1\", f1_final)\n",
    "print(\"Recall\", round(recall_score(test_labels_orig[\"is_phishing\"], test_labels_orig[\"predicted\"]) * 100, 2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a35cc2b6-f14c-418d-b406-853fcabf5578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Best iteration: 22\n",
      "\n",
      "63.12 52.04\n",
      "Fold 2\n",
      "Best iteration: 26\n",
      "\n",
      "62.47 52.29\n",
      "Fold 3\n",
      "Best iteration: 20\n",
      "\n",
      "64.11 54.18\n",
      "Fold 4\n",
      "Best iteration: 23\n",
      "\n",
      "62.04 51.53\n",
      "Fold 5\n",
      "Best iteration: 15\n",
      "\n",
      "64.25 54.59\n",
      "CPU times: user 3h 6min 21s, sys: 1min 23s, total: 3h 7min 45s\n",
      "Wall time: 21min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "CV_FOLD_PERC = 0.8\n",
    "N_FOLDS = 5\n",
    "\n",
    "f1_scores = []\n",
    "for fold in range(N_FOLDS):\n",
    "    print(\"Fold\", fold + 1)\n",
    "    x_train = train_features.sample(frac=CV_FOLD_PERC)\n",
    "    x_train_labels = x_train.loc[:, []].join(train_features_labels, how=\"left\")\n",
    "    x_validation = validation_features.sample(frac=CV_FOLD_PERC)\n",
    "    x_validation_labels = x_validation.loc[:, []].join(validation_features_labels, how=\"left\")\n",
    "    model = train_model(\n",
    "        x_train, x_train_labels[\"is_phishing\"].values, \n",
    "        x_validation, x_validation_labels[\"is_phishing\"].values\n",
    "    )\n",
    "    y_test_predicted = model.predict(test_features)\n",
    "    test_features_labels.loc[:, \"predicted\"] = y_test_predicted\n",
    "    test_labels_orig = test_features_labels.set_index([\"source\", \"target\"]).join(\n",
    "        data_orig_copy.set_index([\"source\", \"target\"]), how=\"inner\"\n",
    "    ).reset_index()\n",
    "    f1_cv = f1_score(test_labels_orig[\"is_phishing\"], test_labels_orig[\"predicted\"]) * 100\n",
    "    print(\n",
    "        round(f1_cv, 2),\n",
    "        round(recall_score(test_labels_orig[\"is_phishing\"], test_labels_orig[\"predicted\"]) * 100, 2)\n",
    "    )\n",
    "    f1_scores.append(f1_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24d2ce78-5748-4c74-8a4e-6a0a63181742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.11 ±0.87\n"
     ]
    }
   ],
   "source": [
    "print(f\"{f1_final} ±{round(np.std(f1_scores), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f0bbd-b00a-498e-bb97-44f08fd52914",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
