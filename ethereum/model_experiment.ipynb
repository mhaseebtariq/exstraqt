{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from glob import glob\n",
    "from datetime import timedelta, datetime\n",
    "from itertools import combinations\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import networkx as nx\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "import settings as s\n",
    "from communities import get_communities_multi_proc\n",
    "from features import get_features_multi_proc, pov_features\n",
    "from common import create_workload_for_multi_proc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d8829f-9248-4077-85a0-954d75dc8f59",
   "metadata": {},
   "source": [
    "Ethereum dataset [15, 82] with 1, 165 accounts labelled as phishing.\n",
    "To enable transaction classification using the ETH Phishing dataset,\n",
    "we label a transaction of this dataset as phishing if its destination\n",
    "account is labelled as phishing. As a result, 0.278% of Ethereum\n",
    "transactions are labelled as phishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b09f78-9b05-478b-ae80-1008c904dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13551303\n",
      "\n",
      "1164\n",
      "\n",
      "CPU times: user 33.4 s, sys: 1.41 s, total: 34.8 s\n",
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"./data/MulDiGraph.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "nodes_mapping = {}\n",
    "phishing_nodes = {}\n",
    "for idx, nd in enumerate(nx.nodes(G)):\n",
    "    nodes_mapping[nd] = f\"id-{idx}\"\n",
    "    phishing_nodes[nodes_mapping[nd]] = G.nodes[nd][\"isp\"]\n",
    "\n",
    "rows = []\n",
    "for edge in nx.edges(G):\n",
    "    source, target = edge\n",
    "    attrs = G[source][target][0]\n",
    "    amount, timestamp = attrs[\"amount\"], attrs[\"timestamp\"]\n",
    "    source, target = nodes_mapping[source], nodes_mapping[target]\n",
    "    rows.append(\n",
    "        {\n",
    "            \"source\": source, \n",
    "            \"target\": target,\n",
    "            \"timestamp\": datetime.fromtimestamp(timestamp),\n",
    "            \"amount\": amount, \n",
    "        }\n",
    "    )\n",
    "data = pd.DataFrame(rows)\n",
    "data = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "data.index.name = \"transaction_id\"\n",
    "size_orig = data.shape[0]\n",
    "print(size_orig)\n",
    "print()\n",
    "\n",
    "# Only interested when \"target\" is phishing\n",
    "data.loc[:, \"is_phishing\"] = data.loc[:, \"target\"].apply(lambda x: phishing_nodes[x] == 1)\n",
    "phishing_nodes_filtered = set(data.loc[data[\"is_phishing\"], \"target\"].unique())\n",
    "phishing_nodes_filtered = set(data.loc[data[\"is_phishing\"], \"target\"].unique())\n",
    "phishing_nodes = {k: 1 if {k}.intersection(phishing_nodes_filtered) else 0 for k in phishing_nodes.keys()}\n",
    "print(sum(phishing_nodes.values()))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b65173d-00cc-4888-b5f1-f63c2a75dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERC = 0.65\n",
    "VALIDATION_PERC = 0.15\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "NUM_PROCS = 10\n",
    "\n",
    "assert(sum([TRAIN_PERC, VALIDATION_PERC, TEST_PERC]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4061ec-a801-4d04-b031-d0b78bc7f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.1 s, sys: 213 ms, total: 25.3 s\n",
      "Wall time: 25.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "source_firsts = data.groupby(\"source\").agg(first_trx=(\"timestamp\", \"min\"))\n",
    "target_firsts = data.groupby(\"target\").agg(first_trx=(\"timestamp\", \"min\"))\n",
    "active_since = source_firsts.join(target_firsts, lsuffix=\"_left\", how=\"outer\").fillna(datetime.now())\n",
    "active_since.loc[:, \"active_since\"] = active_since.apply(lambda x: min([x[\"first_trx_left\"], x[\"first_trx\"]]), axis=1)\n",
    "active_since = active_since.loc[:, [\"active_since\"]]\n",
    "active_since.sort_values(\"active_since\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d6cfa5-97ac-49fa-be9d-a384b76b84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,932,767 | 446,023 | 594,699\n"
     ]
    }
   ],
   "source": [
    "number_of_train_accounts = int(np.floor(active_since.shape[0] * TRAIN_PERC))\n",
    "number_of_validation_accounts = int(np.floor(active_since.shape[0] * VALIDATION_PERC))\n",
    "train_accounts = set(active_since.head(number_of_train_accounts).index.tolist())\n",
    "assert len(train_accounts) == number_of_train_accounts\n",
    "remaining = active_since.loc[~active_since.index.isin(train_accounts), :].sort_values(\"active_since\")\n",
    "validation_accounts = set(remaining.head(number_of_validation_accounts).index.tolist())\n",
    "assert len(validation_accounts) == number_of_validation_accounts\n",
    "test_accounts = set(active_since.index) - train_accounts - validation_accounts\n",
    "print(f\"{len(train_accounts):,} | {len(validation_accounts):,} | {len(test_accounts):,}\")\n",
    "assert sorted(train_accounts | validation_accounts | test_accounts) == sorted(active_since.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f851d6-4900-473e-96ec-d2f4c052b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5355155 0.4\n"
     ]
    }
   ],
   "source": [
    "data = data.groupby([\"source\", \"target\", \"timestamp\"]).agg(\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    num_transactions=(\"amount\", \"count\"),\n",
    ").reset_index()\n",
    "data = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "data.index.name = \"transaction_id\"\n",
    "size_aggd = data.shape[0]\n",
    "print(size_aggd, round(size_aggd / size_orig, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7240d7ca-c966-4250-8e7d-c39a55230a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.4 s, sys: 226 ms, total: 19.7 s\n",
      "Wall time: 19.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rates = pd.read_csv(\"data/rates.csv\", sep=\";\")\n",
    "rates.loc[:, \"rate\"] = (rates[\"low\"] + rates[\"high\"]) / 2\n",
    "rates.index = pd.to_datetime(rates[\"timeOpen\"]).dt.date\n",
    "rates = rates[\"rate\"].to_dict()\n",
    "data.loc[:, \"amount_usd\"] = data.apply(lambda x: rates[x[\"timestamp\"].date()] * x[\"amount\"], axis=1)\n",
    "data.loc[:, \"is_zero_transaction\"] = data.loc[:, \"amount\"] == 0\n",
    "\n",
    "data.loc[data[\"amount\"] < 1e-6, \"amount\"] = 1e-6\n",
    "data.loc[data[\"amount_usd\"] < 1e-6, \"amount_usd\"] = 1e-6\n",
    "data = data.astype({\"amount\": np.float32, \"amount_usd\": np.float32})\n",
    "columns = [\n",
    "    \"source\", \"target\", \"timestamp\", \"num_transactions\", \n",
    "    \"amount\", \"amount_usd\", \"is_zero_transaction\",\n",
    "]\n",
    "data = data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72c1d0c-4d69-435e-9979-730536720a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# num_unique = data[\"source\"].nunique()\n",
    "# source_dispensation = []\n",
    "# for index, (_, group) in enumerate(data[[\"source\", \"amount_usd\"]].groupby(\"source\")):\n",
    "#     group.loc[:, \"source_dispensation\"] = group[\"amount_usd\"].cumsum()\n",
    "#     source_dispensation.append(group)\n",
    "#     if not (index % 200_000):\n",
    "#         print(index, num_unique)\n",
    "# source_dispensation = pd.concat(source_dispensation, ignore_index=False)\n",
    "# source_dispensation.to_parquet(\"source_dispensation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "705349b5-cee6-4e68-825c-aeec19b4fcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dispensation = pd.read_parquet(\"source_dispensation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1e3696a-450f-4e84-acf2-590b56b6b12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# num_unique = data[\"target\"].nunique()\n",
    "# target_accumulation = []\n",
    "# for index, (_, group) in enumerate(data[[\"target\", \"amount_usd\"]].groupby(\"target\")):\n",
    "#     group.loc[:, \"target_accumulation\"] = group[\"amount_usd\"].cumsum()\n",
    "#     target_accumulation.append(group)\n",
    "#     if not (index % 200_000):\n",
    "#         print(index, num_unique)\n",
    "# target_accumulation = pd.concat(target_accumulation, ignore_index=False)\n",
    "# target_accumulation.to_parquet(\"target_accumulation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5906781c-425b-4e0d-9f58-648cc690afe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accumulation = pd.read_parquet(\"target_accumulation.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5853016b-d48b-4db7-9f87-a2fa9bea0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = source_dispensation[[\"source_dispensation\"]].join(\n",
    "    target_accumulation[[\"target_accumulation\"]]\n",
    ").join(data)\n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c3d99e2-3a2f-4eaf-9564-87d674e78759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.1 s, sys: 4.88 s, total: 58 s\n",
      "Wall time: 53.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dispensation_mapping = {}\n",
    "for source, group in data[[\"source\", \"source_dispensation\"]].groupby(\"source\"):\n",
    "    dispensation_mapping[source] = (group.index.tolist(), group[\"source_dispensation\"].tolist())\n",
    "\n",
    "accumulation_mapping = {}\n",
    "for target, group in data[[\"target\", \"target_accumulation\"]].groupby(\"target\"):\n",
    "    accumulation_mapping[target] = (group.index.tolist(), group[\"target_accumulation\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b9afe0f-0664-4cd1-b992-39fd30e36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dis_acc_data(node, mapping_dis, mapping_acc, trx_id):\n",
    "    data_dis = mapping_dis.get(node)\n",
    "    if data_dis is None:\n",
    "        data_acc = mapping_acc[node]\n",
    "        index_acc = bisect.bisect_right(data_acc[0], trx_id)\n",
    "        if index_acc:\n",
    "            index_acc -= 1\n",
    "        else:\n",
    "            return 0, 0\n",
    "        return 0, data_acc[1][index_acc]\n",
    "    data_acc = mapping_acc.get(node)\n",
    "    if data_acc is None:\n",
    "        data_dis = mapping_dis[node]\n",
    "        index_dis = bisect.bisect_right(data_dis[0], trx_id)\n",
    "        if index_dis:\n",
    "            index_dis -= 1\n",
    "        else:\n",
    "            return 0, 0\n",
    "        return data_dis[1][index_dis], 0\n",
    "    index_dis = bisect.bisect_right(data_dis[0], trx_id)\n",
    "    index_acc = bisect.bisect_right(data_acc[0], trx_id)\n",
    "    so_far_dispensed = 0\n",
    "    if index_dis:\n",
    "        index_dis -= 1\n",
    "        so_far_dispensed = data_dis[1][index_dis]\n",
    "    so_far_accumulated = 0\n",
    "    if index_acc:\n",
    "        index_acc -= 1\n",
    "        so_far_accumulated = data_acc[1][index_acc]\n",
    "    return so_far_dispensed, so_far_accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff4bc67-9f53-4cbe-aa5e-c581f38dc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_dis_acc_data(row):\n",
    "    return get_dis_acc_data(row[\"source\"], dispensation_mapping, accumulation_mapping, row.name)\n",
    "\n",
    "\n",
    "def target_dis_acc_data(row):\n",
    "    return get_dis_acc_data(row[\"target\"], dispensation_mapping, accumulation_mapping, row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6bebde69-b7a9-4caa-990a-7745fb3c5e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36 s, sys: 518 ms, total: 36.5 s\n",
      "Wall time: 36.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.loc[:, \"dis_acc_source\"] = data.apply(source_dis_acc_data, axis=1)\n",
    "data.loc[:, \"dis_acc_target\"] = data.apply(target_dis_acc_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aeba59f1-5aae-4da9-9ea3-be67c834b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, \"source_more_dispensed\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] > x[1]\n",
    ")\n",
    "data.loc[:, \"source_dis_acc_ratio\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] / (x[1] or 1) if x[0] < x[1] else 1\n",
    ")\n",
    "data.loc[:, \"source_acc_dis_ratio\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[1] / (x[0] or 1) if x[1] < x[0] else 1\n",
    ")\n",
    "data.loc[:, \"source_positive_balance\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[1] - x[0] if x[1] > x[0] else 0\n",
    ")\n",
    "data.loc[:, \"source_negative_balance\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] - x[1] if x[0] > x[1] else 0\n",
    ")\n",
    "\n",
    "data.loc[:, \"target_more_dispensed\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] > x[1]\n",
    ")\n",
    "data.loc[:, \"target_dis_acc_ratio\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] / (x[1] or 1) if x[0] < x[1] else 1\n",
    ")\n",
    "data.loc[:, \"target_acc_dis_ratio\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[1] / (x[0] or 1) if x[1] < x[0] else 1\n",
    ")\n",
    "data.loc[:, \"target_positive_balance\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[1] - x[0] if x[1] > x[0] else 0\n",
    ")\n",
    "data.loc[:, \"target_negative_balance\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] - x[1] if x[0] > x[1] else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c394d521-c289-4efa-8840-6688e4068da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"dis_acc_source\"]\n",
    "del data[\"dis_acc_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6fbf5a73-c036-4096-9b17-a44a18008824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.1 s, sys: 998 ms, total: 50.1 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "active_since = active_since[\"active_since\"].to_dict()\n",
    "last_trx_ts = data[\"timestamp\"].max() + timedelta(hours=1)\n",
    "first_trx_ts = data[\"timestamp\"].min() - timedelta(hours=1)\n",
    "active_for = {k : (last_trx_ts - v).total_seconds() for k, v in active_since.items()}\n",
    "\n",
    "data.loc[:, \"source_active_for\"] = data.apply(\n",
    "    lambda x: (x[\"timestamp\"] - active_since[x[\"source\"]]).total_seconds(), axis=1\n",
    ")\n",
    "data.loc[:, \"target_active_for\"] = data.apply(\n",
    "    lambda x: (x[\"timestamp\"] - active_since[x[\"target\"]]).total_seconds(), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "700f3861-70cb-4c01-bb8b-244b53a310b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_types(df):\n",
    "    round_columns = [\n",
    "        \"source_dispensation\",\n",
    "        \"target_accumulation\",\n",
    "        \"amount\",\n",
    "        \"amount_usd\",\n",
    "        \"source_active_for\",\n",
    "        \"target_active_for\",\n",
    "    ]\n",
    "    for col in round_columns:\n",
    "        df.loc[:, col] = np.ceil(df.loc[:, col])\n",
    "    new_types = {\n",
    "        \"source_dispensation\": np.uint64,\n",
    "        \"target_accumulation\": np.uint64,\n",
    "        \"num_transactions\": np.uint16,\n",
    "        \"amount\": np.uint64,\n",
    "        \"amount_usd\": np.uint64,\n",
    "        \"source_dis_acc_ratio\": np.float16,\n",
    "        \"source_acc_dis_ratio\": np.float16,\n",
    "        \"source_positive_balance\": np.uint64,\n",
    "        \"source_negative_balance\": np.uint64,\n",
    "        \"target_dis_acc_ratio\": np.float16,\n",
    "        \"target_acc_dis_ratio\": np.float16,\n",
    "        \"target_positive_balance\": np.uint64,\n",
    "        \"target_negative_balance\": np.uint64,\n",
    "        \"source_active_for\": np.uint32,\n",
    "        \"target_active_for\": np.uint32,\n",
    "    }\n",
    "    return df.astype(new_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d7812ddd-d3e7-4cb5-8cd6-de70c57be44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = update_types(data)\n",
    "data.loc[:, \"is_phishing\"] = data.loc[:, \"target\"].apply(lambda x: bool(phishing_nodes[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f309620f-0d51-4c3e-8352-bc432d22f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67 0.06 0.04\n"
     ]
    }
   ],
   "source": [
    "assert data.index.tolist() == list(range(data.shape[0]))\n",
    "\n",
    "train = data.loc[data[\"source\"].isin(train_accounts) & data[\"target\"].isin(train_accounts), :]\n",
    "validation = data.loc[data[\"source\"].isin(validation_accounts) & data[\"target\"].isin(validation_accounts), :]\n",
    "train_validation = data.loc[\n",
    "    data[\"source\"].isin(train_accounts | validation_accounts) & \n",
    "    data[\"target\"].isin(train_accounts | validation_accounts), :\n",
    "]\n",
    "test = data.loc[data[\"source\"].isin(test_accounts) & data[\"target\"].isin(test_accounts), :]\n",
    "print(\n",
    "    round(train.shape[0] / data.shape[0], 2), \n",
    "    round(validation.shape[0] / data.shape[0], 2), \n",
    "    round(test.shape[0] / data.shape[0], 2)\n",
    ")\n",
    "\n",
    "assert set(train.index).intersection(validation.index) == set()\n",
    "assert set(validation.index).intersection(test.index) == set()\n",
    "assert set(train.index).intersection(test.index) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a735041b-db89-4692-9fa2-e5f65aa377cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 354 308 1164\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(train_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len(validation_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len(test_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len([x for x, y in phishing_nodes.items() if y == 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f2e353-a0a1-462f-8979-63d6e9a23936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trx_features(df, source_target):\n",
    "    trx_feats = df.groupby(source_target).agg({\n",
    "        \"source_dispensation\": [\"max\"],\n",
    "        \"target_accumulation\": [\"max\"],\n",
    "        \"amount_usd\": [\"mean\", \"median\", \"max\", \"std\"],  # skew, kurtosis ?\n",
    "        \"num_transactions\": [\"sum\", \"count\"],\n",
    "        \"is_zero_transaction\": [\"sum\"],\n",
    "        \"source_dis_acc_ratio\": [\"mean\", \"std\"],\n",
    "        \"source_acc_dis_ratio\": [\"mean\", \"std\"],    \n",
    "        \"target_dis_acc_ratio\": [\"mean\", \"std\"],\n",
    "        \"target_acc_dis_ratio\": [\"mean\", \"std\"],\n",
    "        \"source_positive_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"source_negative_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"target_positive_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"target_negative_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"source_active_for\": [\"max\", \"std\"],\n",
    "        \"target_active_for\": [\"max\", \"std\"],\n",
    "    })\n",
    "    trx_feats.columns = [f\"trx_feats_{source_target}_{col}_{stat}\" for col, stat in trx_feats.columns]\n",
    "    trx_feats.index.name = \"key\"\n",
    "    return trx_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7cd2c4d-15eb-4513-b1fd-69a4d19c63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.3 s, sys: 1.67 s, total: 17 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_trx_features = get_trx_features(train, \"source\").join(\n",
    "    get_trx_features(train, \"target\"), how=\"outer\"\n",
    ")\n",
    "validation_trx_features = get_trx_features(train_validation, \"source\").join(\n",
    "    get_trx_features(train_validation, \"target\"), how=\"outer\"\n",
    ")\n",
    "test_trx_features = get_trx_features(data, \"source\").join(\n",
    "    get_trx_features(data, \"target\"), how=\"outer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e69899e-e6a0-4f84-a288-737de0dd3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ebc24179-d5c2-4cf0-afdf-e8b5a105c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_main_features = \"features\"\n",
    "\n",
    "location_train = f\"{location_main_features}{os.sep}train{os.sep}\"\n",
    "location_validation = f\"{location_main_features}{os.sep}validation{os.sep}\"\n",
    "location_test = f\"{location_main_features}{os.sep}test{os.sep}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04a2d293-9d6c-4310-9d4f-8a77513393cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# data_agg = (\n",
    "#     train.groupby([\"source\", \"target\"])\n",
    "#     .agg(\n",
    "#         amount=(\"amount_usd\", \"sum\")\n",
    "#     )\n",
    "# ).reset_index()\n",
    "# nodes_source = set(train[\"source\"].unique())\n",
    "# nodes_target = set(train[\"target\"].unique())\n",
    "# nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "# %run communities_global.ipynb\n",
    "\n",
    "# new_types = {}\n",
    "# for k, v in communities_as_source_features.dtypes.to_dict().items():\n",
    "#     if v == np.int64:\n",
    "#         new_types[k] = np.uint8\n",
    "#     elif v == np.float64:\n",
    "#         new_types[k] = np.float16\n",
    "#     else:\n",
    "#         raise \n",
    "\n",
    "# communities_as_source_features = communities_as_source_features.astype(new_types)\n",
    "# communities_as_target_features = communities_as_target_features.astype(new_types)\n",
    "# communities_as_passthrough_features = communities_as_passthrough_features.astype(new_types)\n",
    "\n",
    "# communities_as_source_features.to_parquet(f\"{location_main_features}/train_communities_as_source_features.parquet\")\n",
    "# communities_as_target_features.to_parquet(f\"{location_main_features}/train_communities_as_target_features.parquet\")\n",
    "# communities_as_passthrough_features.to_parquet(f\"{location_main_features}/train_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "136b2723-26e6-4967-91c5-2e892861c4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = pd.read_parquet(f\"{location_main_features}/train_communities_as_source_features.parquet\")\n",
    "communities_as_target_features = pd.read_parquet(f\"{location_main_features}/train_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features = pd.read_parquet(f\"{location_main_features}/train_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dca4b9b1-73fa-446d-81ea-223a18127df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(location_main_features, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f45f4cf-663d-4fb9-8b90-4064bd2cf3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 74 9220511\n",
      "0 194\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_train)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = train.copy(deep=True)\n",
    "in_scope_nodes = list(set(train[\"source\"].unique()).union(train[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "train.set_index(\"target\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    train_trx_features, how=\"left\", rsuffix=\"_trx_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    train_trx_features, how=\"left\", rsuffix=\"_trx_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_source\"\n",
    ").reset_index().to_parquet(f\"{location_train}data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd18b44-0534-471a-a230-81bfb36c0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# data_agg = (\n",
    "#     train_validation.groupby([\"source\", \"target\"])\n",
    "#     .agg(\n",
    "#         amount=(\"amount_usd\", \"sum\")\n",
    "#     )\n",
    "# ).reset_index()\n",
    "# nodes_source = set(validation[\"source\"].unique())\n",
    "# nodes_target = set(validation[\"target\"].unique())\n",
    "# nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "# %run communities_global.ipynb\n",
    "\n",
    "# new_types = {}\n",
    "# for k, v in communities_as_source_features.dtypes.to_dict().items():\n",
    "#     if v == np.int64:\n",
    "#         new_types[k] = np.uint8\n",
    "#     elif v == np.float64:\n",
    "#         new_types[k] = np.float16\n",
    "#     else:\n",
    "#         raise \n",
    "\n",
    "# communities_as_source_features = communities_as_source_features.astype(new_types)\n",
    "# communities_as_target_features = communities_as_target_features.astype(new_types)\n",
    "# communities_as_passthrough_features = communities_as_passthrough_features.astype(new_types)\n",
    "\n",
    "# communities_as_source_features.to_parquet(f\"{location_main_features}/valid_communities_as_source_features.parquet\")\n",
    "# communities_as_target_features.to_parquet(f\"{location_main_features}/valid_communities_as_target_features.parquet\")\n",
    "# communities_as_passthrough_features.to_parquet(f\"{location_main_features}/valid_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4621686-9dc1-46bb-8592-fd80d201a4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = pd.read_parquet(f\"{location_main_features}/valid_communities_as_source_features.parquet\")\n",
    "communities_as_target_features = pd.read_parquet(f\"{location_main_features}/valid_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features = pd.read_parquet(f\"{location_main_features}/valid_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3defa4-a869-41ee-ac8b-107b5a5bb82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_validation)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = train_validation.copy(deep=True)\n",
    "in_scope_nodes = list(set(validation[\"source\"].unique()).union(validation[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "validation.set_index(\"target\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    validation_trx_features, how=\"left\", rsuffix=\"_trx_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    validation_trx_features, how=\"left\", rsuffix=\"_trx_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_source\"\n",
    ").reset_index().to_parquet(f\"{location_validation}data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a529df6-b86d-4aed-92dd-c3e6bca09a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# data_agg = (\n",
    "#     data.groupby([\"source\", \"target\"])\n",
    "#     .agg(\n",
    "#         amount=(\"amount_usd\", \"sum\")\n",
    "#     )\n",
    "# ).reset_index()\n",
    "# nodes_source = set(test[\"source\"].unique())\n",
    "# nodes_target = set(test[\"target\"].unique())\n",
    "# nodes_passthrough = nodes_source.intersection(nodes_target)\n",
    "\n",
    "# %run communities_global.ipynb\n",
    "\n",
    "# new_types = {}\n",
    "# for k, v in communities_as_source_features.dtypes.to_dict().items():\n",
    "#     if v == np.int64:\n",
    "#         new_types[k] = np.uint8\n",
    "#     elif v == np.float64:\n",
    "#         new_types[k] = np.float16\n",
    "#     else:\n",
    "#         raise \n",
    "\n",
    "# communities_as_source_features = communities_as_source_features.astype(new_types)\n",
    "# communities_as_target_features = communities_as_target_features.astype(new_types)\n",
    "# communities_as_passthrough_features = communities_as_passthrough_features.astype(new_types)\n",
    "\n",
    "# communities_as_source_features.to_parquet(f\"{location_main_features}/test_communities_as_source_features.parquet\")\n",
    "# communities_as_target_features.to_parquet(f\"{location_main_features}/test_communities_as_target_features.parquet\")\n",
    "# communities_as_passthrough_features.to_parquet(f\"{location_main_features}/test_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442e5869-4516-4f12-9088-2c2d8ad95f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = pd.read_parquet(f\"{location_main_features}/test_communities_as_source_features.parquet\")\n",
    "communities_as_target_features = pd.read_parquet(f\"{location_main_features}/test_communities_as_target_features.parquet\")\n",
    "communities_as_passthrough_features = pd.read_parquet(f\"{location_main_features}/test_communities_as_passthrough_features.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b67ba-00e0-48f3-bc9a-e917a789a3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_test)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = data.copy(deep=True)\n",
    "in_scope_nodes = list(set(test[\"source\"].unique()).union(test[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "test.set_index(\"target\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_source_features, how=\"left\", rsuffix=\"_sf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_target_features, how=\"left\", rsuffix=\"_tf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    communities_as_passthrough_features, how=\"left\", rsuffix=\"_pf_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    test_trx_features, how=\"left\", rsuffix=\"_trx_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    test_trx_features, how=\"left\", rsuffix=\"_trx_source\"\n",
    ").reset_index().set_index(\"target\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_target\"\n",
    ").reset_index().set_index(\"source\").join(\n",
    "    features_all.set_index(\"key\"), how=\"left\", rsuffix=\"_gf_source\"\n",
    ").reset_index().to_parquet(f\"{location_test}data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d6ed1b-8c5d-45b6-8ec7-17557a4ebb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((time.time() - start) // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbf8d36-22b4-4974-9bc9-90b29063b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval(y, y_):\n",
    "    return 1 - f1_score(y, np.round(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9c6375-7b12-4daf-a48d-aeb96caed993",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "label_columns = [\"source\", \"target\", \"timestamp\", \"is_phishing\"]\n",
    "\n",
    "train_features = pd.read_parquet(f\"{location_train}data.parquet\")\n",
    "train_features_labels = train_features.loc[:, label_columns]\n",
    "for col in label_columns:\n",
    "    del train_features[col]\n",
    "\n",
    "validation_features = pd.read_parquet(f\"{location_validation}data.parquet\")\n",
    "validation_features_labels = validation_features.loc[:, label_columns]\n",
    "for col in label_columns:\n",
    "    del validation_features[col]\n",
    "\n",
    "test_features = pd.read_parquet(f\"{location_test}data.parquet\")\n",
    "test_features_labels = test_features.loc[:, label_columns]\n",
    "for col in label_columns:\n",
    "    del test_features[col]\n",
    "\n",
    "# scale_pos_weight = int(train_features_labels.shape[0] / (train_features_labels[\"is_phishing\"].sum() or 1))\n",
    "scale_pos_weight = 10\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    early_stopping_rounds=20, scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=10,\n",
    "    colsample_bytree=0.5, subsample=0.5, max_depth=6,\n",
    ")\n",
    "model.fit(\n",
    "    train_features, train_features_labels[\"is_phishing\"].values, verbose=False,\n",
    "    eval_set=[\n",
    "        # (train_features, train_features_labels[\"is_laundering\"].values), \n",
    "        (validation_features, validation_features_labels[\"is_phishing\"].values)\n",
    "    ]\n",
    ")\n",
    "print(f\"Best iteration: {model.best_iteration}\")\n",
    "\n",
    "y_test_predicted = model.predict(test_features)\n",
    "print(\"F1\", round(f1_score(test_features_labels[\"is_phishing\"], y_test_predicted), 8))\n",
    "print(\"Recall\", round(recall_score(test_features_labels[\"is_phishing\"], y_test_predicted), 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c00c1-3923-482a-85c4-22372b2415fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
