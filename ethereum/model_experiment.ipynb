{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bisect\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from glob import glob\n",
    "from datetime import timedelta, datetime\n",
    "from itertools import combinations\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import networkx as nx\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "\n",
    "import settings as s\n",
    "from communities import get_communities_multi_proc\n",
    "from features import get_features_multi_proc, pov_features\n",
    "from common import create_workload_for_multi_proc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b09f78-9b05-478b-ae80-1008c904dad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13551303\n",
      "\n",
      "CPU times: user 31.7 s, sys: 1.43 s, total: 33.1 s\n",
      "Wall time: 33.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"./data/MulDiGraph.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "nodes_mapping = {}\n",
    "phishing_nodes = {}\n",
    "for idx, nd in enumerate(nx.nodes(G)):\n",
    "    nodes_mapping[nd] = f\"id-{idx}\"\n",
    "    phishing_nodes[nodes_mapping[nd]] = G.nodes[nd][\"isp\"]\n",
    "\n",
    "rows = []\n",
    "for edge in nx.edges(G):\n",
    "    source, target = edge\n",
    "    attrs = G[source][target][0]\n",
    "    amount, timestamp = attrs[\"amount\"], attrs[\"timestamp\"]\n",
    "    source, target = nodes_mapping[source], nodes_mapping[target]\n",
    "    rows.append(\n",
    "        {\n",
    "            \"source\": source, \n",
    "            \"target\": target,\n",
    "            \"timestamp\": datetime.fromtimestamp(timestamp),\n",
    "            \"amount\": amount, \n",
    "        }\n",
    "    )\n",
    "data = pd.DataFrame(rows)\n",
    "data = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "data.index.name = \"transaction_id\"\n",
    "size_orig = data.shape[0]\n",
    "print(size_orig)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b65173d-00cc-4888-b5f1-f63c2a75dfd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PERC = 0.65\n",
    "VALIDATION_PERC = 0.15\n",
    "TEST_PERC = 0.2\n",
    "\n",
    "NUM_PROCS = 10\n",
    "\n",
    "assert(sum([TRAIN_PERC, VALIDATION_PERC, TEST_PERC]) == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac4061ec-a801-4d04-b031-d0b78bc7f44a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 239 ms, total: 25.7 s\n",
      "Wall time: 25.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "source_firsts = data.groupby(\"source\").agg(first_trx=(\"timestamp\", \"min\"))\n",
    "target_firsts = data.groupby(\"target\").agg(first_trx=(\"timestamp\", \"min\"))\n",
    "active_since = source_firsts.join(target_firsts, lsuffix=\"_left\", how=\"outer\").fillna(datetime.now())\n",
    "active_since.loc[:, \"active_since\"] = active_since.apply(lambda x: min([x[\"first_trx_left\"], x[\"first_trx\"]]), axis=1)\n",
    "active_since = active_since.loc[:, [\"active_since\"]]\n",
    "active_since.sort_values(\"active_since\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d6cfa5-97ac-49fa-be9d-a384b76b84ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,932,767 | 446,023 | 594,699\n"
     ]
    }
   ],
   "source": [
    "number_of_train_accounts = int(np.floor(active_since.shape[0] * TRAIN_PERC))\n",
    "number_of_validation_accounts = int(np.floor(active_since.shape[0] * VALIDATION_PERC))\n",
    "train_accounts = set(active_since.head(number_of_train_accounts).index.tolist())\n",
    "assert len(train_accounts) == number_of_train_accounts\n",
    "remaining = active_since.loc[~active_since.index.isin(train_accounts), :].sort_values(\"active_since\")\n",
    "validation_accounts = set(remaining.head(number_of_validation_accounts).index.tolist())\n",
    "assert len(validation_accounts) == number_of_validation_accounts\n",
    "test_accounts = set(active_since.index) - train_accounts - validation_accounts\n",
    "print(f\"{len(train_accounts):,} | {len(validation_accounts):,} | {len(test_accounts):,}\")\n",
    "assert sorted(train_accounts | validation_accounts | test_accounts) == sorted(active_since.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93f851d6-4900-473e-96ec-d2f4c052b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5355155 0.4\n"
     ]
    }
   ],
   "source": [
    "data = data.groupby([\"source\", \"target\", \"timestamp\"]).agg(\n",
    "    amount=(\"amount\", \"sum\"),\n",
    "    num_transactions=(\"amount\", \"count\"),\n",
    ").reset_index()\n",
    "data = data.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "data.index.name = \"transaction_id\"\n",
    "size_aggd = data.shape[0]\n",
    "print(size_aggd, round(size_aggd / size_orig, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7240d7ca-c966-4250-8e7d-c39a55230a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.2 s, sys: 213 ms, total: 19.4 s\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rates = pd.read_csv(\"data/rates.csv\", sep=\";\")\n",
    "rates.loc[:, \"rate\"] = (rates[\"low\"] + rates[\"high\"]) / 2\n",
    "rates.index = pd.to_datetime(rates[\"timeOpen\"]).dt.date\n",
    "rates = rates[\"rate\"].to_dict()\n",
    "data.loc[:, \"amount_usd\"] = data.apply(lambda x: rates[x[\"timestamp\"].date()] * x[\"amount\"], axis=1)\n",
    "data.loc[:, \"is_zero_transaction\"] = data.loc[:, \"amount\"] == 0\n",
    "\n",
    "data.loc[data[\"amount\"] < 1e-6, \"amount\"] = 1e-6\n",
    "data.loc[data[\"amount_usd\"] < 1e-6, \"amount_usd\"] = 1e-6\n",
    "data = data.astype({\"amount\": np.float32, \"amount_usd\": np.float32})\n",
    "columns = [\n",
    "    \"source\", \"target\", \"timestamp\", \"num_transactions\", \n",
    "    \"amount\", \"amount_usd\", \"is_zero_transaction\",\n",
    "]\n",
    "data = data.loc[:, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72c1d0c-4d69-435e-9979-730536720a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2113093\n",
      "200000 2113093\n",
      "400000 2113093\n",
      "600000 2113093\n",
      "800000 2113093\n",
      "1000000 2113093\n",
      "1200000 2113093\n",
      "1400000 2113093\n",
      "1600000 2113093\n",
      "1800000 2113093\n",
      "2000000 2113093\n",
      "CPU times: user 5min 21s, sys: 11.6 s, total: 5min 32s\n",
      "Wall time: 5min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_unique = data[\"source\"].nunique()\n",
    "source_dispensation = []\n",
    "for index, (_, group) in enumerate(data[[\"source\", \"amount_usd\"]].groupby(\"source\")):\n",
    "    group.loc[:, \"source_dispensation\"] = group[\"amount_usd\"].cumsum()\n",
    "    source_dispensation.append(group)\n",
    "    if not (index % 200_000):\n",
    "        print(index, num_unique)\n",
    "source_dispensation = pd.concat(source_dispensation, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1e3696a-450f-4e84-acf2-590b56b6b12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1119024\n",
      "200000 1119024\n",
      "400000 1119024\n",
      "600000 1119024\n",
      "800000 1119024\n",
      "1000000 1119024\n",
      "CPU times: user 2min 41s, sys: 4.88 s, total: 2min 46s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "num_unique = data[\"target\"].nunique()\n",
    "target_accumulation = []\n",
    "for index, (_, group) in enumerate(data[[\"target\", \"amount_usd\"]].groupby(\"target\")):\n",
    "    group.loc[:, \"target_accumulation\"] = group[\"amount_usd\"].cumsum()\n",
    "    target_accumulation.append(group)\n",
    "    if not (index % 200_000):\n",
    "        print(index, num_unique)\n",
    "target_accumulation = pd.concat(target_accumulation, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5853016b-d48b-4db7-9f87-a2fa9bea0e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = source_dispensation[[\"source_dispensation\"]].join(\n",
    "    target_accumulation[[\"target_accumulation\"]]\n",
    ").join(data)\n",
    "data.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c3d99e2-3a2f-4eaf-9564-87d674e78759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.1 s, sys: 4.59 s, total: 48.7 s\n",
      "Wall time: 44.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dispensation_mapping = {}\n",
    "for source, group in data[[\"source\", \"source_dispensation\"]].groupby(\"source\"):\n",
    "    dispensation_mapping[source] = (group.index.tolist(), group[\"source_dispensation\"].tolist())\n",
    "\n",
    "accumulation_mapping = {}\n",
    "for target, group in data[[\"target\", \"target_accumulation\"]].groupby(\"target\"):\n",
    "    accumulation_mapping[target] = (group.index.tolist(), group[\"target_accumulation\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b9afe0f-0664-4cd1-b992-39fd30e36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dis_acc_data(node, mapping_dis, mapping_acc, trx_id):\n",
    "    data_dis = mapping_dis.get(node)\n",
    "    if data_dis is None:\n",
    "        data_acc = mapping_acc[node]\n",
    "        index_acc = bisect.bisect_right(data_acc[0], trx_id)\n",
    "        if index_acc:\n",
    "            index_acc -= 1\n",
    "        else:\n",
    "            return 0, 0\n",
    "        return 0, data_acc[1][index_acc]\n",
    "    data_acc = mapping_acc.get(node)\n",
    "    if data_acc is None:\n",
    "        data_dis = mapping_dis[node]\n",
    "        index_dis = bisect.bisect_right(data_dis[0], trx_id)\n",
    "        if index_dis:\n",
    "            index_dis -= 1\n",
    "        else:\n",
    "            return 0, 0\n",
    "        return data_dis[1][index_dis], 0\n",
    "    index_dis = bisect.bisect_right(data_dis[0], trx_id)\n",
    "    index_acc = bisect.bisect_right(data_acc[0], trx_id)\n",
    "    so_far_dispensed = 0\n",
    "    if index_dis:\n",
    "        index_dis -= 1\n",
    "        so_far_dispensed = data_dis[1][index_dis]\n",
    "    so_far_accumulated = 0\n",
    "    if index_acc:\n",
    "        index_acc -= 1\n",
    "        so_far_accumulated = data_acc[1][index_acc]\n",
    "    return so_far_dispensed, so_far_accumulated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dff4bc67-9f53-4cbe-aa5e-c581f38dc235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_dis_acc_data(row):\n",
    "    return get_dis_acc_data(row[\"source\"], dispensation_mapping, accumulation_mapping, row.name)\n",
    "\n",
    "\n",
    "def target_dis_acc_data(row):\n",
    "    return get_dis_acc_data(row[\"target\"], dispensation_mapping, accumulation_mapping, row.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bebde69-b7a9-4caa-990a-7745fb3c5e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 485 ms, total: 36.1 s\n",
      "Wall time: 36.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "data.loc[:, \"dis_acc_source\"] = data.apply(source_dis_acc_data, axis=1)\n",
    "data.loc[:, \"dis_acc_target\"] = data.apply(target_dis_acc_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeba59f1-5aae-4da9-9ea3-be67c834b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[:, \"source_more_dispensed\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] > x[1]\n",
    ")\n",
    "data.loc[:, \"source_dis_acc_ratio\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] / (x[1] or 1) if x[0] < x[1] else 1\n",
    ")\n",
    "data.loc[:, \"source_acc_dis_ratio\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[1] / (x[0] or 1) if x[1] < x[0] else 1\n",
    ")\n",
    "data.loc[:, \"source_positive_balance\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[1] - x[0] if x[1] > x[0] else 0\n",
    ")\n",
    "data.loc[:, \"source_negative_balance\"] = data.loc[:, \"dis_acc_source\"].apply(\n",
    "    lambda x: x[0] - x[1] if x[0] > x[1] else 0\n",
    ")\n",
    "\n",
    "data.loc[:, \"target_more_dispensed\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] > x[1]\n",
    ")\n",
    "data.loc[:, \"target_dis_acc_ratio\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] / (x[1] or 1) if x[0] < x[1] else 1\n",
    ")\n",
    "data.loc[:, \"target_acc_dis_ratio\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[1] / (x[0] or 1) if x[1] < x[0] else 1\n",
    ")\n",
    "data.loc[:, \"target_positive_balance\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[1] - x[0] if x[1] > x[0] else 0\n",
    ")\n",
    "data.loc[:, \"target_negative_balance\"] = data.loc[:, \"dis_acc_target\"].apply(\n",
    "    lambda x: x[0] - x[1] if x[0] > x[1] else 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c394d521-c289-4efa-8840-6688e4068da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data[\"dis_acc_source\"]\n",
    "del data[\"dis_acc_target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fbf5a73-c036-4096-9b17-a44a18008824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 49.1 s, sys: 884 ms, total: 50 s\n",
      "Wall time: 50 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "active_since = active_since[\"active_since\"].to_dict()\n",
    "last_trx_ts = data[\"timestamp\"].max() + timedelta(hours=1)\n",
    "first_trx_ts = data[\"timestamp\"].min() - timedelta(hours=1)\n",
    "active_for = {k : (last_trx_ts - v).total_seconds() for k, v in active_since.items()}\n",
    "\n",
    "data.loc[:, \"source_active_for\"] = data.apply(\n",
    "    lambda x: (x[\"timestamp\"] - active_since[x[\"source\"]]).total_seconds(), axis=1\n",
    ")\n",
    "data.loc[:, \"target_active_for\"] = data.apply(\n",
    "    lambda x: (x[\"timestamp\"] - active_since[x[\"target\"]]).total_seconds(), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f309620f-0d51-4c3e-8352-bc432d22f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67 0.06 0.04\n"
     ]
    }
   ],
   "source": [
    "assert data.index.tolist() == list(range(data.shape[0]))\n",
    "\n",
    "train = data.loc[data[\"source\"].isin(train_accounts) & data[\"target\"].isin(train_accounts), :]\n",
    "validation = data.loc[data[\"source\"].isin(validation_accounts) & data[\"target\"].isin(validation_accounts), :]\n",
    "train_validation = data.loc[\n",
    "    data[\"source\"].isin(train_accounts | validation_accounts) & \n",
    "    data[\"target\"].isin(train_accounts | validation_accounts), :\n",
    "]\n",
    "test = data.loc[data[\"source\"].isin(test_accounts) & data[\"target\"].isin(test_accounts), :]\n",
    "print(\n",
    "    round(train.shape[0] / data.shape[0], 2), \n",
    "    round(validation.shape[0] / data.shape[0], 2), \n",
    "    round(test.shape[0] / data.shape[0], 2)\n",
    ")\n",
    "\n",
    "assert set(train.index).intersection(validation.index) == set()\n",
    "assert set(validation.index).intersection(test.index) == set()\n",
    "assert set(train.index).intersection(test.index) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a735041b-db89-4692-9fa2-e5f65aa377cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "502 354 309 1165\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    len(train_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len(validation_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len(test_accounts.intersection([x for x, y in phishing_nodes.items() if y == 1])),\n",
    "    len([x for x, y in phishing_nodes.items() if y == 1]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f2e353-a0a1-462f-8979-63d6e9a23936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trx_features(df, source_target):\n",
    "    trx_feats = df.groupby(source_target).agg({\n",
    "        \"source_dispensation\": [\"max\"],\n",
    "        \"target_accumulation\": [\"max\"],\n",
    "        \"amount_usd\": [\"mean\", \"median\", \"max\", \"std\"],  # skew, kurtosis ?\n",
    "        \"num_transactions\": [\"sum\", \"count\"],\n",
    "        \"is_zero_transaction\": [\"sum\"],\n",
    "        \"source_dis_acc_ratio\": [\"mean\", \"std\"],\n",
    "        \"source_acc_dis_ratio\": [\"mean\", \"std\"],    \n",
    "        \"target_dis_acc_ratio\": [\"mean\", \"std\"],\n",
    "        \"target_acc_dis_ratio\": [\"mean\", \"std\"],\n",
    "        \"source_positive_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"source_negative_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"target_positive_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"target_negative_balance\": [\"max\", \"mean\", \"std\"],\n",
    "        \"source_active_for\": [\"max\", \"std\"],\n",
    "        \"target_active_for\": [\"max\", \"std\"],\n",
    "    })\n",
    "    trx_feats.columns = [f\"trx_feats_{source_target}_{col}_{stat}\" for col, stat in trx_feats.columns]\n",
    "    trx_feats.index.name = \"key\"\n",
    "    return trx_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7cd2c4d-15eb-4513-b1fd-69a4d19c63fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 1.33 s, total: 14.9 s\n",
      "Wall time: 14.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_trx_features = get_trx_features(train, \"source\").join(\n",
    "    get_trx_features(train, \"target\"), how=\"outer\"\n",
    ")\n",
    "validation_trx_features = get_trx_features(train_validation, \"source\").join(\n",
    "    get_trx_features(train_validation, \"target\"), how=\"outer\"\n",
    ")\n",
    "test_trx_features = get_trx_features(data, \"source\").join(\n",
    "    get_trx_features(data, \"target\"), how=\"outer\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e69899e-e6a0-4f84-a288-737de0dd3009",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebc24179-d5c2-4cf0-afdf-e8b5a105c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_main_features = \"features\"\n",
    "\n",
    "location_train = f\"{location_main_features}{os.sep}train{os.sep}\"\n",
    "location_validation = f\"{location_main_features}{os.sep}validation{os.sep}\"\n",
    "location_test = f\"{location_main_features}{os.sep}test{os.sep}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dca4b9b1-73fa-446d-81ea-223a18127df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shutil.rmtree(location_main_features, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f45f4cf-663d-4fb9-8b90-4064bd2cf3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 74 9079121\n",
      "0 194\n",
      "20 194\n",
      "40 194\n",
      "60 194\n",
      "80 194\n",
      "100 194\n",
      "120 194\n",
      "140 194\n",
      "160 194\n",
      "180 194\n",
      "CPU times: user 7min 17s, sys: 26.4 s, total: 7min 43s\n",
      "Wall time: 59min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_train)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = train.copy(deep=True)\n",
    "in_scope_nodes = list(set(train[\"source\"].unique()).union(train[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "features_all = features_all.join(train_trx_features, how=\"left\")\n",
    "features_all.to_parquet(f\"{location_train}data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd3defa4-a869-41ee-ac8b-107b5a5bb82f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 65 871854\n",
      "0 21\n",
      "20 21\n",
      "CPU times: user 4min 52s, sys: 13.5 s, total: 5min 6s\n",
      "Wall time: 25min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_validation)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = train_validation.copy(deep=True)\n",
    "in_scope_nodes = list(set(validation[\"source\"].unique()).union(validation[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "features_all = features_all.join(validation_trx_features, how=\"left\")\n",
    "features_all.to_parquet(f\"{location_validation}data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f1b67ba-00e0-48f3-bc9a-e917a789a3b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 81 791044\n",
      "0 19\n",
      "CPU times: user 5min 42s, sys: 15.9 s, total: 5min 58s\n",
      "Wall time: 30min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "try:\n",
    "    os.makedirs(location_test)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "in_scope_window = data.copy(deep=True)\n",
    "in_scope_nodes = list(set(test[\"source\"].unique()).union(test[\"target\"].unique()))\n",
    "%run model_experiment_nested.ipynb\n",
    "features_all = features_all.join(test_trx_features, how=\"left\")\n",
    "features_all.to_parquet(f\"{location_test}data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1d6ed1b-8c5d-45b6-8ec7-17557a4ebb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.0\n"
     ]
    }
   ],
   "source": [
    "print((time.time() - start) // 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9dbf8d36-22b4-4974-9bc9-90b29063b26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_eval_multiclass(y, y_):\n",
    "    labels_predicted = y_.argmax(axis=1)\n",
    "    class_1 = labels_predicted.copy()\n",
    "    class_1[class_1 == 2] = 0\n",
    "    class_2 = labels_predicted.copy()\n",
    "    class_2[class_2 == 1] = 0\n",
    "    class_2[class_2 == 2] = 1\n",
    "    labels_actual = y.copy()\n",
    "    labels_actual[labels_actual == 2] = 0\n",
    "    f1_error_1 = 1 - f1_score(labels_actual, class_1)\n",
    "    labels_actual = y.copy()\n",
    "    labels_actual[labels_actual == 1] = 0\n",
    "    labels_actual[labels_actual == 2] = 1\n",
    "    f1_error_2 = 1 - f1_score(labels_actual, class_2)\n",
    "    return f1_error_1 + f1_error_2\n",
    "\n",
    "\n",
    "def f1_eval(y, y_):\n",
    "    return 1 - f1_score(y, np.round(y_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a222ed5e-9584-4441-bf39-8206338c57c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_merge_features(features_normal, features_graph, feat_for):\n",
    "    features_normal.loc[:, \"transaction_id\"] = features_normal.index.tolist()\n",
    "    if \"is_phishing\" in features_normal.columns:\n",
    "        del features_normal[\"is_phishing\"]\n",
    "    features_normal.loc[:, \"is_phishing\"] = features_normal.loc[:, feat_for].apply(lambda x: bool(phishing_nodes[x]))\n",
    "    features_graph_source = features_normal.set_index(\"source\").join(\n",
    "        features_graph.set_index(\"key\"), how=\"left\", rsuffix=\"_source\"\n",
    "    ).reset_index()\n",
    "    features_graph_target = features_normal[[\"transaction_id\", \"target\"]].set_index(\"target\").join(\n",
    "        features_graph.set_index(\"key\"), how=\"left\", rsuffix=\"_target\"\n",
    "    ).reset_index()\n",
    "    del features_graph_target[\"target\"]\n",
    "    result = features_graph_source.set_index(\"transaction_id\").join(\n",
    "        features_graph_target.set_index(\"transaction_id\"), how=\"left\", rsuffix=\"_target\"\n",
    "    )\n",
    "    labels = result.loc[:, label_columns].copy(deep=True)\n",
    "    for c in label_columns:\n",
    "        del result[c]\n",
    "    return result, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4a104486-cc51-4207-8230-3b012f05942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.read_parquet(f\"{location_train}data.parquet\").fillna(0)\n",
    "train_features.loc[:, \"is_phishing\"] = train_features.loc[:, \"key\"].apply(lambda x: bool(phishing_nodes[x]))\n",
    "train_features_labels = train_features.loc[:, [\"key\", \"is_phishing\"]]\n",
    "del train_features[\"key\"]\n",
    "del train_features[\"is_phishing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8c9c6375-7b12-4daf-a48d-aeb96caed993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best iteration: 14\n",
      "F1 0.62567812\n",
      "Recall 0.60278746\n",
      "CPU times: user 2min 21s, sys: 2.48 s, total: 2min 24s\n",
      "Wall time: 19.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "all_test_nodes = set(test[\"source\"].unique()).union(test[\"target\"].unique())\n",
    "phishers_data = pd.DataFrame(all_test_nodes, columns=[\"node\"])\n",
    "phishers_data.loc[:, \"is_phisher\"] = False\n",
    "phishers_data.loc[:, \"is_phisher\"] = phishers_data[\"node\"].apply(lambda x: bool(phishing_nodes[x]))\n",
    "phishers_data.loc[:, \"is_phisher_predicted\"] = False\n",
    "\n",
    "train_features = pd.read_parquet(f\"{location_train}data.parquet\").fillna(0)\n",
    "train_features.loc[:, \"is_phishing\"] = train_features.loc[:, \"key\"].apply(lambda x: bool(phishing_nodes[x]))\n",
    "train_features_labels = train_features.loc[:, [\"key\", \"is_phishing\"]]\n",
    "del train_features[\"key\"]\n",
    "del train_features[\"is_phishing\"]\n",
    "\n",
    "validation_features = pd.read_parquet(f\"{location_validation}data.parquet\").fillna(0)\n",
    "validation_features.loc[:, \"is_phishing\"] = validation_features.loc[:, \"key\"].apply(lambda x: bool(phishing_nodes[x]))\n",
    "validation_features_labels = validation_features.loc[:, [\"key\", \"is_phishing\"]]\n",
    "del validation_features[\"key\"]\n",
    "del validation_features[\"is_phishing\"]\n",
    "\n",
    "test_features = pd.read_parquet(f\"{location_test}data.parquet\").fillna(0)\n",
    "test_features.loc[:, \"is_phishing\"] = test_features.loc[:, \"key\"].apply(lambda x: bool(phishing_nodes[x]))\n",
    "test_features_labels = test_features.loc[:, [\"key\", \"is_phishing\"]]\n",
    "del test_features[\"key\"]\n",
    "del test_features[\"is_phishing\"]\n",
    "\n",
    "# scale_pos_weight = int(train_features_labels.shape[0] / (train_features_labels[\"is_phishing\"].sum() or 1))\n",
    "scale_pos_weight = 10\n",
    "\n",
    "# model = xgb.XGBClassifier(\n",
    "#     early_stopping_rounds=100,\n",
    "#     objective=\"multi:softprob\", num_class=3, eval_metric=f1_eval, disable_default_eval_metric=True\n",
    "# )\n",
    "# model.fit(\n",
    "#     train_features, train_features_labels[\"is_phishing\"].values,\n",
    "#     eval_set=[\n",
    "#         # (train_features, train_features_labels[\"is_laundering\"].values), \n",
    "#         (validation_features, validation_features_labels[\"is_phishing\"].values)\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    early_stopping_rounds=20, scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric=f1_eval, disable_default_eval_metric=True, num_parallel_tree=10,\n",
    "    colsample_bytree=0.5, subsample=0.5, max_depth=6,\n",
    ")\n",
    "model.fit(\n",
    "    train_features, train_features_labels[\"is_phishing\"].values, verbose=False,\n",
    "    eval_set=[\n",
    "        # (train_features, train_features_labels[\"is_laundering\"].values), \n",
    "        (validation_features, validation_features_labels[\"is_phishing\"].values)\n",
    "    ]\n",
    ")\n",
    "print(f\"Best iteration: {model.best_iteration}\")\n",
    "\n",
    "y_test_predicted = model.predict(test_features)\n",
    "print(\"F1\", round(f1_score(test_features_labels[\"is_phishing\"], y_test_predicted), 8))\n",
    "print(\"Recall\", round(recall_score(test_features_labels[\"is_phishing\"], y_test_predicted), 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ff6f4f80-0be0-49ae-86d6-53a45842c4ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(287, 227)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features_labels[\"is_phishing\"].sum(), y_test_predicted.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fe7be6c-9ec4-438b-915b-a17a38813297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "309 - 287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a288c174-ae0c-411e-b6a8-fc5fea0a6e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = list(test_features_labels[\"is_phishing\"]) + ([1]*22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91bf404d-f262-4651-a9b0-d0759eaf587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(y_test_predicted) + ([0] * 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2aef1e2-b46d-4073-a18c-09ccd7ba14b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.582089552238806"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(k, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c00c1-3923-482a-85c4-22372b2415fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
