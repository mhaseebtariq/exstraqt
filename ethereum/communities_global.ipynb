{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6844f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import shutil\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "from collections import Counter\n",
    "from glob import glob\n",
    "from datetime import timedelta, datetime\n",
    "from itertools import combinations\n",
    "\n",
    "import igraph as ig\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945d95e6-ad47-4c78-9da3-4387ea8610cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg.loc[:, \"amount\"] = np.ceil(data_agg.loc[:, \"amount\"])\n",
    "data_agg = data_agg.astype({\"amount\": np.uint64})\n",
    "data_agg = data_agg.sort_values(\"amount\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0b0ed-bb7c-46ea-aff8-542335fe9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_sent = data_agg.groupby(\"source\").agg({\"amount\": \"sum\"})[\"amount\"].to_dict()\n",
    "totals_received = data_agg.groupby(\"target\").agg({\"amount\": \"sum\"})[\"amount\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7c627-1d78-4c2b-be10-934c35c05710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_communities(top_n, n_hops, data_input, pov, cp, totals, to_check_in):\n",
    "    if not(0 < n_hops < 11):\n",
    "        raise NotImplementedError\n",
    "    if top_n < 1:\n",
    "        raise ValueError\n",
    "    \n",
    "    result = []\n",
    "    \n",
    "    level_1st = data_input[data_input[pov].isin(to_check_in)].groupby(pov).head(top_n).reset_index(drop=True)\n",
    "    level_1st.loc[:, \"amount\"] = np.array(\n",
    "        [\n",
    "            level_1st.loc[:, pov].apply(lambda x: totals[x]).values, \n",
    "            level_1st.loc[:, \"amount\"].values\n",
    "        ],\n",
    "        dtype=np.uint64\n",
    "    ).min(axis=0)\n",
    "    level_1st = level_1st.sort_values(\"amount\", ascending=False)\n",
    "    level_1st = level_1st.loc[level_1st[\"source\"] != level_1st[\"target\"], :].reset_index(drop=True)\n",
    "    level_1st_comms = level_1st.groupby(pov).agg(nodes=(cp, list), amounts=(\"amount\", list))\n",
    "    level_1st_comms = level_1st_comms.apply(lambda x: dict(zip(x[\"nodes\"], x[\"amounts\"])), axis=1).to_dict()\n",
    "    print(f\"Processed hop #1 | {level_1st.shape[0]:,} | {len(level_1st_comms):,}\")\n",
    "    \n",
    "    result.append(level_1st_comms)\n",
    "\n",
    "    for n_hop in range(1, n_hops):\n",
    "        if n_hop == 1:\n",
    "            n_minus_1 = level_1st.copy(deep=True)\n",
    "        else:\n",
    "            n_minus_1 = level_nth.copy(deep=True)\n",
    "        level_nth = n_minus_1.set_index(cp).join(\n",
    "            level_1st.set_index(pov), lsuffix=\"_left\", how=\"inner\"\n",
    "        ).reset_index(drop=True)\n",
    "        level_nth = level_nth.loc[level_nth[\"source\"] != level_nth[\"target\"], :].reset_index(drop=True)\n",
    "        level_nth.loc[:, \"amount\"] = level_nth[[\"amount_left\", \"amount\"]].min(axis=1)\n",
    "        del level_nth[\"amount_left\"]\n",
    "        level_nth = level_nth.groupby([pov, cp]).agg(amount=(\"amount\", \"sum\")).reset_index()\n",
    "        level_nth.loc[:, \"amount\"] = np.array(\n",
    "            [\n",
    "                level_nth.loc[:, pov].apply(lambda x: totals[x]).values, \n",
    "                level_nth.loc[:, \"amount\"].values\n",
    "            ],\n",
    "            dtype=np.uint64\n",
    "        ).min(axis=0)\n",
    "        level_nth = level_nth.sort_values(\"amount\", ascending=False).reset_index(drop=True)\n",
    "        level_nth = level_nth.groupby(pov).head(top_n).reset_index(drop=True)\n",
    "        level_nth_comms = level_nth.groupby(pov).agg(nodes=(cp, list), amounts=(\"amount\", list))\n",
    "        level_nth_comms = level_nth_comms.apply(lambda x: dict(zip(x[\"nodes\"], x[\"amounts\"])), axis=1).to_dict()\n",
    "        print(f\"Processed hop #{n_hop + 1} | {level_nth.shape[0]:,} | {len(level_nth_comms):,}\")\n",
    "\n",
    "        result.append(level_nth_comms)\n",
    "    \n",
    "    del level_1st\n",
    "    del n_minus_1\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153c715-8699-4abf-9e1b-99949d37bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing communities_as_source\\n\")\n",
    "communities_as_source = get_communities(50, 4, data_agg, \"source\", \"target\", totals_sent, nodes_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd484ee-cf34-466c-980c-f1d4978a57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing communities_as_target\\n\")\n",
    "communities_as_target = get_communities(50, 4, data_agg, \"target\", \"source\", totals_received, nodes_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aeb50-c10d-47d9-86c1-8d33ace73688",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing communities_as_passthrough\\n\")\n",
    "communities_as_passthrough = get_communities(\n",
    "    50, 4, data_agg.loc[data_agg[\"source\"].isin(nodes_passthrough), :], \"source\", \"target\", \n",
    "    totals_received, nodes_passthrough\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed78fd-8a2a-41bd-8908-b73835a59247",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features = []\n",
    "for node in nodes_source.intersection(communities_as_source[0].keys()):\n",
    "    all_nodes = set()\n",
    "    node_comm_stats = {\"key\": node}\n",
    "    for index, communities in enumerate(communities_as_source):\n",
    "        n_hop = index + 1\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = 0\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = 0\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = 0\n",
    "        if not communities.get(node):\n",
    "            continue\n",
    "        nodes_community, amounts_community = zip(*communities[node].items())\n",
    "        if not index:\n",
    "            sum_prev = totals_sent[node]\n",
    "        else:\n",
    "            sum_prev = sum(communities_as_source[index - 1][node].values())\n",
    "        sum_prev = min([totals_sent[node], sum_prev])\n",
    "        amounts_community_adjusted = np.array(amounts_community, dtype=np.float64)\n",
    "        amounts_community_adjusted /= sum_prev\n",
    "        amounts_community_adjusted[amounts_community_adjusted > 1] = 1\n",
    "        sum_this = sum(communities[node].values())\n",
    "        perc_transferred = (sum_this / sum_prev) if sum_prev > sum_this else 1\n",
    "        amounts_community_adjusted *= perc_transferred\n",
    "        number_of_new_accounts = len(set(nodes_community) - all_nodes)\n",
    "        all_nodes = all_nodes.union(nodes_community)\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = len(nodes_community)\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = len(all_nodes)\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = number_of_new_accounts\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = np.max(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = np.mean(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = np.median(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = np.std(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_skew_transferred\"] = stats.skew(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_kurtosis_transferred\"] = stats.kurtosis(amounts_community_adjusted)\n",
    "    communities_as_source_features.append(node_comm_stats)\n",
    "\n",
    "communities_as_source_features = pd.DataFrame(communities_as_source_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec56cd2-0b7f-42b5-a2da-a1a29178cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_target_features = []\n",
    "for node in nodes_target.intersection(communities_as_target[0].keys()):\n",
    "    all_nodes = set()\n",
    "    node_comm_stats = {\"key\": node}\n",
    "    for index, communities in enumerate(communities_as_target):\n",
    "        n_hop = index + 1\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = 0\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = 0\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = 0\n",
    "        if not communities.get(node):\n",
    "            continue\n",
    "        nodes_community, amounts_community = zip(*communities[node].items())\n",
    "        if not index:\n",
    "            sum_prev = totals_received[node]\n",
    "        else:\n",
    "            sum_prev = sum(communities_as_target[index - 1][node].values())\n",
    "        sum_prev = min([totals_received[node], sum_prev])\n",
    "        amounts_community_adjusted = np.array(amounts_community, dtype=np.float64)\n",
    "        amounts_community_adjusted /= sum_prev\n",
    "        amounts_community_adjusted[amounts_community_adjusted > 1] = 1\n",
    "        sum_this = sum(communities[node].values())\n",
    "        perc_transferred = (sum_this / sum_prev) if sum_prev > sum_this else 1\n",
    "        amounts_community_adjusted *= perc_transferred\n",
    "        number_of_new_accounts = len(set(nodes_community) - all_nodes)\n",
    "        all_nodes = all_nodes.union(nodes_community)\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = len(nodes_community)\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = len(all_nodes)\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = number_of_new_accounts\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = np.max(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = np.mean(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = np.median(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = np.std(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_skew_transferred\"] = stats.skew(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_kurtosis_transferred\"] = stats.kurtosis(amounts_community_adjusted)\n",
    "    communities_as_target_features.append(node_comm_stats)\n",
    "\n",
    "communities_as_target_features = pd.DataFrame(communities_as_target_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb95904-1c97-4442-9400-82f4980a4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_passthrough_features = []\n",
    "for node in nodes_passthrough.intersection(communities_as_passthrough[0].keys()):\n",
    "    all_nodes = set()\n",
    "    node_comm_stats = {\"key\": node}\n",
    "    for index, communities in enumerate(communities_as_passthrough):\n",
    "        n_hop = index + 1\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = 0\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = 0\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = 0\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = 0\n",
    "        if not communities.get(node):\n",
    "            continue\n",
    "        nodes_community, amounts_community = zip(*communities[node].items())\n",
    "        if not index:\n",
    "            sum_prev = totals_received[node]\n",
    "        else:\n",
    "            sum_prev = sum(communities_as_passthrough[index - 1][node].values())\n",
    "        sum_prev = min([totals_received[node], sum_prev])\n",
    "        amounts_community_adjusted = np.array(amounts_community, dtype=np.float64)\n",
    "        amounts_community_adjusted /= sum_prev\n",
    "        amounts_community_adjusted[amounts_community_adjusted > 1] = 1\n",
    "        sum_this = sum(communities[node].values())\n",
    "        perc_transferred = (sum_this / sum_prev) if sum_prev > sum_this else 1\n",
    "        amounts_community_adjusted *= perc_transferred\n",
    "        number_of_new_accounts = len(set(nodes_community) - all_nodes)\n",
    "        all_nodes = all_nodes.union(nodes_community)\n",
    "        node_comm_stats[f\"hop_{n_hop}_number_of_accounts\"] = len(nodes_community)\n",
    "        if index:\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_distinct_accounts\"] = len(all_nodes)\n",
    "            node_comm_stats[f\"hop_{n_hop}_number_of_new_accounts\"] = number_of_new_accounts\n",
    "        node_comm_stats[f\"hop_{n_hop}_max_transferred\"] = np.max(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_mean_transferred\"] = np.mean(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_median_transferred\"] = np.median(amounts_community_adjusted)\n",
    "        node_comm_stats[f\"hop_{n_hop}_std_transferred\"] = np.std(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_skew_transferred\"] = stats.skew(amounts_community_adjusted)\n",
    "        # node_comm_stats[f\"hop_{n_hop}_kurtosis_transferred\"] = stats.kurtosis(amounts_community_adjusted)\n",
    "    communities_as_passthrough_features.append(node_comm_stats)\n",
    "\n",
    "communities_as_passthrough_features = pd.DataFrame(communities_as_passthrough_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836cd53-b001-481c-ae52-103e5b798531",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features.set_index(\"key\", inplace=True)\n",
    "communities_as_target_features.set_index(\"key\", inplace=True)\n",
    "communities_as_passthrough_features.set_index(\"key\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806a051-123e-4696-b7a9-48ee4dcfdf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_types = {}\n",
    "for k, v in communities_as_source_features.dtypes.to_dict().items():\n",
    "    if str(v).startswith(\"int\"):\n",
    "        new_types[k] = np.uint8\n",
    "    elif str(v).startswith(\"float\"):\n",
    "        new_types[k] = np.float16\n",
    "    elif str(v).startswith(\"uint\"):\n",
    "        pass\n",
    "    else:\n",
    "        raise Exception(k, v)\n",
    "\n",
    "communities_as_source_features = communities_as_source_features.astype(new_types)\n",
    "communities_as_target_features = communities_as_target_features.astype(new_types)\n",
    "communities_as_passthrough_features = communities_as_passthrough_features.astype(new_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51c356-8b07-4e3c-8ada-a3697107a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_as_source_features.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in communities_as_source_features.columns]\n",
    "communities_as_target_features.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in communities_as_target_features.columns]\n",
    "communities_as_passthrough_features.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in communities_as_passthrough_features.columns]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
